{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
      "170500096/170498071 [==============================] - 15s 0us/step\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "\n",
    "(x_train,y_train),(x_test,y_test) = cifar10.load_data() \n",
    "\n",
    "x_train = x_train / 255\n",
    "x_test = x_test / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = tf.keras.utils.to_categorical(y_train, num_classes=10)\n",
    "y_test = tf.keras.utils.to_categorical(y_test, num_classes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras import regularizers\n",
    "\n",
    "# from src.scripts.residuallayer import ResnetIdentityBlock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_generator = ImageDataGenerator(\n",
    "        featurewise_center=False,\n",
    "        samplewise_center=False,\n",
    "        featurewise_std_normalization=False,\n",
    "        samplewise_std_normalization=False,\n",
    "        zca_whitening=False,\n",
    "        zca_epsilon=1e-06,\n",
    "        rotation_range=15,\n",
    "        width_shift_range=0.1,\n",
    "        height_shift_range=0.1,\n",
    "        shear_range=0.,\n",
    "        zoom_range=0.,\n",
    "        channel_shift_range=0.,\n",
    "        fill_mode='nearest',\n",
    "        cval=0.,\n",
    "        horizontal_flip=True,\n",
    "        vertical_flip=False,\n",
    "        rescale=None,\n",
    "        preprocessing_function=None,\n",
    "        data_format=None,\n",
    "        validation_split=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_generator.fit(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CLASSES = 10\n",
    "INPUT_SHAPE = (32, 32, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Conv2D(32, (3, 3), padding='same', activation='relu', input_shape=INPUT_SHAPE, kernel_regularizer=regularizers.l2(0.0005)))\n",
    "model.add(tf.keras.layers.BatchNormalization())\n",
    "model.add(tf.keras.layers.Conv2D(32, (3, 3), padding='same', activation='relu', kernel_regularizer=regularizers.l2(0.002)))\n",
    "model.add(tf.keras.layers.BatchNormalization())\n",
    "model.add(tf.keras.layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(tf.keras.layers.Conv2D(64, (3, 3), padding='same', activation='relu', input_shape=INPUT_SHAPE, kernel_regularizer=regularizers.l2(0.001)))\n",
    "model.add(tf.keras.layers.BatchNormalization())\n",
    "model.add(tf.keras.layers.Conv2D(64, (3, 3), padding='same', activation='relu', kernel_regularizer=regularizers.l2(0.002)))\n",
    "model.add(tf.keras.layers.BatchNormalization())\n",
    "model.add(tf.keras.layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(tf.keras.layers.Conv2D(128, (3, 3), padding='same', activation='relu', kernel_regularizer=regularizers.l2(0.002)))\n",
    "model.add(tf.keras.layers.BatchNormalization())\n",
    "model.add(tf.keras.layers.Conv2D(128, (3, 3), padding='same', activation='relu', kernel_regularizer=regularizers.l2(0.002)))\n",
    "model.add(tf.keras.layers.BatchNormalization())\n",
    "model.add(tf.keras.layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(tf.keras.layers.Conv2D(256, (3, 3), padding='same', activation='relu', kernel_regularizer=regularizers.l2(0.002)))\n",
    "model.add(tf.keras.layers.BatchNormalization())\n",
    "model.add(tf.keras.layers.Conv2D(256, (3, 3), padding='same', activation='relu', kernel_regularizer=regularizers.l2(0.002)))\n",
    "model.add(tf.keras.layers.BatchNormalization())\n",
    "model.add(tf.keras.layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(tf.keras.layers.Conv2D(512, (2, 2), padding='same', activation='relu', kernel_regularizer=regularizers.l2(0.002)))\n",
    "model.add(tf.keras.layers.BatchNormalization())\n",
    "model.add(tf.keras.layers.Conv2D(512, (2, 2), padding='same', activation='relu', kernel_regularizer=regularizers.l2(0.002)))\n",
    "model.add(tf.keras.layers.BatchNormalization())\n",
    "model.add(tf.keras.layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "\n",
    "model.add(tf.keras.layers.Dense(128, activation='relu', kernel_regularizer=regularizers.l2(0.002)))\n",
    "model.add(tf.keras.layers.Dropout(0.1))\n",
    "\n",
    "model.add(tf.keras.layers.Dense(NUM_CLASSES, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_20 (Conv2D)           (None, 32, 32, 32)        896       \n",
      "_________________________________________________________________\n",
      "batch_normalization_20 (Batc (None, 32, 32, 32)        128       \n",
      "_________________________________________________________________\n",
      "conv2d_21 (Conv2D)           (None, 32, 32, 32)        9248      \n",
      "_________________________________________________________________\n",
      "batch_normalization_21 (Batc (None, 32, 32, 32)        128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_22 (Conv2D)           (None, 16, 16, 64)        18496     \n",
      "_________________________________________________________________\n",
      "batch_normalization_22 (Batc (None, 16, 16, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv2d_23 (Conv2D)           (None, 16, 16, 64)        36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_23 (Batc (None, 16, 16, 64)        256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_11 (MaxPooling (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_24 (Conv2D)           (None, 8, 8, 128)         73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_24 (Batc (None, 8, 8, 128)         512       \n",
      "_________________________________________________________________\n",
      "conv2d_25 (Conv2D)           (None, 8, 8, 128)         147584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_25 (Batc (None, 8, 8, 128)         512       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_12 (MaxPooling (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_26 (Conv2D)           (None, 4, 4, 256)         295168    \n",
      "_________________________________________________________________\n",
      "batch_normalization_26 (Batc (None, 4, 4, 256)         1024      \n",
      "_________________________________________________________________\n",
      "conv2d_27 (Conv2D)           (None, 4, 4, 256)         590080    \n",
      "_________________________________________________________________\n",
      "batch_normalization_27 (Batc (None, 4, 4, 256)         1024      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_13 (MaxPooling (None, 2, 2, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_28 (Conv2D)           (None, 2, 2, 512)         524800    \n",
      "_________________________________________________________________\n",
      "batch_normalization_28 (Batc (None, 2, 2, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv2d_29 (Conv2D)           (None, 2, 2, 512)         1049088   \n",
      "_________________________________________________________________\n",
      "batch_normalization_29 (Batc (None, 2, 2, 512)         2048      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_14 (MaxPooling (None, 1, 1, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 128)               65664     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 2,821,034\n",
      "Trainable params: 2,817,066\n",
      "Non-trainable params: 3,968\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 391 steps, validate on 10000 samples\n",
      "Epoch 1/100\n",
      "391/391 [==============================] - 22s 55ms/step - loss: 4.1467 - accuracy: 0.4460 - val_loss: 3.5465 - val_accuracy: 0.3035\n",
      "Epoch 2/100\n",
      "391/391 [==============================] - 18s 46ms/step - loss: 2.2468 - accuracy: 0.6006 - val_loss: 1.8851 - val_accuracy: 0.6246\n",
      "Epoch 3/100\n",
      "391/391 [==============================] - 18s 47ms/step - loss: 1.6357 - accuracy: 0.6738 - val_loss: 1.6877 - val_accuracy: 0.6332\n",
      "Epoch 4/100\n",
      "391/391 [==============================] - 18s 47ms/step - loss: 1.4095 - accuracy: 0.7090 - val_loss: 1.5282 - val_accuracy: 0.6741\n",
      "Epoch 5/100\n",
      "391/391 [==============================] - 18s 46ms/step - loss: 1.3136 - accuracy: 0.7282 - val_loss: 1.7107 - val_accuracy: 0.6393\n",
      "Epoch 6/100\n",
      "391/391 [==============================] - 18s 45ms/step - loss: 1.2661 - accuracy: 0.7457 - val_loss: 1.4216 - val_accuracy: 0.6987\n",
      "Epoch 7/100\n",
      "391/391 [==============================] - 18s 47ms/step - loss: 1.2382 - accuracy: 0.7536 - val_loss: 1.8313 - val_accuracy: 0.5862\n",
      "Epoch 8/100\n",
      "391/391 [==============================] - 18s 46ms/step - loss: 1.2224 - accuracy: 0.7623 - val_loss: 1.4217 - val_accuracy: 0.6985\n",
      "Epoch 9/100\n",
      "391/391 [==============================] - 19s 48ms/step - loss: 1.1922 - accuracy: 0.7692 - val_loss: 1.4745 - val_accuracy: 0.6838\n",
      "Epoch 10/100\n",
      "391/391 [==============================] - 18s 47ms/step - loss: 1.1818 - accuracy: 0.7758 - val_loss: 1.3300 - val_accuracy: 0.7276\n",
      "Epoch 11/100\n",
      "391/391 [==============================] - 19s 49ms/step - loss: 1.1536 - accuracy: 0.7834 - val_loss: 1.3457 - val_accuracy: 0.7113\n",
      "Epoch 12/100\n",
      "391/391 [==============================] - 18s 46ms/step - loss: 1.1447 - accuracy: 0.7863 - val_loss: 1.2053 - val_accuracy: 0.7674\n",
      "Epoch 13/100\n",
      "391/391 [==============================] - 18s 47ms/step - loss: 1.1157 - accuracy: 0.7910 - val_loss: 1.1489 - val_accuracy: 0.7740\n",
      "Epoch 14/100\n",
      "391/391 [==============================] - 18s 47ms/step - loss: 1.0989 - accuracy: 0.7951 - val_loss: 1.1227 - val_accuracy: 0.7927\n",
      "Epoch 15/100\n",
      "391/391 [==============================] - 19s 48ms/step - loss: 1.0807 - accuracy: 0.8010 - val_loss: 1.2104 - val_accuracy: 0.7589\n",
      "Epoch 16/100\n",
      "391/391 [==============================] - 19s 47ms/step - loss: 1.0668 - accuracy: 0.8045 - val_loss: 1.2032 - val_accuracy: 0.7451\n",
      "Epoch 17/100\n",
      "391/391 [==============================] - 19s 48ms/step - loss: 1.0516 - accuracy: 0.8045 - val_loss: 1.1273 - val_accuracy: 0.7799\n",
      "Epoch 18/100\n",
      "391/391 [==============================] - 18s 45ms/step - loss: 1.0543 - accuracy: 0.8064 - val_loss: 1.1201 - val_accuracy: 0.7809\n",
      "Epoch 19/100\n",
      "391/391 [==============================] - 18s 45ms/step - loss: 1.0300 - accuracy: 0.8106 - val_loss: 1.0514 - val_accuracy: 0.7909\n",
      "Epoch 20/100\n",
      "391/391 [==============================] - 18s 45ms/step - loss: 1.0129 - accuracy: 0.8138 - val_loss: 1.0977 - val_accuracy: 0.7764\n",
      "Epoch 21/100\n",
      "391/391 [==============================] - 18s 46ms/step - loss: 0.9984 - accuracy: 0.8172 - val_loss: 1.0431 - val_accuracy: 0.7973\n",
      "Epoch 22/100\n",
      "391/391 [==============================] - 18s 46ms/step - loss: 0.9905 - accuracy: 0.8183 - val_loss: 1.2554 - val_accuracy: 0.7367\n",
      "Epoch 23/100\n",
      "391/391 [==============================] - 18s 46ms/step - loss: 0.9789 - accuracy: 0.8193 - val_loss: 1.0851 - val_accuracy: 0.7858\n",
      "Epoch 24/100\n",
      "391/391 [==============================] - 18s 46ms/step - loss: 0.9540 - accuracy: 0.8223 - val_loss: 1.2031 - val_accuracy: 0.7532\n",
      "Epoch 25/100\n",
      "391/391 [==============================] - 20s 51ms/step - loss: 0.9499 - accuracy: 0.8240 - val_loss: 1.2672 - val_accuracy: 0.7270\n",
      "Epoch 26/100\n",
      "391/391 [==============================] - 20s 50ms/step - loss: 0.9482 - accuracy: 0.8215 - val_loss: 1.1282 - val_accuracy: 0.7674\n",
      "Epoch 27/100\n",
      "391/391 [==============================] - 18s 47ms/step - loss: 0.9418 - accuracy: 0.8231 - val_loss: 1.2024 - val_accuracy: 0.7479\n",
      "Epoch 28/100\n",
      "391/391 [==============================] - 18s 47ms/step - loss: 0.9321 - accuracy: 0.8262 - val_loss: 0.9427 - val_accuracy: 0.8241\n",
      "Epoch 29/100\n",
      "391/391 [==============================] - 18s 47ms/step - loss: 0.9225 - accuracy: 0.8277 - val_loss: 1.0055 - val_accuracy: 0.7973\n",
      "Epoch 30/100\n",
      "391/391 [==============================] - 19s 49ms/step - loss: 0.9170 - accuracy: 0.8290 - val_loss: 0.9815 - val_accuracy: 0.8061\n",
      "Epoch 31/100\n",
      "391/391 [==============================] - 18s 47ms/step - loss: 0.9115 - accuracy: 0.8288 - val_loss: 0.9974 - val_accuracy: 0.8037\n",
      "Epoch 32/100\n",
      "391/391 [==============================] - 20s 50ms/step - loss: 0.8982 - accuracy: 0.8295 - val_loss: 0.9842 - val_accuracy: 0.8025\n",
      "Epoch 33/100\n",
      "391/391 [==============================] - 21s 53ms/step - loss: 0.8954 - accuracy: 0.8310 - val_loss: 1.0286 - val_accuracy: 0.7845\n",
      "Epoch 34/100\n",
      "391/391 [==============================] - 19s 48ms/step - loss: 0.8913 - accuracy: 0.8308 - val_loss: 0.9677 - val_accuracy: 0.8010\n",
      "Epoch 35/100\n",
      "391/391 [==============================] - 19s 48ms/step - loss: 0.8889 - accuracy: 0.8296 - val_loss: 1.1098 - val_accuracy: 0.7601\n",
      "Epoch 36/100\n",
      "391/391 [==============================] - 19s 48ms/step - loss: 0.8826 - accuracy: 0.8328 - val_loss: 1.0850 - val_accuracy: 0.7687\n",
      "Epoch 37/100\n",
      "391/391 [==============================] - 18s 47ms/step - loss: 0.8763 - accuracy: 0.8335 - val_loss: 0.9270 - val_accuracy: 0.8207\n",
      "Epoch 38/100\n",
      "391/391 [==============================] - 19s 50ms/step - loss: 0.8724 - accuracy: 0.8361 - val_loss: 1.1676 - val_accuracy: 0.7511\n",
      "Epoch 39/100\n",
      "391/391 [==============================] - 19s 47ms/step - loss: 0.8683 - accuracy: 0.8341 - val_loss: 0.9529 - val_accuracy: 0.8099\n",
      "Epoch 40/100\n",
      "391/391 [==============================] - 18s 46ms/step - loss: 0.8607 - accuracy: 0.8371 - val_loss: 0.9483 - val_accuracy: 0.8139\n",
      "Epoch 41/100\n",
      "391/391 [==============================] - 19s 47ms/step - loss: 0.8545 - accuracy: 0.8372 - val_loss: 1.0313 - val_accuracy: 0.7918\n",
      "Epoch 42/100\n",
      "391/391 [==============================] - 18s 47ms/step - loss: 0.8536 - accuracy: 0.8370 - val_loss: 0.9683 - val_accuracy: 0.8031\n",
      "Epoch 43/100\n",
      "391/391 [==============================] - 23s 59ms/step - loss: 0.8440 - accuracy: 0.8396 - val_loss: 0.8915 - val_accuracy: 0.8215\n",
      "Epoch 44/100\n",
      "391/391 [==============================] - 21s 55ms/step - loss: 0.8438 - accuracy: 0.8380 - val_loss: 0.9609 - val_accuracy: 0.8041\n",
      "Epoch 45/100\n",
      "391/391 [==============================] - 19s 49ms/step - loss: 0.8428 - accuracy: 0.8378 - val_loss: 0.9121 - val_accuracy: 0.8198\n",
      "Epoch 46/100\n",
      "391/391 [==============================] - 19s 48ms/step - loss: 0.8456 - accuracy: 0.8382 - val_loss: 1.1345 - val_accuracy: 0.7444\n",
      "Epoch 47/100\n",
      "391/391 [==============================] - 18s 47ms/step - loss: 0.8333 - accuracy: 0.8408 - val_loss: 1.1621 - val_accuracy: 0.7361\n",
      "Epoch 48/100\n",
      "391/391 [==============================] - 19s 47ms/step - loss: 0.8353 - accuracy: 0.8391 - val_loss: 0.9311 - val_accuracy: 0.8058\n",
      "Epoch 49/100\n",
      "391/391 [==============================] - 18s 47ms/step - loss: 0.8361 - accuracy: 0.8393 - val_loss: 0.9880 - val_accuracy: 0.7934\n",
      "Epoch 50/100\n",
      "391/391 [==============================] - 18s 47ms/step - loss: 0.8315 - accuracy: 0.8403 - val_loss: 0.9926 - val_accuracy: 0.7896\n",
      "Epoch 51/100\n",
      "391/391 [==============================] - 21s 53ms/step - loss: 0.8296 - accuracy: 0.8405 - val_loss: 0.9806 - val_accuracy: 0.8022\n",
      "Epoch 52/100\n",
      "391/391 [==============================] - 20s 50ms/step - loss: 0.8326 - accuracy: 0.8397 - val_loss: 1.0421 - val_accuracy: 0.7739\n",
      "Epoch 53/100\n",
      "391/391 [==============================] - 18s 47ms/step - loss: 0.8295 - accuracy: 0.8405 - val_loss: 0.8568 - val_accuracy: 0.8317\n",
      "Epoch 54/100\n",
      "391/391 [==============================] - 18s 46ms/step - loss: 0.8228 - accuracy: 0.8408 - val_loss: 0.9975 - val_accuracy: 0.7868\n",
      "Epoch 55/100\n",
      "391/391 [==============================] - 18s 45ms/step - loss: 0.8150 - accuracy: 0.8439 - val_loss: 1.0171 - val_accuracy: 0.7809\n",
      "Epoch 56/100\n",
      "391/391 [==============================] - 18s 46ms/step - loss: 0.8198 - accuracy: 0.8412 - val_loss: 0.9739 - val_accuracy: 0.7983\n",
      "Epoch 57/100\n",
      "391/391 [==============================] - 18s 46ms/step - loss: 0.8152 - accuracy: 0.8444 - val_loss: 0.8506 - val_accuracy: 0.8281\n",
      "Epoch 58/100\n",
      "391/391 [==============================] - 18s 46ms/step - loss: 0.8226 - accuracy: 0.8388 - val_loss: 0.9556 - val_accuracy: 0.8069\n",
      "Epoch 59/100\n",
      "391/391 [==============================] - 18s 47ms/step - loss: 0.8108 - accuracy: 0.8442 - val_loss: 0.8445 - val_accuracy: 0.8302\n",
      "Epoch 60/100\n",
      "391/391 [==============================] - 18s 46ms/step - loss: 0.8119 - accuracy: 0.8427 - val_loss: 0.8161 - val_accuracy: 0.8440\n",
      "Epoch 61/100\n",
      "391/391 [==============================] - 18s 46ms/step - loss: 0.8123 - accuracy: 0.8437 - val_loss: 0.9948 - val_accuracy: 0.7891\n",
      "Epoch 62/100\n",
      "391/391 [==============================] - 18s 46ms/step - loss: 0.8093 - accuracy: 0.8438 - val_loss: 1.0463 - val_accuracy: 0.7820\n",
      "Epoch 63/100\n",
      "391/391 [==============================] - 18s 46ms/step - loss: 0.8039 - accuracy: 0.8455 - val_loss: 0.8413 - val_accuracy: 0.8314\n",
      "Epoch 64/100\n",
      "391/391 [==============================] - 18s 45ms/step - loss: 0.8072 - accuracy: 0.8429 - val_loss: 0.9015 - val_accuracy: 0.8182\n",
      "Epoch 65/100\n",
      "391/391 [==============================] - 19s 47ms/step - loss: 0.8068 - accuracy: 0.8442 - val_loss: 0.9362 - val_accuracy: 0.8035\n",
      "Epoch 66/100\n",
      "391/391 [==============================] - 18s 46ms/step - loss: 0.8035 - accuracy: 0.8448 - val_loss: 0.9171 - val_accuracy: 0.8113\n",
      "Epoch 67/100\n",
      "391/391 [==============================] - 18s 47ms/step - loss: 0.8021 - accuracy: 0.8445 - val_loss: 0.8978 - val_accuracy: 0.8132\n",
      "Epoch 68/100\n",
      "391/391 [==============================] - 18s 45ms/step - loss: 0.7990 - accuracy: 0.8455 - val_loss: 0.8869 - val_accuracy: 0.8164\n",
      "Epoch 69/100\n",
      "391/391 [==============================] - 18s 46ms/step - loss: 0.7952 - accuracy: 0.8472 - val_loss: 0.9653 - val_accuracy: 0.8010\n",
      "Epoch 70/100\n",
      "391/391 [==============================] - 18s 46ms/step - loss: 0.7983 - accuracy: 0.8467 - val_loss: 0.8900 - val_accuracy: 0.8209\n",
      "Epoch 71/100\n",
      "391/391 [==============================] - 18s 45ms/step - loss: 0.7910 - accuracy: 0.8457 - val_loss: 0.9164 - val_accuracy: 0.8070\n",
      "Epoch 72/100\n",
      "391/391 [==============================] - 19s 47ms/step - loss: 0.7898 - accuracy: 0.8458 - val_loss: 0.9193 - val_accuracy: 0.8097\n",
      "Epoch 73/100\n",
      "391/391 [==============================] - 18s 46ms/step - loss: 0.7925 - accuracy: 0.8457 - val_loss: 0.8516 - val_accuracy: 0.8255\n",
      "Epoch 74/100\n",
      "391/391 [==============================] - 19s 48ms/step - loss: 0.7874 - accuracy: 0.8456 - val_loss: 0.9956 - val_accuracy: 0.7788\n",
      "Epoch 75/100\n",
      "391/391 [==============================] - 19s 48ms/step - loss: 0.7922 - accuracy: 0.8450 - val_loss: 0.9013 - val_accuracy: 0.8129\n",
      "Epoch 76/100\n",
      "391/391 [==============================] - 19s 47ms/step - loss: 0.7793 - accuracy: 0.8499 - val_loss: 0.9182 - val_accuracy: 0.8078\n",
      "Epoch 77/100\n",
      "391/391 [==============================] - 18s 47ms/step - loss: 0.7886 - accuracy: 0.8462 - val_loss: 0.8917 - val_accuracy: 0.8178\n",
      "Epoch 78/100\n",
      "391/391 [==============================] - 20s 52ms/step - loss: 0.7849 - accuracy: 0.8488 - val_loss: 0.9726 - val_accuracy: 0.7966\n",
      "Epoch 79/100\n",
      "391/391 [==============================] - 18s 47ms/step - loss: 0.7831 - accuracy: 0.8493 - val_loss: 0.9521 - val_accuracy: 0.8001\n",
      "Epoch 80/100\n",
      "391/391 [==============================] - 18s 47ms/step - loss: 0.7853 - accuracy: 0.8480 - val_loss: 0.8728 - val_accuracy: 0.8166\n",
      "Epoch 81/100\n",
      "391/391 [==============================] - 18s 46ms/step - loss: 0.7853 - accuracy: 0.8481 - val_loss: 0.9618 - val_accuracy: 0.7989\n",
      "Epoch 82/100\n",
      "391/391 [==============================] - 19s 48ms/step - loss: 0.7802 - accuracy: 0.8464 - val_loss: 0.8685 - val_accuracy: 0.8250\n",
      "Epoch 83/100\n",
      "391/391 [==============================] - 18s 45ms/step - loss: 0.7821 - accuracy: 0.8475 - val_loss: 0.9925 - val_accuracy: 0.7916\n",
      "Epoch 84/100\n",
      "391/391 [==============================] - 18s 45ms/step - loss: 0.7778 - accuracy: 0.8487 - val_loss: 0.9136 - val_accuracy: 0.8043\n",
      "Epoch 85/100\n",
      "391/391 [==============================] - 18s 45ms/step - loss: 0.7798 - accuracy: 0.8480 - val_loss: 0.8058 - val_accuracy: 0.8405\n",
      "Epoch 86/100\n",
      "391/391 [==============================] - 18s 45ms/step - loss: 0.7821 - accuracy: 0.8479 - val_loss: 1.2631 - val_accuracy: 0.7384\n",
      "Epoch 87/100\n",
      "391/391 [==============================] - 18s 46ms/step - loss: 0.7735 - accuracy: 0.8471 - val_loss: 0.8253 - val_accuracy: 0.8348\n",
      "Epoch 88/100\n",
      "391/391 [==============================] - 19s 48ms/step - loss: 0.7760 - accuracy: 0.8474 - val_loss: 0.8411 - val_accuracy: 0.8349\n",
      "Epoch 89/100\n",
      "391/391 [==============================] - 19s 48ms/step - loss: 0.7765 - accuracy: 0.8483 - val_loss: 1.0746 - val_accuracy: 0.7684\n",
      "Epoch 90/100\n",
      "391/391 [==============================] - 18s 46ms/step - loss: 0.7695 - accuracy: 0.8503 - val_loss: 0.9363 - val_accuracy: 0.8007\n",
      "Epoch 91/100\n",
      "391/391 [==============================] - 18s 46ms/step - loss: 0.7731 - accuracy: 0.8500 - val_loss: 0.8617 - val_accuracy: 0.8135\n",
      "Epoch 92/100\n",
      "391/391 [==============================] - 18s 46ms/step - loss: 0.7715 - accuracy: 0.8484 - val_loss: 0.9485 - val_accuracy: 0.7996\n",
      "Epoch 93/100\n",
      "391/391 [==============================] - 18s 46ms/step - loss: 0.7696 - accuracy: 0.8481 - val_loss: 0.9006 - val_accuracy: 0.8093\n",
      "Epoch 94/100\n",
      "391/391 [==============================] - 20s 51ms/step - loss: 0.7706 - accuracy: 0.8485 - val_loss: 0.8199 - val_accuracy: 0.8325\n",
      "Epoch 95/100\n",
      "391/391 [==============================] - 20s 51ms/step - loss: 0.7692 - accuracy: 0.8500 - val_loss: 0.8052 - val_accuracy: 0.8366\n",
      "Epoch 96/100\n",
      "391/391 [==============================] - 20s 52ms/step - loss: 0.7774 - accuracy: 0.8464 - val_loss: 0.8915 - val_accuracy: 0.8095\n",
      "Epoch 97/100\n",
      "391/391 [==============================] - 19s 49ms/step - loss: 0.7627 - accuracy: 0.8507 - val_loss: 0.9158 - val_accuracy: 0.8027\n",
      "Epoch 98/100\n",
      "391/391 [==============================] - 19s 49ms/step - loss: 0.7657 - accuracy: 0.8516 - val_loss: 0.8329 - val_accuracy: 0.8314\n",
      "Epoch 99/100\n",
      "391/391 [==============================] - 19s 49ms/step - loss: 0.7642 - accuracy: 0.8485 - val_loss: 0.9214 - val_accuracy: 0.8028\n",
      "Epoch 100/100\n",
      "391/391 [==============================] - 22s 55ms/step - loss: 0.7617 - accuracy: 0.8495 - val_loss: 0.8873 - val_accuracy: 0.8150\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fa01c3a5490>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(image_generator.flow(x_train, y_train, batch_size=128),\n",
    "                    validation_data=(x_test, y_test),\n",
    "                    epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_param = 0.001\n",
    "\n",
    "\n",
    "model_2 = tf.keras.Sequential()\n",
    "model_2.add(tf.keras.layers.Conv2D(16, (3, 3), padding='same', activation='relu', input_shape=INPUT_SHAPE, kernel_regularizer=regularizers.l2(0.0005)))\n",
    "model_2.add(tf.keras.layers.BatchNormalization())\n",
    "model_2.add(tf.keras.layers.Conv2D(16, (3, 3), padding='same', activation='relu', kernel_regularizer=regularizers.l2(reg_param)))\n",
    "model_2.add(tf.keras.layers.BatchNormalization())\n",
    "model_2.add(tf.keras.layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "model_2.add(tf.keras.layers.Conv2D(32, (3, 3), padding='same', activation='relu', input_shape=INPUT_SHAPE, kernel_regularizer=regularizers.l2(0.001)))\n",
    "model_2.add(tf.keras.layers.BatchNormalization())\n",
    "model_2.add(tf.keras.layers.Conv2D(32, (3, 3), padding='same', activation='relu', kernel_regularizer=regularizers.l2(reg_param)))\n",
    "model_2.add(tf.keras.layers.BatchNormalization())\n",
    "model_2.add(tf.keras.layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "model_2.add(tf.keras.layers.Conv2D(64, (3, 3), padding='same', activation='relu', kernel_regularizer=regularizers.l2(reg_param)))\n",
    "model_2.add(tf.keras.layers.BatchNormalization())\n",
    "model_2.add(tf.keras.layers.Conv2D(64, (3, 3), padding='same', activation='relu', kernel_regularizer=regularizers.l2(reg_param)))\n",
    "model_2.add(tf.keras.layers.BatchNormalization())\n",
    "model_2.add(tf.keras.layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "model_2.add(tf.keras.layers.Conv2D(128, (3, 3), padding='same', activation='relu', kernel_regularizer=regularizers.l2(reg_param)))\n",
    "model_2.add(tf.keras.layers.BatchNormalization())\n",
    "model_2.add(tf.keras.layers.Conv2D(128, (3, 3), padding='same', activation='relu', kernel_regularizer=regularizers.l2(reg_param)))\n",
    "model_2.add(tf.keras.layers.BatchNormalization())\n",
    "model_2.add(tf.keras.layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "model_2.add(tf.keras.layers.Conv2D(256, (2, 2), padding='same', activation='relu', kernel_regularizer=regularizers.l2(reg_param)))\n",
    "model_2.add(tf.keras.layers.BatchNormalization())\n",
    "model_2.add(tf.keras.layers.Conv2D(512, (2, 2), padding='same', activation='relu', kernel_regularizer=regularizers.l2(reg_param)))\n",
    "model_2.add(tf.keras.layers.BatchNormalization())\n",
    "model_2.add(tf.keras.layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "model_2.add(tf.keras.layers.Flatten())\n",
    "\n",
    "model_2.add(tf.keras.layers.Dense(1024, activation='relu', kernel_regularizer=regularizers.l2(reg_param)))\n",
    "model_2.add(tf.keras.layers.Dense(1024, activation='relu', kernel_regularizer=regularizers.l2(reg_param)))\n",
    "model_2.add(tf.keras.layers.Dense(128, activation='relu', kernel_regularizer=regularizers.l2(reg_param)))\n",
    "\n",
    "\n",
    "model_2.add(tf.keras.layers.Dense(NUM_CLASSES, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_40 (Conv2D)           (None, 32, 32, 16)        448       \n",
      "_________________________________________________________________\n",
      "batch_normalization_40 (Batc (None, 32, 32, 16)        64        \n",
      "_________________________________________________________________\n",
      "conv2d_41 (Conv2D)           (None, 32, 32, 16)        2320      \n",
      "_________________________________________________________________\n",
      "batch_normalization_41 (Batc (None, 32, 32, 16)        64        \n",
      "_________________________________________________________________\n",
      "max_pooling2d_20 (MaxPooling (None, 16, 16, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_42 (Conv2D)           (None, 16, 16, 32)        4640      \n",
      "_________________________________________________________________\n",
      "batch_normalization_42 (Batc (None, 16, 16, 32)        128       \n",
      "_________________________________________________________________\n",
      "conv2d_43 (Conv2D)           (None, 16, 16, 32)        9248      \n",
      "_________________________________________________________________\n",
      "batch_normalization_43 (Batc (None, 16, 16, 32)        128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_21 (MaxPooling (None, 8, 8, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_44 (Conv2D)           (None, 8, 8, 64)          18496     \n",
      "_________________________________________________________________\n",
      "batch_normalization_44 (Batc (None, 8, 8, 64)          256       \n",
      "_________________________________________________________________\n",
      "conv2d_45 (Conv2D)           (None, 8, 8, 64)          36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_45 (Batc (None, 8, 8, 64)          256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_22 (MaxPooling (None, 4, 4, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_46 (Conv2D)           (None, 4, 4, 128)         73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_46 (Batc (None, 4, 4, 128)         512       \n",
      "_________________________________________________________________\n",
      "conv2d_47 (Conv2D)           (None, 4, 4, 128)         147584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_47 (Batc (None, 4, 4, 128)         512       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_23 (MaxPooling (None, 2, 2, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_48 (Conv2D)           (None, 2, 2, 256)         131328    \n",
      "_________________________________________________________________\n",
      "batch_normalization_48 (Batc (None, 2, 2, 256)         1024      \n",
      "_________________________________________________________________\n",
      "conv2d_49 (Conv2D)           (None, 2, 2, 512)         524800    \n",
      "_________________________________________________________________\n",
      "batch_normalization_49 (Batc (None, 2, 2, 512)         2048      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_24 (MaxPooling (None, 1, 1, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 1024)              525312    \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 128)               131200    \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 2,662,042\n",
      "Trainable params: 2,659,546\n",
      "Non-trainable params: 2,496\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_2.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model_2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "callback_es = tf.keras.callbacks.EarlyStopping(patience=50,\n",
    "                                               monitor='val_loss',\n",
    "                                               mode='auto',\n",
    "                                               restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 391 steps, validate on 10000 samples\n",
      "Epoch 1/150\n",
      "391/391 [==============================] - 18s 45ms/step - loss: 2.9755 - accuracy: 0.4607 - val_loss: 2.9633 - val_accuracy: 0.3041\n",
      "Epoch 2/150\n",
      "391/391 [==============================] - 17s 42ms/step - loss: 1.6977 - accuracy: 0.5984 - val_loss: 1.4778 - val_accuracy: 0.6395\n",
      "Epoch 3/150\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 1.3746 - accuracy: 0.6571 - val_loss: 1.2703 - val_accuracy: 0.6910\n",
      "Epoch 4/150\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 1.2388 - accuracy: 0.6931 - val_loss: 1.2780 - val_accuracy: 0.6999\n",
      "Epoch 5/150\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 1.1609 - accuracy: 0.7164 - val_loss: 1.1904 - val_accuracy: 0.7059\n",
      "Epoch 6/150\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 1.1048 - accuracy: 0.7331 - val_loss: 1.2167 - val_accuracy: 0.7025\n",
      "Epoch 7/150\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 1.0664 - accuracy: 0.7450 - val_loss: 1.1941 - val_accuracy: 0.7085\n",
      "Epoch 8/150\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 1.0357 - accuracy: 0.7567 - val_loss: 1.0389 - val_accuracy: 0.7554\n",
      "Epoch 9/150\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 1.0174 - accuracy: 0.7626 - val_loss: 1.1129 - val_accuracy: 0.7304\n",
      "Epoch 10/150\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 0.9942 - accuracy: 0.7694 - val_loss: 0.9809 - val_accuracy: 0.7742\n",
      "Epoch 11/150\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 0.9746 - accuracy: 0.7751 - val_loss: 0.9738 - val_accuracy: 0.7758\n",
      "Epoch 12/150\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 0.9614 - accuracy: 0.7811 - val_loss: 1.2964 - val_accuracy: 0.6982\n",
      "Epoch 13/150\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 0.9456 - accuracy: 0.7853 - val_loss: 1.0349 - val_accuracy: 0.7609\n",
      "Epoch 14/150\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 0.9342 - accuracy: 0.7892 - val_loss: 0.9621 - val_accuracy: 0.7823\n",
      "Epoch 15/150\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 0.9160 - accuracy: 0.7952 - val_loss: 0.9213 - val_accuracy: 0.7927\n",
      "Epoch 16/150\n",
      "391/391 [==============================] - 17s 44ms/step - loss: 0.9029 - accuracy: 0.7997 - val_loss: 1.0159 - val_accuracy: 0.7675\n",
      "Epoch 17/150\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 0.8960 - accuracy: 0.8023 - val_loss: 1.0362 - val_accuracy: 0.7614\n",
      "Epoch 18/150\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 0.8904 - accuracy: 0.8024 - val_loss: 1.0722 - val_accuracy: 0.7445\n",
      "Epoch 19/150\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 0.8815 - accuracy: 0.8038 - val_loss: 0.9382 - val_accuracy: 0.7906\n",
      "Epoch 20/150\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 0.8695 - accuracy: 0.8086 - val_loss: 1.1068 - val_accuracy: 0.7453\n",
      "Epoch 21/150\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 0.8595 - accuracy: 0.8098 - val_loss: 1.0410 - val_accuracy: 0.7604\n",
      "Epoch 22/150\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 0.8560 - accuracy: 0.8115 - val_loss: 0.9039 - val_accuracy: 0.7977\n",
      "Epoch 23/150\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 0.8522 - accuracy: 0.8119 - val_loss: 0.8968 - val_accuracy: 0.7967\n",
      "Epoch 24/150\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 0.8457 - accuracy: 0.8133 - val_loss: 0.8317 - val_accuracy: 0.8204\n",
      "Epoch 25/150\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 0.8346 - accuracy: 0.8171 - val_loss: 0.9320 - val_accuracy: 0.7873\n",
      "Epoch 26/150\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 0.8282 - accuracy: 0.8184 - val_loss: 0.9389 - val_accuracy: 0.7850\n",
      "Epoch 27/150\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 0.8291 - accuracy: 0.8188 - val_loss: 1.0564 - val_accuracy: 0.7565\n",
      "Epoch 28/150\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 0.8194 - accuracy: 0.8221 - val_loss: 0.9161 - val_accuracy: 0.7921\n",
      "Epoch 29/150\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 0.8108 - accuracy: 0.8230 - val_loss: 0.8935 - val_accuracy: 0.7990\n",
      "Epoch 30/150\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 0.8179 - accuracy: 0.8213 - val_loss: 0.9382 - val_accuracy: 0.7907\n",
      "Epoch 31/150\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 0.8106 - accuracy: 0.8242 - val_loss: 0.9436 - val_accuracy: 0.7793\n",
      "Epoch 32/150\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 0.7995 - accuracy: 0.8258 - val_loss: 0.8864 - val_accuracy: 0.8004\n",
      "Epoch 33/150\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 0.7998 - accuracy: 0.8254 - val_loss: 0.9838 - val_accuracy: 0.7690\n",
      "Epoch 34/150\n",
      "391/391 [==============================] - 17s 44ms/step - loss: 0.8010 - accuracy: 0.8242 - val_loss: 0.9780 - val_accuracy: 0.7686\n",
      "Epoch 35/150\n",
      "391/391 [==============================] - 16s 42ms/step - loss: 0.7919 - accuracy: 0.8284 - val_loss: 1.0168 - val_accuracy: 0.7587\n",
      "Epoch 36/150\n",
      "391/391 [==============================] - 17s 42ms/step - loss: 0.7880 - accuracy: 0.8281 - val_loss: 0.8621 - val_accuracy: 0.8051\n",
      "Epoch 37/150\n",
      "391/391 [==============================] - 17s 44ms/step - loss: 0.7872 - accuracy: 0.8275 - val_loss: 0.8219 - val_accuracy: 0.8226\n",
      "Epoch 38/150\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 0.7851 - accuracy: 0.8287 - val_loss: 1.1005 - val_accuracy: 0.7494\n",
      "Epoch 39/150\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 0.7792 - accuracy: 0.8291 - val_loss: 0.9836 - val_accuracy: 0.7675\n",
      "Epoch 40/150\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 0.7745 - accuracy: 0.8326 - val_loss: 0.9144 - val_accuracy: 0.7914\n",
      "Epoch 41/150\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 0.7749 - accuracy: 0.8312 - val_loss: 0.8487 - val_accuracy: 0.8093\n",
      "Epoch 42/150\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 0.7755 - accuracy: 0.8330 - val_loss: 0.8920 - val_accuracy: 0.7972\n",
      "Epoch 43/150\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 0.7638 - accuracy: 0.8358 - val_loss: 0.9261 - val_accuracy: 0.7865\n",
      "Epoch 44/150\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 0.7661 - accuracy: 0.8335 - val_loss: 0.9068 - val_accuracy: 0.7986\n",
      "Epoch 45/150\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 0.7643 - accuracy: 0.8348 - val_loss: 0.9823 - val_accuracy: 0.7735\n",
      "Epoch 46/150\n",
      "391/391 [==============================] - 17s 44ms/step - loss: 0.7654 - accuracy: 0.8351 - val_loss: 0.8676 - val_accuracy: 0.7984\n",
      "Epoch 47/150\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 0.7613 - accuracy: 0.8344 - val_loss: 0.8707 - val_accuracy: 0.8059\n",
      "Epoch 48/150\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 0.7572 - accuracy: 0.8347 - val_loss: 0.8824 - val_accuracy: 0.7925\n",
      "Epoch 49/150\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 0.7614 - accuracy: 0.8354 - val_loss: 0.8228 - val_accuracy: 0.8148\n",
      "Epoch 50/150\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 0.7512 - accuracy: 0.8383 - val_loss: 1.0304 - val_accuracy: 0.7593\n",
      "Epoch 51/150\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 0.7494 - accuracy: 0.8367 - val_loss: 0.8969 - val_accuracy: 0.7918\n",
      "Epoch 52/150\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 0.7548 - accuracy: 0.8373 - val_loss: 0.8554 - val_accuracy: 0.8006\n",
      "Epoch 53/150\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 0.7508 - accuracy: 0.8372 - val_loss: 0.8287 - val_accuracy: 0.8144\n",
      "Epoch 54/150\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 0.7435 - accuracy: 0.8392 - val_loss: 0.8888 - val_accuracy: 0.8077\n",
      "Epoch 55/150\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 0.7456 - accuracy: 0.8375 - val_loss: 0.8922 - val_accuracy: 0.7930\n",
      "Epoch 56/150\n",
      "391/391 [==============================] - 16s 42ms/step - loss: 0.7397 - accuracy: 0.8400 - val_loss: 0.8505 - val_accuracy: 0.8089\n",
      "Epoch 57/150\n",
      "391/391 [==============================] - 17s 42ms/step - loss: 0.7429 - accuracy: 0.8401 - val_loss: 0.8240 - val_accuracy: 0.8196\n",
      "Epoch 58/150\n",
      "391/391 [==============================] - 17s 44ms/step - loss: 0.7401 - accuracy: 0.8392 - val_loss: 0.7843 - val_accuracy: 0.8272\n",
      "Epoch 59/150\n",
      "391/391 [==============================] - 17s 42ms/step - loss: 0.7356 - accuracy: 0.8413 - val_loss: 0.8923 - val_accuracy: 0.7952\n",
      "Epoch 60/150\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 0.7375 - accuracy: 0.8404 - val_loss: 1.0416 - val_accuracy: 0.7591\n",
      "Epoch 61/150\n",
      "391/391 [==============================] - 17s 44ms/step - loss: 0.7353 - accuracy: 0.8389 - val_loss: 0.8338 - val_accuracy: 0.8163\n",
      "Epoch 62/150\n",
      "391/391 [==============================] - 17s 44ms/step - loss: 0.7320 - accuracy: 0.8431 - val_loss: 0.8049 - val_accuracy: 0.8188\n",
      "Epoch 63/150\n",
      "391/391 [==============================] - 16s 42ms/step - loss: 0.7322 - accuracy: 0.8416 - val_loss: 0.8662 - val_accuracy: 0.8017\n",
      "Epoch 64/150\n",
      "391/391 [==============================] - 17s 42ms/step - loss: 0.7287 - accuracy: 0.8415 - val_loss: 0.8079 - val_accuracy: 0.8212\n",
      "Epoch 65/150\n",
      "391/391 [==============================] - 16s 41ms/step - loss: 0.7323 - accuracy: 0.8397 - val_loss: 0.8102 - val_accuracy: 0.8244\n",
      "Epoch 66/150\n",
      "391/391 [==============================] - 16s 41ms/step - loss: 0.7237 - accuracy: 0.8445 - val_loss: 0.8272 - val_accuracy: 0.8143\n",
      "Epoch 67/150\n",
      "391/391 [==============================] - 16s 41ms/step - loss: 0.7312 - accuracy: 0.8404 - val_loss: 0.7823 - val_accuracy: 0.8250\n",
      "Epoch 68/150\n",
      "391/391 [==============================] - 16s 41ms/step - loss: 0.7304 - accuracy: 0.8430 - val_loss: 0.7594 - val_accuracy: 0.8361\n",
      "Epoch 69/150\n",
      "391/391 [==============================] - 16s 41ms/step - loss: 0.7264 - accuracy: 0.8427 - val_loss: 0.8137 - val_accuracy: 0.8207\n",
      "Epoch 70/150\n",
      "391/391 [==============================] - 16s 41ms/step - loss: 0.7237 - accuracy: 0.8432 - val_loss: 0.8542 - val_accuracy: 0.8034\n",
      "Epoch 71/150\n",
      "391/391 [==============================] - 16s 41ms/step - loss: 0.7243 - accuracy: 0.8424 - val_loss: 1.0371 - val_accuracy: 0.7668\n",
      "Epoch 72/150\n",
      "391/391 [==============================] - 16s 41ms/step - loss: 0.7233 - accuracy: 0.8457 - val_loss: 0.8143 - val_accuracy: 0.8093\n",
      "Epoch 73/150\n",
      "391/391 [==============================] - 16s 41ms/step - loss: 0.7186 - accuracy: 0.8459 - val_loss: 0.8789 - val_accuracy: 0.7969\n",
      "Epoch 74/150\n",
      "391/391 [==============================] - 16s 41ms/step - loss: 0.7195 - accuracy: 0.8454 - val_loss: 0.7794 - val_accuracy: 0.8270\n",
      "Epoch 75/150\n",
      "391/391 [==============================] - 17s 44ms/step - loss: 0.7172 - accuracy: 0.8443 - val_loss: 0.9139 - val_accuracy: 0.7937\n",
      "Epoch 76/150\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 0.7159 - accuracy: 0.8458 - val_loss: 0.8232 - val_accuracy: 0.8161\n",
      "Epoch 77/150\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 0.7143 - accuracy: 0.8448 - val_loss: 0.8185 - val_accuracy: 0.8182\n",
      "Epoch 78/150\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 0.7162 - accuracy: 0.8446 - val_loss: 0.8044 - val_accuracy: 0.8205\n",
      "Epoch 79/150\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 0.7168 - accuracy: 0.8453 - val_loss: 0.7802 - val_accuracy: 0.8202\n",
      "Epoch 80/150\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 0.7124 - accuracy: 0.8457 - val_loss: 0.8640 - val_accuracy: 0.8055\n",
      "Epoch 81/150\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 0.7141 - accuracy: 0.8462 - val_loss: 0.8700 - val_accuracy: 0.8074\n",
      "Epoch 82/150\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 0.7145 - accuracy: 0.8452 - val_loss: 0.9175 - val_accuracy: 0.7874\n",
      "Epoch 83/150\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 0.7085 - accuracy: 0.8469 - val_loss: 0.8273 - val_accuracy: 0.8098\n",
      "Epoch 84/150\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 0.7134 - accuracy: 0.8452 - val_loss: 0.7486 - val_accuracy: 0.8380\n",
      "Epoch 85/150\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 0.7107 - accuracy: 0.8471 - val_loss: 0.8392 - val_accuracy: 0.8153\n",
      "Epoch 86/150\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 0.7078 - accuracy: 0.8489 - val_loss: 0.7329 - val_accuracy: 0.8417\n",
      "Epoch 87/150\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 0.7078 - accuracy: 0.8476 - val_loss: 0.7456 - val_accuracy: 0.8306\n",
      "Epoch 88/150\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 0.7021 - accuracy: 0.8484 - val_loss: 0.8164 - val_accuracy: 0.8146\n",
      "Epoch 89/150\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 0.7091 - accuracy: 0.8465 - val_loss: 0.7643 - val_accuracy: 0.8296\n",
      "Epoch 90/150\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 0.7013 - accuracy: 0.8475 - val_loss: 0.7454 - val_accuracy: 0.8388\n",
      "Epoch 91/150\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 0.7000 - accuracy: 0.8500 - val_loss: 0.7605 - val_accuracy: 0.8356\n",
      "Epoch 92/150\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 0.7008 - accuracy: 0.8478 - val_loss: 0.7808 - val_accuracy: 0.8287\n",
      "Epoch 93/150\n",
      "391/391 [==============================] - 17s 44ms/step - loss: 0.7058 - accuracy: 0.8480 - val_loss: 0.7372 - val_accuracy: 0.8396\n",
      "Epoch 94/150\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 0.7026 - accuracy: 0.8477 - val_loss: 0.8677 - val_accuracy: 0.8045\n",
      "Epoch 95/150\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 0.6959 - accuracy: 0.8501 - val_loss: 0.8070 - val_accuracy: 0.8147\n",
      "Epoch 96/150\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 0.7015 - accuracy: 0.8495 - val_loss: 0.7298 - val_accuracy: 0.8370\n",
      "Epoch 97/150\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 0.7006 - accuracy: 0.8496 - val_loss: 0.8485 - val_accuracy: 0.8132\n",
      "Epoch 98/150\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 0.6993 - accuracy: 0.8485 - val_loss: 0.7765 - val_accuracy: 0.8224\n",
      "Epoch 99/150\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 0.7040 - accuracy: 0.8477 - val_loss: 0.8926 - val_accuracy: 0.7928\n",
      "Epoch 100/150\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 0.7019 - accuracy: 0.8484 - val_loss: 0.7466 - val_accuracy: 0.8374\n",
      "Epoch 101/150\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 0.6971 - accuracy: 0.8482 - val_loss: 0.7691 - val_accuracy: 0.8300\n",
      "Epoch 102/150\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 0.6983 - accuracy: 0.8480 - val_loss: 0.9372 - val_accuracy: 0.7925\n",
      "Epoch 103/150\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 0.6954 - accuracy: 0.8508 - val_loss: 0.8774 - val_accuracy: 0.7997\n",
      "Epoch 104/150\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 0.6949 - accuracy: 0.8495 - val_loss: 0.7363 - val_accuracy: 0.8418\n",
      "Epoch 105/150\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 0.7005 - accuracy: 0.8484 - val_loss: 0.7831 - val_accuracy: 0.8202\n",
      "Epoch 106/150\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 0.6942 - accuracy: 0.8500 - val_loss: 0.7382 - val_accuracy: 0.8379\n",
      "Epoch 107/150\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 0.6998 - accuracy: 0.8486 - val_loss: 0.8973 - val_accuracy: 0.7915\n",
      "Epoch 108/150\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 0.6915 - accuracy: 0.8527 - val_loss: 0.9145 - val_accuracy: 0.7952\n",
      "Epoch 109/150\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 0.6929 - accuracy: 0.8510 - val_loss: 0.9132 - val_accuracy: 0.7841\n",
      "Epoch 110/150\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 0.6896 - accuracy: 0.8529 - val_loss: 0.7976 - val_accuracy: 0.8197\n",
      "Epoch 111/150\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 0.6886 - accuracy: 0.8514 - val_loss: 0.7487 - val_accuracy: 0.8353\n",
      "Epoch 112/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391/391 [==============================] - 17s 43ms/step - loss: 0.6896 - accuracy: 0.8500 - val_loss: 1.0025 - val_accuracy: 0.7650\n",
      "Epoch 113/150\n",
      "391/391 [==============================] - 16s 42ms/step - loss: 0.6869 - accuracy: 0.8527 - val_loss: 0.7886 - val_accuracy: 0.8253\n",
      "Epoch 114/150\n",
      "391/391 [==============================] - 16s 42ms/step - loss: 0.6889 - accuracy: 0.8524 - val_loss: 0.7641 - val_accuracy: 0.8301\n",
      "Epoch 115/150\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 0.6919 - accuracy: 0.8509 - val_loss: 0.7168 - val_accuracy: 0.8433\n",
      "Epoch 116/150\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 0.6898 - accuracy: 0.8495 - val_loss: 0.8875 - val_accuracy: 0.7983\n",
      "Epoch 117/150\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 0.6867 - accuracy: 0.8521 - val_loss: 0.7706 - val_accuracy: 0.8262\n",
      "Epoch 118/150\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 0.6877 - accuracy: 0.8506 - val_loss: 0.7958 - val_accuracy: 0.8191\n",
      "Epoch 119/150\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 0.6842 - accuracy: 0.8534 - val_loss: 0.7677 - val_accuracy: 0.8275\n",
      "Epoch 120/150\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 0.6885 - accuracy: 0.8507 - val_loss: 0.8568 - val_accuracy: 0.7981\n",
      "Epoch 121/150\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 0.6820 - accuracy: 0.8528 - val_loss: 0.8876 - val_accuracy: 0.7989\n",
      "Epoch 122/150\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 0.6847 - accuracy: 0.8532 - val_loss: 0.8003 - val_accuracy: 0.8188\n",
      "Epoch 123/150\n",
      "391/391 [==============================] - 17s 44ms/step - loss: 0.6839 - accuracy: 0.8524 - val_loss: 0.8202 - val_accuracy: 0.8220\n",
      "Epoch 124/150\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 0.6853 - accuracy: 0.8515 - val_loss: 0.8610 - val_accuracy: 0.7957\n",
      "Epoch 125/150\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 0.6830 - accuracy: 0.8538 - val_loss: 0.7508 - val_accuracy: 0.8331\n",
      "Epoch 126/150\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 0.6831 - accuracy: 0.8521 - val_loss: 0.7524 - val_accuracy: 0.8344\n",
      "Epoch 127/150\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 0.6859 - accuracy: 0.8506 - val_loss: 0.8007 - val_accuracy: 0.8169\n",
      "Epoch 128/150\n",
      "391/391 [==============================] - 19s 48ms/step - loss: 0.6764 - accuracy: 0.8532 - val_loss: 0.7825 - val_accuracy: 0.8262\n",
      "Epoch 129/150\n",
      "201/391 [==============>...............] - ETA: 8s - loss: 0.6883 - accuracy: 0.8505WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-47-0dc01d2b8c16>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m                       \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m                       \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcallback_es\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m                       epochs=150)\n\u001b[0m",
      "\u001b[0;32m~/.conda/envs/ml-gpu/lib/python3.7/site-packages/tensorflow_core/python/util/deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    322\u001b[0m               \u001b[0;34m'in a future version'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'after %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mdate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m               instructions)\n\u001b[0;32m--> 324\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    325\u001b[0m     return tf_decorator.make_decorator(\n\u001b[1;32m    326\u001b[0m         \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'deprecated'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/ml-gpu/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1304\u001b[0m         \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1305\u001b[0m         \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1306\u001b[0;31m         initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1307\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1308\u001b[0m   @deprecation.deprecated(\n",
      "\u001b[0;32m~/.conda/envs/ml-gpu/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    817\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 819\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    820\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m~/.conda/envs/ml-gpu/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    340\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m                 \u001b[0mtraining_context\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining_context\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 342\u001b[0;31m                 total_epochs=epochs)\n\u001b[0m\u001b[1;32m    343\u001b[0m             \u001b[0mcbks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/ml-gpu/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[0;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[1;32m    126\u001b[0m         step=step, mode=mode, size=current_batch_size) as batch_logs:\n\u001b[1;32m    127\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m         \u001b[0;31m# TODO(kaftan): File bug about tf function and errors.OutOfRangeError?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/ml-gpu/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py\u001b[0m in \u001b[0;36mexecution_function\u001b[0;34m(input_fn)\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0;31m# `numpy` translates Tensors to values in Eager mode.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m     return nest.map_structure(_non_none_constant_value,\n\u001b[0;32m---> 98\u001b[0;31m                               distributed_function(input_fn))\n\u001b[0m\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/ml-gpu/lib/python3.7/site-packages/tensorflow_core/python/util/nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m    566\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    567\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 568\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    569\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    570\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/ml-gpu/lib/python3.7/site-packages/tensorflow_core/python/util/nest.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    566\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    567\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 568\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    569\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    570\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/ml-gpu/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py\u001b[0m in \u001b[0;36m_non_none_constant_value\u001b[0;34m(v)\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_non_none_constant_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m   \u001b[0mconstant_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtensor_util\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstant_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mconstant_value\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mconstant_value\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/ml-gpu/lib/python3.7/site-packages/tensorflow_core/python/framework/tensor_util.py\u001b[0m in \u001b[0;36mconstant_value\u001b[0;34m(tensor, partial)\u001b[0m\n\u001b[1;32m    820\u001b[0m   \"\"\"\n\u001b[1;32m    821\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEagerTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 822\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    823\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    824\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/ml-gpu/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py\u001b[0m in \u001b[0;36mnumpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    940\u001b[0m     \"\"\"\n\u001b[1;32m    941\u001b[0m     \u001b[0;31m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 942\u001b[0;31m     \u001b[0mmaybe_arr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    943\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_arr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/ml-gpu/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py\u001b[0m in \u001b[0;36m_numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    906\u001b[0m     \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    907\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 908\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    909\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    910\u001b[0m       \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model_2.fit_generator(image_generator.flow(x_train, y_train, batch_size=128),\n",
    "                      validation_data=(x_test, y_test),\n",
    "                      callbacks=[callback_es],\n",
    "                      epochs=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2.save_weights('./checkpoints/my_checkpoint')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (ml-gpu)",
   "language": "python",
   "name": "ml-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
