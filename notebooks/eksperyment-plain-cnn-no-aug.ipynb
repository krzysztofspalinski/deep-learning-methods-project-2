{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "from plain_cnn_experiment import model_1, model_2, model_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train),(x_test, y_test) = cifar10.load_data() \n",
    "\n",
    "x_train_orig = x_train / 255\n",
    "x_test = x_test / 255\n",
    "\n",
    "y_train_orig = tf.keras.utils.to_categorical(y_train, num_classes=10)\n",
    "y_test = tf.keras.utils.to_categorical(y_test, num_classes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model_1(results, x_train, x_test, y_train, y_test):\n",
    "    results['model_1'] = []\n",
    "    for iteration in range(1, 11):\n",
    "        \n",
    "        model_name = f'model_1_{iteration}'\n",
    "        \n",
    "        x_train, x_valid, y_train, y_valid = train_test_split(x_train_orig, y_train_orig, test_size=0.05)\n",
    "                \n",
    "        print('##################################')\n",
    "        print('')\n",
    "        print(f'Training {model_name}:')\n",
    "        print('')\n",
    "        \n",
    "        model = model_1.get_model()\n",
    "        \n",
    "        model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "        callback_earlystop = tf.keras.callbacks.EarlyStopping(patience=20,\n",
    "                                               monitor='val_loss',\n",
    "                                               mode='auto',\n",
    "                                               restore_best_weights=True)\n",
    "        \n",
    "        model.fit(x_train, y_train, batch_size=128,\n",
    "                      validation_data=(x_valid, y_valid),\n",
    "                      callbacks=[callback_earlystop],\n",
    "                      verbose=1,\n",
    "                      epochs=150)\n",
    "        \n",
    "        model.save(f'./models/no_aug/{model_name}.h5')\n",
    "        \n",
    "        y_proba = model.predict(x_test)\n",
    "        y_hat = np.zeros_like(y_proba)\n",
    "        y_hat[np.arange(y_proba.shape[0]), np.argmax(y_proba, axis=1)] = 1\n",
    "\n",
    "        model_acc = accuracy_score(y_hat, y_test)\n",
    "        results['model_1'].append(model_acc)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##################################\n",
      "\n",
      "Training model_1_1:\n",
      "\n",
      "Train on 47500 samples, validate on 2500 samples\n",
      "Epoch 1/150\n",
      "47500/47500 [==============================] - 9s 191us/sample - loss: 1.5210 - accuracy: 0.5076 - val_loss: 2.1586 - val_accuracy: 0.3212\n",
      "Epoch 2/150\n",
      "47500/47500 [==============================] - 6s 134us/sample - loss: 1.0807 - accuracy: 0.6730 - val_loss: 1.2290 - val_accuracy: 0.6372\n",
      "Epoch 3/150\n",
      "47500/47500 [==============================] - 7s 143us/sample - loss: 0.8831 - accuracy: 0.7407 - val_loss: 1.0064 - val_accuracy: 0.7184\n",
      "Epoch 4/150\n",
      "47500/47500 [==============================] - 7s 146us/sample - loss: 0.7559 - accuracy: 0.7835 - val_loss: 0.9472 - val_accuracy: 0.7244\n",
      "Epoch 5/150\n",
      "47500/47500 [==============================] - 7s 140us/sample - loss: 0.6595 - accuracy: 0.8178 - val_loss: 0.8928 - val_accuracy: 0.7520\n",
      "Epoch 6/150\n",
      "47500/47500 [==============================] - 7s 142us/sample - loss: 0.5887 - accuracy: 0.8439 - val_loss: 0.9182 - val_accuracy: 0.7580\n",
      "Epoch 7/150\n",
      "47500/47500 [==============================] - 8s 158us/sample - loss: 0.5271 - accuracy: 0.8677 - val_loss: 1.0111 - val_accuracy: 0.7376\n",
      "Epoch 8/150\n",
      "47500/47500 [==============================] - 7s 142us/sample - loss: 0.4865 - accuracy: 0.8840 - val_loss: 0.9473 - val_accuracy: 0.7672\n",
      "Epoch 9/150\n",
      "47500/47500 [==============================] - 7s 141us/sample - loss: 0.4318 - accuracy: 0.9057 - val_loss: 1.0361 - val_accuracy: 0.7520\n",
      "Epoch 10/150\n",
      "47500/47500 [==============================] - 7s 138us/sample - loss: 0.4164 - accuracy: 0.9141 - val_loss: 1.0846 - val_accuracy: 0.7644\n",
      "Epoch 11/150\n",
      "47500/47500 [==============================] - 7s 138us/sample - loss: 0.3796 - accuracy: 0.9290 - val_loss: 1.1279 - val_accuracy: 0.7548\n",
      "Epoch 12/150\n",
      "47500/47500 [==============================] - 7s 140us/sample - loss: 0.3825 - accuracy: 0.9313 - val_loss: 1.0852 - val_accuracy: 0.7624\n",
      "Epoch 13/150\n",
      "47500/47500 [==============================] - 7s 140us/sample - loss: 0.3565 - accuracy: 0.9430 - val_loss: 1.1236 - val_accuracy: 0.7696\n",
      "Epoch 14/150\n",
      "47500/47500 [==============================] - 7s 140us/sample - loss: 0.3405 - accuracy: 0.9503 - val_loss: 1.1776 - val_accuracy: 0.7660\n",
      "Epoch 15/150\n",
      "47500/47500 [==============================] - 7s 141us/sample - loss: 0.3466 - accuracy: 0.9498 - val_loss: 1.1883 - val_accuracy: 0.7592\n",
      "Epoch 16/150\n",
      "47500/47500 [==============================] - 7s 141us/sample - loss: 0.3344 - accuracy: 0.9555 - val_loss: 1.3423 - val_accuracy: 0.7456\n",
      "Epoch 17/150\n",
      "47500/47500 [==============================] - 7s 139us/sample - loss: 0.3500 - accuracy: 0.9530 - val_loss: 1.2718 - val_accuracy: 0.7720\n",
      "Epoch 18/150\n",
      "47500/47500 [==============================] - 7s 140us/sample - loss: 0.3167 - accuracy: 0.9651 - val_loss: 1.3146 - val_accuracy: 0.7648\n",
      "Epoch 19/150\n",
      "47500/47500 [==============================] - 7s 138us/sample - loss: 0.3481 - accuracy: 0.9564 - val_loss: 1.2961 - val_accuracy: 0.7600\n",
      "Epoch 20/150\n",
      "47500/47500 [==============================] - 7s 138us/sample - loss: 0.3206 - accuracy: 0.9655 - val_loss: 1.2914 - val_accuracy: 0.7768\n",
      "Epoch 21/150\n",
      "47500/47500 [==============================] - 7s 138us/sample - loss: 0.3255 - accuracy: 0.9648 - val_loss: 1.3463 - val_accuracy: 0.7676\n",
      "Epoch 22/150\n",
      "47500/47500 [==============================] - 7s 139us/sample - loss: 0.3105 - accuracy: 0.9712 - val_loss: 1.2840 - val_accuracy: 0.7756\n",
      "Epoch 23/150\n",
      "47500/47500 [==============================] - 7s 140us/sample - loss: 0.3179 - accuracy: 0.9675 - val_loss: 1.3400 - val_accuracy: 0.7680\n",
      "Epoch 24/150\n",
      "47500/47500 [==============================] - 7s 143us/sample - loss: 0.3168 - accuracy: 0.9686 - val_loss: 1.2843 - val_accuracy: 0.7696\n",
      "Epoch 25/150\n",
      "47500/47500 [==============================] - 7s 141us/sample - loss: 0.3192 - accuracy: 0.9684 - val_loss: 1.2871 - val_accuracy: 0.7772\n",
      "##################################\n",
      "\n",
      "Training model_1_2:\n",
      "\n",
      "Train on 47500 samples, validate on 2500 samples\n",
      "Epoch 1/150\n",
      "47500/47500 [==============================] - 8s 171us/sample - loss: 1.5050 - accuracy: 0.5161 - val_loss: 1.6927 - val_accuracy: 0.4520\n",
      "Epoch 2/150\n",
      "47500/47500 [==============================] - 7s 145us/sample - loss: 1.0580 - accuracy: 0.6790 - val_loss: 1.2487 - val_accuracy: 0.6200\n",
      "Epoch 3/150\n",
      "47500/47500 [==============================] - 7s 147us/sample - loss: 0.8678 - accuracy: 0.7465 - val_loss: 1.0997 - val_accuracy: 0.6732\n",
      "Epoch 4/150\n",
      "47500/47500 [==============================] - 7s 149us/sample - loss: 0.7303 - accuracy: 0.7955 - val_loss: 0.8332 - val_accuracy: 0.7676\n",
      "Epoch 5/150\n",
      "47500/47500 [==============================] - 7s 146us/sample - loss: 0.6426 - accuracy: 0.8248 - val_loss: 0.8689 - val_accuracy: 0.7552\n",
      "Epoch 6/150\n",
      "47500/47500 [==============================] - 7s 143us/sample - loss: 0.5705 - accuracy: 0.8500 - val_loss: 0.8561 - val_accuracy: 0.7632\n",
      "Epoch 7/150\n",
      "47500/47500 [==============================] - 7s 140us/sample - loss: 0.4993 - accuracy: 0.8769 - val_loss: 0.8833 - val_accuracy: 0.7808\n",
      "Epoch 8/150\n",
      "47500/47500 [==============================] - 7s 141us/sample - loss: 0.4574 - accuracy: 0.8941 - val_loss: 0.9993 - val_accuracy: 0.7528\n",
      "Epoch 9/150\n",
      "47500/47500 [==============================] - 7s 150us/sample - loss: 0.4186 - accuracy: 0.9097 - val_loss: 1.0297 - val_accuracy: 0.7628\n",
      "Epoch 10/150\n",
      "47500/47500 [==============================] - 7s 142us/sample - loss: 0.4069 - accuracy: 0.9171 - val_loss: 1.0429 - val_accuracy: 0.7568\n",
      "Epoch 11/150\n",
      "47500/47500 [==============================] - 7s 141us/sample - loss: 0.3854 - accuracy: 0.9287 - val_loss: 1.0709 - val_accuracy: 0.7644\n",
      "Epoch 12/150\n",
      "47500/47500 [==============================] - 6s 131us/sample - loss: 0.3450 - accuracy: 0.9438 - val_loss: 1.1022 - val_accuracy: 0.7724\n",
      "Epoch 13/150\n",
      "47500/47500 [==============================] - 7s 138us/sample - loss: 0.3421 - accuracy: 0.9460 - val_loss: 1.1049 - val_accuracy: 0.7536\n",
      "Epoch 14/150\n",
      "47500/47500 [==============================] - 7s 143us/sample - loss: 0.3491 - accuracy: 0.9473 - val_loss: 1.1820 - val_accuracy: 0.7616\n",
      "Epoch 15/150\n",
      "47500/47500 [==============================] - 7s 142us/sample - loss: 0.3257 - accuracy: 0.9555 - val_loss: 1.1992 - val_accuracy: 0.7632\n",
      "Epoch 16/150\n",
      "47500/47500 [==============================] - 7s 141us/sample - loss: 0.3137 - accuracy: 0.9610 - val_loss: 1.3121 - val_accuracy: 0.7552\n",
      "Epoch 17/150\n",
      "47500/47500 [==============================] - 6s 129us/sample - loss: 0.3437 - accuracy: 0.9525 - val_loss: 1.3696 - val_accuracy: 0.7404\n",
      "Epoch 18/150\n",
      "47500/47500 [==============================] - 6s 129us/sample - loss: 0.3232 - accuracy: 0.9619 - val_loss: 1.3157 - val_accuracy: 0.7688\n",
      "Epoch 19/150\n",
      "47500/47500 [==============================] - 6s 129us/sample - loss: 0.3157 - accuracy: 0.9650 - val_loss: 1.2198 - val_accuracy: 0.7640\n",
      "Epoch 20/150\n",
      "47500/47500 [==============================] - 6s 129us/sample - loss: 0.3178 - accuracy: 0.9647 - val_loss: 1.1838 - val_accuracy: 0.7740\n",
      "Epoch 21/150\n",
      "47500/47500 [==============================] - 6s 132us/sample - loss: 0.3175 - accuracy: 0.9658 - val_loss: 1.3061 - val_accuracy: 0.7620\n",
      "Epoch 22/150\n",
      "47500/47500 [==============================] - 6s 133us/sample - loss: 0.3034 - accuracy: 0.9706 - val_loss: 1.3498 - val_accuracy: 0.7688\n",
      "Epoch 23/150\n",
      "47500/47500 [==============================] - 7s 139us/sample - loss: 0.3235 - accuracy: 0.9656 - val_loss: 1.3629 - val_accuracy: 0.7560\n",
      "Epoch 24/150\n",
      "47500/47500 [==============================] - 6s 133us/sample - loss: 0.3092 - accuracy: 0.9704 - val_loss: 1.1957 - val_accuracy: 0.7808\n",
      "##################################\n",
      "\n",
      "Training model_1_3:\n",
      "\n",
      "Train on 47500 samples, validate on 2500 samples\n",
      "Epoch 1/150\n",
      "47500/47500 [==============================] - 7s 155us/sample - loss: 1.5100 - accuracy: 0.5132 - val_loss: 2.2721 - val_accuracy: 0.3600\n",
      "Epoch 2/150\n",
      "47500/47500 [==============================] - 6s 133us/sample - loss: 1.0771 - accuracy: 0.6713 - val_loss: 1.0572 - val_accuracy: 0.6784\n",
      "Epoch 3/150\n",
      "47500/47500 [==============================] - 6s 134us/sample - loss: 0.8823 - accuracy: 0.7432 - val_loss: 0.9905 - val_accuracy: 0.7060\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/150\n",
      "47500/47500 [==============================] - 6s 133us/sample - loss: 0.7537 - accuracy: 0.7842 - val_loss: 0.8957 - val_accuracy: 0.7452\n",
      "Epoch 5/150\n",
      "47500/47500 [==============================] - 6s 133us/sample - loss: 0.6573 - accuracy: 0.8185 - val_loss: 0.8993 - val_accuracy: 0.7436\n",
      "Epoch 6/150\n",
      "47500/47500 [==============================] - 6s 135us/sample - loss: 0.5812 - accuracy: 0.8452 - val_loss: 1.0142 - val_accuracy: 0.7300\n",
      "Epoch 7/150\n",
      "47500/47500 [==============================] - 6s 129us/sample - loss: 0.5219 - accuracy: 0.8698 - val_loss: 0.9442 - val_accuracy: 0.7664\n",
      "Epoch 8/150\n",
      "47500/47500 [==============================] - 6s 131us/sample - loss: 0.4795 - accuracy: 0.8856 - val_loss: 1.0374 - val_accuracy: 0.7452\n",
      "Epoch 9/150\n",
      "47500/47500 [==============================] - 7s 143us/sample - loss: 0.4394 - accuracy: 0.9042 - val_loss: 0.9573 - val_accuracy: 0.7696\n",
      "Epoch 10/150\n",
      "47500/47500 [==============================] - 7s 137us/sample - loss: 0.4038 - accuracy: 0.9181 - val_loss: 1.0938 - val_accuracy: 0.7548\n",
      "Epoch 11/150\n",
      "47500/47500 [==============================] - 7s 148us/sample - loss: 0.3789 - accuracy: 0.9307 - val_loss: 1.0652 - val_accuracy: 0.7740\n",
      "Epoch 12/150\n",
      "47500/47500 [==============================] - 6s 135us/sample - loss: 0.3647 - accuracy: 0.9381 - val_loss: 1.0811 - val_accuracy: 0.7656\n",
      "Epoch 13/150\n",
      "47500/47500 [==============================] - 6s 136us/sample - loss: 0.3481 - accuracy: 0.9445 - val_loss: 1.1188 - val_accuracy: 0.7708\n",
      "Epoch 14/150\n",
      "47500/47500 [==============================] - 7s 137us/sample - loss: 0.3376 - accuracy: 0.9487 - val_loss: 1.1845 - val_accuracy: 0.7652\n",
      "Epoch 15/150\n",
      "47500/47500 [==============================] - 7s 137us/sample - loss: 0.3416 - accuracy: 0.9512 - val_loss: 1.2550 - val_accuracy: 0.7688\n",
      "Epoch 16/150\n",
      "47500/47500 [==============================] - 7s 139us/sample - loss: 0.3353 - accuracy: 0.9545 - val_loss: 1.1666 - val_accuracy: 0.7740\n",
      "Epoch 17/150\n",
      "47500/47500 [==============================] - 7s 138us/sample - loss: 0.3171 - accuracy: 0.9616 - val_loss: 1.2951 - val_accuracy: 0.7636\n",
      "Epoch 18/150\n",
      "47500/47500 [==============================] - 7s 138us/sample - loss: 0.3230 - accuracy: 0.9611 - val_loss: 1.2690 - val_accuracy: 0.7636\n",
      "Epoch 19/150\n",
      "47500/47500 [==============================] - 7s 138us/sample - loss: 0.3425 - accuracy: 0.9556 - val_loss: 1.2479 - val_accuracy: 0.7680\n",
      "Epoch 20/150\n",
      "47500/47500 [==============================] - 7s 140us/sample - loss: 0.3177 - accuracy: 0.9659 - val_loss: 1.2773 - val_accuracy: 0.7716\n",
      "Epoch 21/150\n",
      "47500/47500 [==============================] - 7s 139us/sample - loss: 0.3182 - accuracy: 0.9660 - val_loss: 1.2564 - val_accuracy: 0.7704\n",
      "Epoch 22/150\n",
      "47500/47500 [==============================] - 7s 139us/sample - loss: 0.3274 - accuracy: 0.9644 - val_loss: 1.3354 - val_accuracy: 0.7744\n",
      "Epoch 23/150\n",
      "47500/47500 [==============================] - 7s 140us/sample - loss: 0.3351 - accuracy: 0.9637 - val_loss: 1.3255 - val_accuracy: 0.7832\n",
      "Epoch 24/150\n",
      "47500/47500 [==============================] - 7s 140us/sample - loss: 0.3175 - accuracy: 0.9696 - val_loss: 1.4261 - val_accuracy: 0.7528\n",
      "##################################\n",
      "\n",
      "Training model_1_4:\n",
      "\n",
      "Train on 47500 samples, validate on 2500 samples\n",
      "Epoch 1/150\n",
      "47500/47500 [==============================] - 8s 160us/sample - loss: 1.4806 - accuracy: 0.5191 - val_loss: 2.0415 - val_accuracy: 0.3584\n",
      "Epoch 2/150\n",
      "47500/47500 [==============================] - 7s 140us/sample - loss: 1.0511 - accuracy: 0.6827 - val_loss: 1.0965 - val_accuracy: 0.6724\n",
      "Epoch 3/150\n",
      "47500/47500 [==============================] - 7s 140us/sample - loss: 0.8653 - accuracy: 0.7456 - val_loss: 1.0255 - val_accuracy: 0.7020\n",
      "Epoch 4/150\n",
      "47500/47500 [==============================] - 7s 140us/sample - loss: 0.7447 - accuracy: 0.7881 - val_loss: 0.9479 - val_accuracy: 0.7324\n",
      "Epoch 5/150\n",
      "47500/47500 [==============================] - 7s 140us/sample - loss: 0.6522 - accuracy: 0.8190 - val_loss: 0.9089 - val_accuracy: 0.7436\n",
      "Epoch 6/150\n",
      "47500/47500 [==============================] - 7s 140us/sample - loss: 0.5783 - accuracy: 0.8483 - val_loss: 0.9152 - val_accuracy: 0.7448\n",
      "Epoch 7/150\n",
      "47500/47500 [==============================] - 7s 139us/sample - loss: 0.5228 - accuracy: 0.8686 - val_loss: 1.0137 - val_accuracy: 0.7388\n",
      "Epoch 8/150\n",
      "47500/47500 [==============================] - 7s 140us/sample - loss: 0.4625 - accuracy: 0.8911 - val_loss: 1.0035 - val_accuracy: 0.7576\n",
      "Epoch 9/150\n",
      "47500/47500 [==============================] - 7s 140us/sample - loss: 0.4349 - accuracy: 0.9036 - val_loss: 1.0194 - val_accuracy: 0.7576\n",
      "Epoch 10/150\n",
      "47500/47500 [==============================] - 7s 139us/sample - loss: 0.3927 - accuracy: 0.9209 - val_loss: 1.0237 - val_accuracy: 0.7732\n",
      "Epoch 11/150\n",
      "47500/47500 [==============================] - 7s 139us/sample - loss: 0.3768 - accuracy: 0.9297 - val_loss: 1.0643 - val_accuracy: 0.7588\n",
      "Epoch 12/150\n",
      "47500/47500 [==============================] - 7s 140us/sample - loss: 0.3698 - accuracy: 0.9340 - val_loss: 1.0287 - val_accuracy: 0.7672\n",
      "Epoch 13/150\n",
      "47500/47500 [==============================] - 7s 140us/sample - loss: 0.3435 - accuracy: 0.9451 - val_loss: 1.1636 - val_accuracy: 0.7688\n",
      "Epoch 14/150\n",
      "47500/47500 [==============================] - 7s 139us/sample - loss: 0.3419 - accuracy: 0.9484 - val_loss: 1.1684 - val_accuracy: 0.7660\n",
      "Epoch 15/150\n",
      "47500/47500 [==============================] - 7s 139us/sample - loss: 0.3373 - accuracy: 0.9516 - val_loss: 1.1579 - val_accuracy: 0.7776\n",
      "Epoch 16/150\n",
      "47500/47500 [==============================] - 7s 140us/sample - loss: 0.3440 - accuracy: 0.9535 - val_loss: 1.2301 - val_accuracy: 0.7680\n",
      "Epoch 17/150\n",
      "47500/47500 [==============================] - 7s 140us/sample - loss: 0.3209 - accuracy: 0.9607 - val_loss: 1.2593 - val_accuracy: 0.7588\n",
      "Epoch 18/150\n",
      "47500/47500 [==============================] - 7s 140us/sample - loss: 0.3337 - accuracy: 0.9580 - val_loss: 1.2486 - val_accuracy: 0.7568\n",
      "Epoch 19/150\n",
      "47500/47500 [==============================] - 7s 139us/sample - loss: 0.3056 - accuracy: 0.9682 - val_loss: 1.3953 - val_accuracy: 0.7604\n",
      "Epoch 20/150\n",
      "47500/47500 [==============================] - 7s 139us/sample - loss: 0.3156 - accuracy: 0.9657 - val_loss: 1.3508 - val_accuracy: 0.7600\n",
      "Epoch 21/150\n",
      "47500/47500 [==============================] - 7s 140us/sample - loss: 0.3171 - accuracy: 0.9665 - val_loss: 1.2153 - val_accuracy: 0.7804\n",
      "Epoch 22/150\n",
      "47500/47500 [==============================] - 7s 140us/sample - loss: 0.3126 - accuracy: 0.9675 - val_loss: 1.2570 - val_accuracy: 0.7736\n",
      "Epoch 23/150\n",
      "47500/47500 [==============================] - 7s 140us/sample - loss: 0.3105 - accuracy: 0.9695 - val_loss: 1.3476 - val_accuracy: 0.7792\n",
      "Epoch 24/150\n",
      "47500/47500 [==============================] - 7s 141us/sample - loss: 0.3167 - accuracy: 0.9675 - val_loss: 1.2654 - val_accuracy: 0.7768\n",
      "Epoch 25/150\n",
      "47500/47500 [==============================] - 7s 140us/sample - loss: 0.3101 - accuracy: 0.9706 - val_loss: 1.3154 - val_accuracy: 0.7820\n",
      "##################################\n",
      "\n",
      "Training model_1_5:\n",
      "\n",
      "Train on 47500 samples, validate on 2500 samples\n",
      "Epoch 1/150\n",
      "47500/47500 [==============================] - 8s 176us/sample - loss: 1.5088 - accuracy: 0.5111 - val_loss: 1.8246 - val_accuracy: 0.4224\n",
      "Epoch 2/150\n",
      "47500/47500 [==============================] - 7s 138us/sample - loss: 1.0716 - accuracy: 0.6745 - val_loss: 1.0829 - val_accuracy: 0.6740\n",
      "Epoch 3/150\n",
      "47500/47500 [==============================] - 7s 139us/sample - loss: 0.8689 - accuracy: 0.7465 - val_loss: 0.9083 - val_accuracy: 0.7376\n",
      "Epoch 4/150\n",
      "47500/47500 [==============================] - 7s 138us/sample - loss: 0.7414 - accuracy: 0.7904 - val_loss: 0.9436 - val_accuracy: 0.7280\n",
      "Epoch 5/150\n",
      "47500/47500 [==============================] - 7s 138us/sample - loss: 0.6567 - accuracy: 0.8208 - val_loss: 0.8783 - val_accuracy: 0.7552\n",
      "Epoch 6/150\n",
      "47500/47500 [==============================] - 7s 138us/sample - loss: 0.5704 - accuracy: 0.8523 - val_loss: 1.0351 - val_accuracy: 0.7228\n",
      "Epoch 7/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47500/47500 [==============================] - 6s 133us/sample - loss: 0.5137 - accuracy: 0.8728 - val_loss: 0.8963 - val_accuracy: 0.7624\n",
      "Epoch 8/150\n",
      "47500/47500 [==============================] - 6s 135us/sample - loss: 0.4647 - accuracy: 0.8911 - val_loss: 0.9662 - val_accuracy: 0.7568\n",
      "Epoch 9/150\n",
      "47500/47500 [==============================] - 6s 135us/sample - loss: 0.4236 - accuracy: 0.9088 - val_loss: 1.0706 - val_accuracy: 0.7596\n",
      "Epoch 10/150\n",
      "47500/47500 [==============================] - 7s 140us/sample - loss: 0.4056 - accuracy: 0.9170 - val_loss: 1.0066 - val_accuracy: 0.7708\n",
      "Epoch 11/150\n",
      "47500/47500 [==============================] - 7s 139us/sample - loss: 0.3777 - accuracy: 0.9292 - val_loss: 1.0178 - val_accuracy: 0.7760\n",
      "Epoch 12/150\n",
      "47500/47500 [==============================] - 7s 140us/sample - loss: 0.3636 - accuracy: 0.9373 - val_loss: 1.0618 - val_accuracy: 0.7804\n",
      "Epoch 13/150\n",
      "47500/47500 [==============================] - 7s 140us/sample - loss: 0.3521 - accuracy: 0.9444 - val_loss: 1.0717 - val_accuracy: 0.7700\n",
      "Epoch 14/150\n",
      "47500/47500 [==============================] - 7s 140us/sample - loss: 0.3340 - accuracy: 0.9516 - val_loss: 1.2214 - val_accuracy: 0.7680\n",
      "Epoch 15/150\n",
      "47500/47500 [==============================] - 7s 140us/sample - loss: 0.3241 - accuracy: 0.9563 - val_loss: 1.2419 - val_accuracy: 0.7636\n",
      "Epoch 16/150\n",
      "47500/47500 [==============================] - 7s 140us/sample - loss: 0.3400 - accuracy: 0.9527 - val_loss: 1.2815 - val_accuracy: 0.7584\n",
      "Epoch 17/150\n",
      "47500/47500 [==============================] - 7s 140us/sample - loss: 0.3239 - accuracy: 0.9590 - val_loss: 1.2382 - val_accuracy: 0.7708\n",
      "Epoch 18/150\n",
      "47500/47500 [==============================] - 7s 140us/sample - loss: 0.3225 - accuracy: 0.9620 - val_loss: 1.2472 - val_accuracy: 0.7796\n",
      "Epoch 19/150\n",
      "47500/47500 [==============================] - 7s 140us/sample - loss: 0.3338 - accuracy: 0.9599 - val_loss: 1.1871 - val_accuracy: 0.7740\n",
      "Epoch 20/150\n",
      "47500/47500 [==============================] - 7s 140us/sample - loss: 0.3213 - accuracy: 0.9644 - val_loss: 1.2828 - val_accuracy: 0.7680\n",
      "Epoch 21/150\n",
      "47500/47500 [==============================] - 7s 140us/sample - loss: 0.3378 - accuracy: 0.9589 - val_loss: 1.1936 - val_accuracy: 0.7816\n",
      "Epoch 22/150\n",
      "47500/47500 [==============================] - 7s 140us/sample - loss: 0.3136 - accuracy: 0.9692 - val_loss: 1.1866 - val_accuracy: 0.7736\n",
      "Epoch 23/150\n",
      "47500/47500 [==============================] - 7s 140us/sample - loss: 0.3090 - accuracy: 0.9709 - val_loss: 1.3143 - val_accuracy: 0.7708\n",
      "Epoch 24/150\n",
      "47500/47500 [==============================] - 7s 139us/sample - loss: 0.3236 - accuracy: 0.9668 - val_loss: 1.2734 - val_accuracy: 0.7776\n",
      "Epoch 25/150\n",
      "47500/47500 [==============================] - 7s 140us/sample - loss: 0.3088 - accuracy: 0.9718 - val_loss: 1.2467 - val_accuracy: 0.7812\n",
      "##################################\n",
      "\n",
      "Training model_1_6:\n",
      "\n",
      "Train on 47500 samples, validate on 2500 samples\n",
      "Epoch 1/150\n",
      "47500/47500 [==============================] - 8s 159us/sample - loss: 1.5419 - accuracy: 0.5012 - val_loss: 3.2027 - val_accuracy: 0.1940\n",
      "Epoch 2/150\n",
      "47500/47500 [==============================] - 7s 140us/sample - loss: 1.0730 - accuracy: 0.6723 - val_loss: 1.1386 - val_accuracy: 0.6620\n",
      "Epoch 3/150\n",
      "47500/47500 [==============================] - 7s 140us/sample - loss: 0.8824 - accuracy: 0.7380 - val_loss: 1.0022 - val_accuracy: 0.7028\n",
      "Epoch 4/150\n",
      "47500/47500 [==============================] - 7s 140us/sample - loss: 0.7541 - accuracy: 0.7839 - val_loss: 0.8983 - val_accuracy: 0.7388\n",
      "Epoch 5/150\n",
      "47500/47500 [==============================] - 7s 139us/sample - loss: 0.6575 - accuracy: 0.8176 - val_loss: 0.9778 - val_accuracy: 0.7240\n",
      "Epoch 6/150\n",
      "47500/47500 [==============================] - 7s 140us/sample - loss: 0.5801 - accuracy: 0.8452 - val_loss: 0.9466 - val_accuracy: 0.7352\n",
      "Epoch 7/150\n",
      "47500/47500 [==============================] - 7s 139us/sample - loss: 0.5175 - accuracy: 0.8712 - val_loss: 1.0912 - val_accuracy: 0.7284\n",
      "Epoch 8/150\n",
      "47500/47500 [==============================] - 7s 140us/sample - loss: 0.4647 - accuracy: 0.8913 - val_loss: 1.0340 - val_accuracy: 0.7500\n",
      "Epoch 9/150\n",
      "47500/47500 [==============================] - 7s 139us/sample - loss: 0.4310 - accuracy: 0.9070 - val_loss: 1.0372 - val_accuracy: 0.7572\n",
      "Epoch 10/150\n",
      "47500/47500 [==============================] - 7s 140us/sample - loss: 0.3935 - accuracy: 0.9218 - val_loss: 0.9492 - val_accuracy: 0.7768\n",
      "Epoch 11/150\n",
      "47500/47500 [==============================] - 7s 139us/sample - loss: 0.3706 - accuracy: 0.9317 - val_loss: 1.1433 - val_accuracy: 0.7532\n",
      "Epoch 12/150\n",
      "47500/47500 [==============================] - 7s 139us/sample - loss: 0.3573 - accuracy: 0.9399 - val_loss: 1.1612 - val_accuracy: 0.7572\n",
      "Epoch 13/150\n",
      "47500/47500 [==============================] - 7s 140us/sample - loss: 0.3475 - accuracy: 0.9454 - val_loss: 1.3524 - val_accuracy: 0.7384\n",
      "Epoch 14/150\n",
      "47500/47500 [==============================] - 7s 140us/sample - loss: 0.3513 - accuracy: 0.9464 - val_loss: 1.2665 - val_accuracy: 0.7520\n",
      "Epoch 15/150\n",
      "47500/47500 [==============================] - 7s 140us/sample - loss: 0.3249 - accuracy: 0.9567 - val_loss: 1.1682 - val_accuracy: 0.7800\n",
      "Epoch 16/150\n",
      "47500/47500 [==============================] - 7s 139us/sample - loss: 0.3293 - accuracy: 0.9572 - val_loss: 1.3465 - val_accuracy: 0.7500\n",
      "Epoch 17/150\n",
      "47500/47500 [==============================] - 7s 139us/sample - loss: 0.3387 - accuracy: 0.9555 - val_loss: 1.2914 - val_accuracy: 0.7592\n",
      "Epoch 18/150\n",
      "47500/47500 [==============================] - 7s 139us/sample - loss: 0.3252 - accuracy: 0.9600 - val_loss: 1.2036 - val_accuracy: 0.7824\n",
      "Epoch 19/150\n",
      "47500/47500 [==============================] - 7s 139us/sample - loss: 0.3164 - accuracy: 0.9639 - val_loss: 1.3578 - val_accuracy: 0.7564\n",
      "Epoch 20/150\n",
      "47500/47500 [==============================] - 7s 139us/sample - loss: 0.3052 - accuracy: 0.9687 - val_loss: 1.4012 - val_accuracy: 0.7508\n",
      "Epoch 21/150\n",
      "47500/47500 [==============================] - 7s 140us/sample - loss: 0.3272 - accuracy: 0.9620 - val_loss: 1.3017 - val_accuracy: 0.7612\n",
      "Epoch 22/150\n",
      "47500/47500 [==============================] - 7s 140us/sample - loss: 0.3240 - accuracy: 0.9644 - val_loss: 1.3080 - val_accuracy: 0.7724\n",
      "Epoch 23/150\n",
      "47500/47500 [==============================] - 7s 140us/sample - loss: 0.3127 - accuracy: 0.9685 - val_loss: 1.3874 - val_accuracy: 0.7584\n",
      "Epoch 24/150\n",
      "47500/47500 [==============================] - 7s 139us/sample - loss: 0.3236 - accuracy: 0.9659 - val_loss: 1.2442 - val_accuracy: 0.7800\n",
      "##################################\n",
      "\n",
      "Training model_1_7:\n",
      "\n",
      "Train on 47500 samples, validate on 2500 samples\n",
      "Epoch 1/150\n",
      "47500/47500 [==============================] - 8s 164us/sample - loss: 1.5194 - accuracy: 0.5108 - val_loss: 2.5612 - val_accuracy: 0.2332\n",
      "Epoch 2/150\n",
      "47500/47500 [==============================] - 7s 139us/sample - loss: 1.0762 - accuracy: 0.6727 - val_loss: 1.0629 - val_accuracy: 0.6768\n",
      "Epoch 3/150\n",
      "47500/47500 [==============================] - 7s 139us/sample - loss: 0.8842 - accuracy: 0.7402 - val_loss: 1.0172 - val_accuracy: 0.6936\n",
      "Epoch 4/150\n",
      "47500/47500 [==============================] - 7s 138us/sample - loss: 0.7559 - accuracy: 0.7835 - val_loss: 0.9516 - val_accuracy: 0.7284\n",
      "Epoch 5/150\n",
      "47500/47500 [==============================] - 7s 138us/sample - loss: 0.6700 - accuracy: 0.8149 - val_loss: 0.9651 - val_accuracy: 0.7224\n",
      "Epoch 6/150\n",
      "47500/47500 [==============================] - 7s 139us/sample - loss: 0.5938 - accuracy: 0.8432 - val_loss: 0.9242 - val_accuracy: 0.7452\n",
      "Epoch 7/150\n",
      "47500/47500 [==============================] - 7s 139us/sample - loss: 0.5333 - accuracy: 0.8640 - val_loss: 0.9252 - val_accuracy: 0.7444\n",
      "Epoch 8/150\n",
      "47500/47500 [==============================] - 7s 138us/sample - loss: 0.4813 - accuracy: 0.8861 - val_loss: 1.0647 - val_accuracy: 0.7292\n",
      "Epoch 9/150\n",
      "47500/47500 [==============================] - 7s 139us/sample - loss: 0.4398 - accuracy: 0.9032 - val_loss: 1.0052 - val_accuracy: 0.7508\n",
      "Epoch 10/150\n",
      "47500/47500 [==============================] - 7s 139us/sample - loss: 0.4280 - accuracy: 0.9098 - val_loss: 1.1048 - val_accuracy: 0.7384\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/150\n",
      "47500/47500 [==============================] - 6s 130us/sample - loss: 0.3937 - accuracy: 0.9250 - val_loss: 1.0503 - val_accuracy: 0.7732\n",
      "Epoch 12/150\n",
      "47500/47500 [==============================] - 6s 130us/sample - loss: 0.3727 - accuracy: 0.9350 - val_loss: 1.1239 - val_accuracy: 0.7608\n",
      "Epoch 13/150\n",
      "47500/47500 [==============================] - 6s 130us/sample - loss: 0.3478 - accuracy: 0.9455 - val_loss: 1.2173 - val_accuracy: 0.7456\n",
      "Epoch 14/150\n",
      "47500/47500 [==============================] - 6s 130us/sample - loss: 0.3643 - accuracy: 0.9419 - val_loss: 1.3202 - val_accuracy: 0.7520\n",
      "Epoch 15/150\n",
      "47500/47500 [==============================] - 6s 130us/sample - loss: 0.3567 - accuracy: 0.9461 - val_loss: 1.1741 - val_accuracy: 0.7676\n",
      "Epoch 16/150\n",
      "47500/47500 [==============================] - 6s 130us/sample - loss: 0.3423 - accuracy: 0.9532 - val_loss: 1.2906 - val_accuracy: 0.7672\n",
      "Epoch 17/150\n",
      "47500/47500 [==============================] - 6s 130us/sample - loss: 0.3290 - accuracy: 0.9591 - val_loss: 1.1749 - val_accuracy: 0.7768\n",
      "Epoch 18/150\n",
      "47500/47500 [==============================] - 6s 130us/sample - loss: 0.3163 - accuracy: 0.9637 - val_loss: 1.3490 - val_accuracy: 0.7504\n",
      "Epoch 19/150\n",
      "47500/47500 [==============================] - 6s 130us/sample - loss: 0.3333 - accuracy: 0.9589 - val_loss: 1.2468 - val_accuracy: 0.7664\n",
      "Epoch 20/150\n",
      "47500/47500 [==============================] - 6s 130us/sample - loss: 0.3208 - accuracy: 0.9640 - val_loss: 1.2792 - val_accuracy: 0.7620\n",
      "Epoch 21/150\n",
      "47500/47500 [==============================] - 6s 130us/sample - loss: 0.3196 - accuracy: 0.9661 - val_loss: 1.2995 - val_accuracy: 0.7576\n",
      "Epoch 22/150\n",
      "47500/47500 [==============================] - 6s 131us/sample - loss: 0.3273 - accuracy: 0.9645 - val_loss: 1.3489 - val_accuracy: 0.7484\n",
      "Epoch 23/150\n",
      "47500/47500 [==============================] - 6s 130us/sample - loss: 0.3323 - accuracy: 0.9649 - val_loss: 1.3289 - val_accuracy: 0.7580\n",
      "Epoch 24/150\n",
      "47500/47500 [==============================] - 6s 130us/sample - loss: 0.3125 - accuracy: 0.9698 - val_loss: 1.3846 - val_accuracy: 0.7436\n",
      "Epoch 25/150\n",
      "47500/47500 [==============================] - 6s 130us/sample - loss: 0.3371 - accuracy: 0.9637 - val_loss: 1.4291 - val_accuracy: 0.7612\n",
      "Epoch 26/150\n",
      "47500/47500 [==============================] - 6s 131us/sample - loss: 0.3245 - accuracy: 0.9681 - val_loss: 1.3075 - val_accuracy: 0.7616\n",
      "##################################\n",
      "\n",
      "Training model_1_8:\n",
      "\n",
      "Train on 47500 samples, validate on 2500 samples\n",
      "Epoch 1/150\n",
      "47500/47500 [==============================] - 7s 151us/sample - loss: 1.4923 - accuracy: 0.5206 - val_loss: 2.4776 - val_accuracy: 0.3184\n",
      "Epoch 2/150\n",
      "47500/47500 [==============================] - 6s 131us/sample - loss: 1.0377 - accuracy: 0.6878 - val_loss: 1.0052 - val_accuracy: 0.6980\n",
      "Epoch 3/150\n",
      "47500/47500 [==============================] - 6s 131us/sample - loss: 0.8559 - accuracy: 0.7501 - val_loss: 0.9543 - val_accuracy: 0.7076\n",
      "Epoch 4/150\n",
      "47500/47500 [==============================] - 6s 131us/sample - loss: 0.7344 - accuracy: 0.7918 - val_loss: 1.0934 - val_accuracy: 0.6844\n",
      "Epoch 5/150\n",
      "47500/47500 [==============================] - 6s 131us/sample - loss: 0.6395 - accuracy: 0.8264 - val_loss: 0.8906 - val_accuracy: 0.7440\n",
      "Epoch 6/150\n",
      "47500/47500 [==============================] - 6s 131us/sample - loss: 0.5768 - accuracy: 0.8480 - val_loss: 0.8614 - val_accuracy: 0.7632\n",
      "Epoch 7/150\n",
      "47500/47500 [==============================] - 6s 131us/sample - loss: 0.5079 - accuracy: 0.8747 - val_loss: 0.9137 - val_accuracy: 0.7604\n",
      "Epoch 8/150\n",
      "47500/47500 [==============================] - 6s 131us/sample - loss: 0.4653 - accuracy: 0.8922 - val_loss: 0.9475 - val_accuracy: 0.7632\n",
      "Epoch 9/150\n",
      "47500/47500 [==============================] - 6s 131us/sample - loss: 0.4280 - accuracy: 0.9082 - val_loss: 0.9925 - val_accuracy: 0.7504\n",
      "Epoch 10/150\n",
      "47500/47500 [==============================] - 6s 131us/sample - loss: 0.4134 - accuracy: 0.9152 - val_loss: 1.1180 - val_accuracy: 0.7416\n",
      "Epoch 11/150\n",
      "47500/47500 [==============================] - 6s 131us/sample - loss: 0.3714 - accuracy: 0.9329 - val_loss: 1.0333 - val_accuracy: 0.7736\n",
      "Epoch 12/150\n",
      "47500/47500 [==============================] - 6s 131us/sample - loss: 0.3503 - accuracy: 0.9429 - val_loss: 1.0660 - val_accuracy: 0.7820\n",
      "Epoch 13/150\n",
      "47500/47500 [==============================] - 6s 131us/sample - loss: 0.3433 - accuracy: 0.9459 - val_loss: 1.1171 - val_accuracy: 0.7508\n",
      "Epoch 14/150\n",
      "47500/47500 [==============================] - 6s 131us/sample - loss: 0.3383 - accuracy: 0.9511 - val_loss: 1.0982 - val_accuracy: 0.7656\n",
      "Epoch 15/150\n",
      "47500/47500 [==============================] - 6s 131us/sample - loss: 0.3392 - accuracy: 0.9515 - val_loss: 1.1787 - val_accuracy: 0.7624\n",
      "Epoch 16/150\n",
      "47500/47500 [==============================] - 6s 131us/sample - loss: 0.3284 - accuracy: 0.9570 - val_loss: 1.2877 - val_accuracy: 0.7416\n",
      "Epoch 17/150\n",
      "47500/47500 [==============================] - 6s 131us/sample - loss: 0.3359 - accuracy: 0.9572 - val_loss: 1.1994 - val_accuracy: 0.7784\n",
      "Epoch 18/150\n",
      "47500/47500 [==============================] - 7s 137us/sample - loss: 0.3297 - accuracy: 0.9596 - val_loss: 1.2030 - val_accuracy: 0.7784\n",
      "Epoch 19/150\n",
      "47500/47500 [==============================] - 6s 132us/sample - loss: 0.3211 - accuracy: 0.9634 - val_loss: 1.1038 - val_accuracy: 0.7840\n",
      "Epoch 20/150\n",
      "47500/47500 [==============================] - 6s 128us/sample - loss: 0.3318 - accuracy: 0.9620 - val_loss: 1.1606 - val_accuracy: 0.7744\n",
      "Epoch 21/150\n",
      "47500/47500 [==============================] - 6s 127us/sample - loss: 0.3297 - accuracy: 0.9620 - val_loss: 1.1615 - val_accuracy: 0.7824\n",
      "Epoch 22/150\n",
      "47500/47500 [==============================] - 6s 127us/sample - loss: 0.3123 - accuracy: 0.9686 - val_loss: 1.1208 - val_accuracy: 0.7956\n",
      "Epoch 23/150\n",
      "47500/47500 [==============================] - 6s 127us/sample - loss: 0.3103 - accuracy: 0.9697 - val_loss: 1.2508 - val_accuracy: 0.7776\n",
      "Epoch 24/150\n",
      "47500/47500 [==============================] - 6s 127us/sample - loss: 0.3139 - accuracy: 0.9699 - val_loss: 1.3611 - val_accuracy: 0.7748\n",
      "Epoch 25/150\n",
      "47500/47500 [==============================] - 6s 127us/sample - loss: 0.3279 - accuracy: 0.9654 - val_loss: 1.4135 - val_accuracy: 0.7464\n",
      "Epoch 26/150\n",
      "47500/47500 [==============================] - 6s 127us/sample - loss: 0.3165 - accuracy: 0.9707 - val_loss: 1.3409 - val_accuracy: 0.7536\n",
      "##################################\n",
      "\n",
      "Training model_1_9:\n",
      "\n",
      "Train on 47500 samples, validate on 2500 samples\n",
      "Epoch 1/150\n",
      "47500/47500 [==============================] - 7s 151us/sample - loss: 1.4935 - accuracy: 0.5177 - val_loss: 2.6494 - val_accuracy: 0.2256\n",
      "Epoch 2/150\n",
      "47500/47500 [==============================] - 6s 128us/sample - loss: 1.0524 - accuracy: 0.6806 - val_loss: 1.1263 - val_accuracy: 0.6660\n",
      "Epoch 3/150\n",
      "47500/47500 [==============================] - 6s 128us/sample - loss: 0.8633 - accuracy: 0.7449 - val_loss: 0.9597 - val_accuracy: 0.7212\n",
      "Epoch 4/150\n",
      "47500/47500 [==============================] - 6s 128us/sample - loss: 0.7383 - accuracy: 0.7890 - val_loss: 0.8842 - val_accuracy: 0.7588\n",
      "Epoch 5/150\n",
      "47500/47500 [==============================] - 6s 127us/sample - loss: 0.6476 - accuracy: 0.8207 - val_loss: 0.9339 - val_accuracy: 0.7476\n",
      "Epoch 6/150\n",
      "47500/47500 [==============================] - 6s 128us/sample - loss: 0.5822 - accuracy: 0.8452 - val_loss: 1.0060 - val_accuracy: 0.7356\n",
      "Epoch 7/150\n",
      "47500/47500 [==============================] - 6s 128us/sample - loss: 0.5215 - accuracy: 0.8670 - val_loss: 0.9636 - val_accuracy: 0.7500\n",
      "Epoch 8/150\n",
      "47500/47500 [==============================] - 6s 128us/sample - loss: 0.4766 - accuracy: 0.8865 - val_loss: 1.0359 - val_accuracy: 0.7476\n",
      "Epoch 9/150\n",
      "47500/47500 [==============================] - 6s 127us/sample - loss: 0.4388 - accuracy: 0.9029 - val_loss: 1.0860 - val_accuracy: 0.7380\n",
      "Epoch 10/150\n",
      "47500/47500 [==============================] - 6s 128us/sample - loss: 0.4161 - accuracy: 0.9134 - val_loss: 1.0282 - val_accuracy: 0.7644\n",
      "Epoch 11/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47500/47500 [==============================] - 6s 127us/sample - loss: 0.3858 - accuracy: 0.9264 - val_loss: 1.0159 - val_accuracy: 0.7672\n",
      "Epoch 12/150\n",
      "47500/47500 [==============================] - 6s 127us/sample - loss: 0.3733 - accuracy: 0.9338 - val_loss: 1.0803 - val_accuracy: 0.7532\n",
      "Epoch 13/150\n",
      "47500/47500 [==============================] - 6s 127us/sample - loss: 0.3696 - accuracy: 0.9367 - val_loss: 1.1116 - val_accuracy: 0.7684\n",
      "Epoch 14/150\n",
      "47500/47500 [==============================] - 6s 127us/sample - loss: 0.3359 - accuracy: 0.9511 - val_loss: 1.2388 - val_accuracy: 0.7556\n",
      "Epoch 15/150\n",
      "47500/47500 [==============================] - 6s 128us/sample - loss: 0.3267 - accuracy: 0.9558 - val_loss: 1.2483 - val_accuracy: 0.7756\n",
      "Epoch 16/150\n",
      "47500/47500 [==============================] - 6s 128us/sample - loss: 0.3277 - accuracy: 0.9562 - val_loss: 1.2520 - val_accuracy: 0.7624\n",
      "Epoch 17/150\n",
      "47500/47500 [==============================] - 6s 128us/sample - loss: 0.3282 - accuracy: 0.9575 - val_loss: 1.2201 - val_accuracy: 0.7560\n",
      "Epoch 18/150\n",
      "47500/47500 [==============================] - 6s 127us/sample - loss: 0.3239 - accuracy: 0.9608 - val_loss: 1.2899 - val_accuracy: 0.7684\n",
      "Epoch 19/150\n",
      "47500/47500 [==============================] - 6s 127us/sample - loss: 0.3224 - accuracy: 0.9620 - val_loss: 1.1628 - val_accuracy: 0.7828\n",
      "Epoch 20/150\n",
      "47500/47500 [==============================] - 6s 128us/sample - loss: 0.3243 - accuracy: 0.9628 - val_loss: 1.2632 - val_accuracy: 0.7668\n",
      "Epoch 21/150\n",
      "47500/47500 [==============================] - 6s 127us/sample - loss: 0.3246 - accuracy: 0.9635 - val_loss: 1.3382 - val_accuracy: 0.7644\n",
      "Epoch 22/150\n",
      "47500/47500 [==============================] - 6s 128us/sample - loss: 0.3189 - accuracy: 0.9662 - val_loss: 1.3107 - val_accuracy: 0.7604\n",
      "Epoch 23/150\n",
      "47500/47500 [==============================] - 6s 128us/sample - loss: 0.3191 - accuracy: 0.9666 - val_loss: 1.2037 - val_accuracy: 0.7696\n",
      "Epoch 24/150\n",
      "47500/47500 [==============================] - 6s 128us/sample - loss: 0.3193 - accuracy: 0.9669 - val_loss: 1.2379 - val_accuracy: 0.7744\n",
      "##################################\n",
      "\n",
      "Training model_1_10:\n",
      "\n",
      "Train on 47500 samples, validate on 2500 samples\n",
      "Epoch 1/150\n",
      "47500/47500 [==============================] - 7s 147us/sample - loss: 1.4998 - accuracy: 0.5211 - val_loss: 3.1115 - val_accuracy: 0.2204\n",
      "Epoch 2/150\n",
      "47500/47500 [==============================] - 6s 127us/sample - loss: 1.0324 - accuracy: 0.6878 - val_loss: 1.1683 - val_accuracy: 0.6680\n",
      "Epoch 3/150\n",
      "47500/47500 [==============================] - 6s 127us/sample - loss: 0.8444 - accuracy: 0.7523 - val_loss: 0.9993 - val_accuracy: 0.7204\n",
      "Epoch 4/150\n",
      "47500/47500 [==============================] - 6s 127us/sample - loss: 0.7278 - accuracy: 0.7938 - val_loss: 0.9699 - val_accuracy: 0.7292\n",
      "Epoch 5/150\n",
      "47500/47500 [==============================] - 6s 127us/sample - loss: 0.6378 - accuracy: 0.8263 - val_loss: 0.8960 - val_accuracy: 0.7500\n",
      "Epoch 6/150\n",
      "47500/47500 [==============================] - 6s 127us/sample - loss: 0.5691 - accuracy: 0.8504 - val_loss: 0.8940 - val_accuracy: 0.7664\n",
      "Epoch 7/150\n",
      "47500/47500 [==============================] - 6s 127us/sample - loss: 0.5105 - accuracy: 0.8741 - val_loss: 0.8785 - val_accuracy: 0.7704\n",
      "Epoch 8/150\n",
      "47500/47500 [==============================] - 6s 127us/sample - loss: 0.4659 - accuracy: 0.8906 - val_loss: 0.9346 - val_accuracy: 0.7688\n",
      "Epoch 9/150\n",
      "47500/47500 [==============================] - 6s 127us/sample - loss: 0.4195 - accuracy: 0.9113 - val_loss: 1.0238 - val_accuracy: 0.7560\n",
      "Epoch 10/150\n",
      "47500/47500 [==============================] - 6s 127us/sample - loss: 0.4169 - accuracy: 0.9142 - val_loss: 1.1743 - val_accuracy: 0.7436\n",
      "Epoch 11/150\n",
      "47500/47500 [==============================] - 6s 127us/sample - loss: 0.3881 - accuracy: 0.9271 - val_loss: 1.1293 - val_accuracy: 0.7580\n",
      "Epoch 12/150\n",
      "47500/47500 [==============================] - 6s 127us/sample - loss: 0.3556 - accuracy: 0.9411 - val_loss: 1.0680 - val_accuracy: 0.7852\n",
      "Epoch 13/150\n",
      "47500/47500 [==============================] - 6s 127us/sample - loss: 0.3695 - accuracy: 0.9389 - val_loss: 1.0978 - val_accuracy: 0.7728\n",
      "Epoch 14/150\n",
      "47500/47500 [==============================] - 6s 127us/sample - loss: 0.3394 - accuracy: 0.9509 - val_loss: 1.1114 - val_accuracy: 0.7780\n",
      "Epoch 15/150\n",
      "47500/47500 [==============================] - 6s 127us/sample - loss: 0.3263 - accuracy: 0.9577 - val_loss: 1.1985 - val_accuracy: 0.7664\n",
      "Epoch 16/150\n",
      "47500/47500 [==============================] - 6s 127us/sample - loss: 0.3249 - accuracy: 0.9585 - val_loss: 1.2629 - val_accuracy: 0.7556\n",
      "Epoch 17/150\n",
      "47500/47500 [==============================] - 6s 127us/sample - loss: 0.3320 - accuracy: 0.9572 - val_loss: 1.2944 - val_accuracy: 0.7600\n",
      "Epoch 18/150\n",
      "47500/47500 [==============================] - 6s 127us/sample - loss: 0.3206 - accuracy: 0.9612 - val_loss: 1.1305 - val_accuracy: 0.7752\n",
      "Epoch 19/150\n",
      "47500/47500 [==============================] - 6s 127us/sample - loss: 0.3210 - accuracy: 0.9637 - val_loss: 1.3529 - val_accuracy: 0.7600\n",
      "Epoch 20/150\n",
      "47500/47500 [==============================] - 6s 127us/sample - loss: 0.3208 - accuracy: 0.9641 - val_loss: 1.4056 - val_accuracy: 0.7632\n",
      "Epoch 21/150\n",
      "47500/47500 [==============================] - 6s 127us/sample - loss: 0.3209 - accuracy: 0.9649 - val_loss: 1.2433 - val_accuracy: 0.7780\n",
      "Epoch 22/150\n",
      "47500/47500 [==============================] - 6s 127us/sample - loss: 0.3124 - accuracy: 0.9686 - val_loss: 1.2585 - val_accuracy: 0.7584\n",
      "Epoch 23/150\n",
      "47500/47500 [==============================] - 6s 127us/sample - loss: 0.3188 - accuracy: 0.9675 - val_loss: 1.2518 - val_accuracy: 0.7784\n",
      "Epoch 24/150\n",
      "47500/47500 [==============================] - 6s 127us/sample - loss: 0.3134 - accuracy: 0.9695 - val_loss: 1.4036 - val_accuracy: 0.7744\n",
      "Epoch 25/150\n",
      "47500/47500 [==============================] - 6s 127us/sample - loss: 0.3226 - accuracy: 0.9672 - val_loss: 1.2446 - val_accuracy: 0.7744\n",
      "Epoch 26/150\n",
      "47500/47500 [==============================] - 6s 127us/sample - loss: 0.3104 - accuracy: 0.9730 - val_loss: 1.3754 - val_accuracy: 0.7672\n",
      "Epoch 27/150\n",
      "47500/47500 [==============================] - 6s 127us/sample - loss: 0.3433 - accuracy: 0.9629 - val_loss: 1.2654 - val_accuracy: 0.7868\n"
     ]
    }
   ],
   "source": [
    "test_model_1(results, x_train, x_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model_1': [0.7497,\n",
       "  0.755,\n",
       "  0.7304,\n",
       "  0.7479,\n",
       "  0.7485,\n",
       "  0.7359,\n",
       "  0.7437,\n",
       "  0.7601,\n",
       "  0.741,\n",
       "  0.7594]}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model_2(results, x_train, x_test, y_train, y_test):\n",
    "    results['model_2'] = []\n",
    "    for iteration in range(1, 11):\n",
    "        \n",
    "        model_name = f'model_2_{iteration}'\n",
    "        \n",
    "        x_train, x_valid, y_train, y_valid = train_test_split(x_train_orig, y_train_orig, test_size=0.05)\n",
    "                \n",
    "        print('##################################')\n",
    "        print('')\n",
    "        print(f'Training {model_name}:')\n",
    "        print('')\n",
    "        \n",
    "        model = model_2.get_model()\n",
    "        \n",
    "        model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "        callback_earlystop = tf.keras.callbacks.EarlyStopping(patience=20,\n",
    "                                               monitor='val_loss',\n",
    "                                               mode='auto',\n",
    "                                               restore_best_weights=True)\n",
    "        \n",
    "        model.fit(x_train, y_train, batch_size=128,\n",
    "                      validation_data=(x_valid, y_valid),\n",
    "                      callbacks=[callback_earlystop],\n",
    "                      verbose=1,\n",
    "                      epochs=150)\n",
    "        \n",
    "        model.save(f'./models/no_aug/{model_name}.h5')\n",
    "        \n",
    "        y_proba = model.predict(x_test)\n",
    "        y_hat = np.zeros_like(y_proba)\n",
    "        y_hat[np.arange(y_proba.shape[0]), np.argmax(y_proba, axis=1)] = 1\n",
    "\n",
    "        model_acc = accuracy_score(y_hat, y_test)\n",
    "        results['model_2'].append(model_acc)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##################################\n",
      "\n",
      "Training model_2_1:\n",
      "\n",
      "Train on 47500 samples, validate on 2500 samples\n",
      "Epoch 1/150\n",
      "47500/47500 [==============================] - 9s 194us/sample - loss: 1.7072 - accuracy: 0.4865 - val_loss: 2.2278 - val_accuracy: 0.3236\n",
      "Epoch 2/150\n",
      "47500/47500 [==============================] - 8s 162us/sample - loss: 1.2015 - accuracy: 0.6576 - val_loss: 1.6749 - val_accuracy: 0.5568\n",
      "Epoch 3/150\n",
      "47500/47500 [==============================] - 8s 162us/sample - loss: 0.9694 - accuracy: 0.7311 - val_loss: 1.3142 - val_accuracy: 0.6180\n",
      "Epoch 4/150\n",
      "47500/47500 [==============================] - 8s 162us/sample - loss: 0.8433 - accuracy: 0.7694 - val_loss: 1.0710 - val_accuracy: 0.7148\n",
      "Epoch 5/150\n",
      "47500/47500 [==============================] - 8s 162us/sample - loss: 0.7400 - accuracy: 0.8028 - val_loss: 1.1453 - val_accuracy: 0.6940\n",
      "Epoch 6/150\n",
      "47500/47500 [==============================] - 8s 162us/sample - loss: 0.6704 - accuracy: 0.8293 - val_loss: 0.9540 - val_accuracy: 0.7448\n",
      "Epoch 7/150\n",
      "47500/47500 [==============================] - 8s 162us/sample - loss: 0.6013 - accuracy: 0.8537 - val_loss: 0.9234 - val_accuracy: 0.7624\n",
      "Epoch 8/150\n",
      "47500/47500 [==============================] - 8s 162us/sample - loss: 0.5567 - accuracy: 0.8716 - val_loss: 1.0058 - val_accuracy: 0.7516\n",
      "Epoch 9/150\n",
      "47500/47500 [==============================] - 8s 162us/sample - loss: 0.5093 - accuracy: 0.8879 - val_loss: 1.0620 - val_accuracy: 0.7452\n",
      "Epoch 10/150\n",
      "47500/47500 [==============================] - 8s 162us/sample - loss: 0.4869 - accuracy: 0.8995 - val_loss: 0.9270 - val_accuracy: 0.7816\n",
      "Epoch 11/150\n",
      "47500/47500 [==============================] - 8s 162us/sample - loss: 0.4661 - accuracy: 0.9104 - val_loss: 1.0393 - val_accuracy: 0.7600\n",
      "Epoch 12/150\n",
      "47500/47500 [==============================] - 8s 162us/sample - loss: 0.4472 - accuracy: 0.9189 - val_loss: 1.0312 - val_accuracy: 0.7676\n",
      "Epoch 13/150\n",
      "47500/47500 [==============================] - 8s 162us/sample - loss: 0.4133 - accuracy: 0.9315 - val_loss: 1.0737 - val_accuracy: 0.7620\n",
      "Epoch 14/150\n",
      "47500/47500 [==============================] - 8s 162us/sample - loss: 0.4057 - accuracy: 0.9372 - val_loss: 1.0769 - val_accuracy: 0.7696\n",
      "Epoch 15/150\n",
      "47500/47500 [==============================] - 8s 162us/sample - loss: 0.4138 - accuracy: 0.9363 - val_loss: 1.2171 - val_accuracy: 0.7308\n",
      "Epoch 16/150\n",
      "47500/47500 [==============================] - 8s 162us/sample - loss: 0.3921 - accuracy: 0.9444 - val_loss: 1.0094 - val_accuracy: 0.7944\n",
      "Epoch 17/150\n",
      "47500/47500 [==============================] - 8s 162us/sample - loss: 0.3840 - accuracy: 0.9501 - val_loss: 1.1486 - val_accuracy: 0.7708\n",
      "Epoch 18/150\n",
      "47500/47500 [==============================] - 8s 162us/sample - loss: 0.3735 - accuracy: 0.9548 - val_loss: 1.2393 - val_accuracy: 0.7588\n",
      "Epoch 19/150\n",
      "47500/47500 [==============================] - 8s 162us/sample - loss: 0.3609 - accuracy: 0.9587 - val_loss: 1.1613 - val_accuracy: 0.7800\n",
      "Epoch 20/150\n",
      "47500/47500 [==============================] - 8s 162us/sample - loss: 0.3737 - accuracy: 0.9561 - val_loss: 1.1884 - val_accuracy: 0.7732\n",
      "Epoch 21/150\n",
      "47500/47500 [==============================] - 8s 162us/sample - loss: 0.3648 - accuracy: 0.9588 - val_loss: 1.2301 - val_accuracy: 0.7644\n",
      "Epoch 22/150\n",
      "47500/47500 [==============================] - 8s 162us/sample - loss: 0.3733 - accuracy: 0.9584 - val_loss: 1.2481 - val_accuracy: 0.7696\n",
      "Epoch 23/150\n",
      "47500/47500 [==============================] - 8s 162us/sample - loss: 0.3580 - accuracy: 0.9629 - val_loss: 1.2240 - val_accuracy: 0.7608\n",
      "Epoch 24/150\n",
      "47500/47500 [==============================] - 8s 162us/sample - loss: 0.3550 - accuracy: 0.9639 - val_loss: 1.2117 - val_accuracy: 0.7720\n",
      "Epoch 25/150\n",
      "47500/47500 [==============================] - 8s 162us/sample - loss: 0.3744 - accuracy: 0.9592 - val_loss: 1.1603 - val_accuracy: 0.7880\n",
      "Epoch 26/150\n",
      "47500/47500 [==============================] - 8s 162us/sample - loss: 0.3668 - accuracy: 0.9635 - val_loss: 1.2369 - val_accuracy: 0.7780\n",
      "Epoch 27/150\n",
      "47500/47500 [==============================] - 8s 162us/sample - loss: 0.3600 - accuracy: 0.9665 - val_loss: 1.2738 - val_accuracy: 0.7680\n",
      "##################################\n",
      "\n",
      "Training model_2_2:\n",
      "\n",
      "Train on 47500 samples, validate on 2500 samples\n",
      "Epoch 1/150\n",
      "47500/47500 [==============================] - 9s 188us/sample - loss: 1.6789 - accuracy: 0.4913 - val_loss: 3.6402 - val_accuracy: 0.1688\n",
      "Epoch 2/150\n",
      "47500/47500 [==============================] - 8s 162us/sample - loss: 1.2031 - accuracy: 0.6570 - val_loss: 1.1482 - val_accuracy: 0.6740\n",
      "Epoch 3/150\n",
      "47500/47500 [==============================] - 8s 163us/sample - loss: 0.9811 - accuracy: 0.7275 - val_loss: 1.0576 - val_accuracy: 0.6944\n",
      "Epoch 4/150\n",
      "47500/47500 [==============================] - 8s 163us/sample - loss: 0.8458 - accuracy: 0.7715 - val_loss: 0.9563 - val_accuracy: 0.7392\n",
      "Epoch 5/150\n",
      "47500/47500 [==============================] - 8s 163us/sample - loss: 0.7577 - accuracy: 0.8013 - val_loss: 0.8972 - val_accuracy: 0.7604\n",
      "Epoch 6/150\n",
      "47500/47500 [==============================] - 8s 163us/sample - loss: 0.6712 - accuracy: 0.8313 - val_loss: 0.9172 - val_accuracy: 0.7556\n",
      "Epoch 7/150\n",
      "47500/47500 [==============================] - 8s 162us/sample - loss: 0.6356 - accuracy: 0.8430 - val_loss: 0.9154 - val_accuracy: 0.7540\n",
      "Epoch 8/150\n",
      "47500/47500 [==============================] - 8s 163us/sample - loss: 0.5711 - accuracy: 0.8670 - val_loss: 0.9338 - val_accuracy: 0.7656\n",
      "Epoch 9/150\n",
      "47500/47500 [==============================] - 8s 163us/sample - loss: 0.5273 - accuracy: 0.8832 - val_loss: 0.9067 - val_accuracy: 0.7692\n",
      "Epoch 10/150\n",
      "47500/47500 [==============================] - 8s 163us/sample - loss: 0.5007 - accuracy: 0.8942 - val_loss: 0.9300 - val_accuracy: 0.7736\n",
      "Epoch 11/150\n",
      "47500/47500 [==============================] - 8s 163us/sample - loss: 0.4756 - accuracy: 0.9066 - val_loss: 0.9553 - val_accuracy: 0.7784\n",
      "Epoch 12/150\n",
      "47500/47500 [==============================] - 8s 163us/sample - loss: 0.4460 - accuracy: 0.9179 - val_loss: 0.9824 - val_accuracy: 0.7764\n",
      "Epoch 13/150\n",
      "47500/47500 [==============================] - 8s 163us/sample - loss: 0.4165 - accuracy: 0.9307 - val_loss: 1.0241 - val_accuracy: 0.7740\n",
      "Epoch 14/150\n",
      "47500/47500 [==============================] - 8s 163us/sample - loss: 0.4118 - accuracy: 0.9352 - val_loss: 0.9948 - val_accuracy: 0.7856\n",
      "Epoch 15/150\n",
      "47500/47500 [==============================] - 8s 163us/sample - loss: 0.4143 - accuracy: 0.9353 - val_loss: 1.0879 - val_accuracy: 0.7732\n",
      "Epoch 16/150\n",
      "47500/47500 [==============================] - 8s 162us/sample - loss: 0.4228 - accuracy: 0.9362 - val_loss: 1.0438 - val_accuracy: 0.7828\n",
      "Epoch 17/150\n",
      "47500/47500 [==============================] - 8s 163us/sample - loss: 0.3828 - accuracy: 0.9501 - val_loss: 1.1180 - val_accuracy: 0.7804\n",
      "Epoch 18/150\n",
      "47500/47500 [==============================] - 8s 163us/sample - loss: 0.3774 - accuracy: 0.9527 - val_loss: 1.0871 - val_accuracy: 0.7824\n",
      "Epoch 19/150\n",
      "47500/47500 [==============================] - 8s 163us/sample - loss: 0.3735 - accuracy: 0.9554 - val_loss: 1.1582 - val_accuracy: 0.7820\n",
      "Epoch 20/150\n",
      "47500/47500 [==============================] - 8s 163us/sample - loss: 0.3753 - accuracy: 0.9562 - val_loss: 1.1371 - val_accuracy: 0.7872\n",
      "Epoch 21/150\n",
      "47500/47500 [==============================] - 8s 163us/sample - loss: 0.3682 - accuracy: 0.9582 - val_loss: 1.1405 - val_accuracy: 0.7784\n",
      "Epoch 22/150\n",
      "47500/47500 [==============================] - 8s 163us/sample - loss: 0.3886 - accuracy: 0.9535 - val_loss: 1.2068 - val_accuracy: 0.7784\n",
      "Epoch 23/150\n",
      "47500/47500 [==============================] - 8s 162us/sample - loss: 0.3718 - accuracy: 0.9600 - val_loss: 1.1784 - val_accuracy: 0.7792\n",
      "Epoch 24/150\n",
      "47500/47500 [==============================] - 8s 163us/sample - loss: 0.3666 - accuracy: 0.9629 - val_loss: 1.1672 - val_accuracy: 0.7848\n",
      "Epoch 25/150\n",
      "47500/47500 [==============================] - 8s 163us/sample - loss: 0.3575 - accuracy: 0.9645 - val_loss: 1.2323 - val_accuracy: 0.7764\n",
      "##################################\n",
      "\n",
      "Training model_2_3:\n",
      "\n",
      "Train on 47500 samples, validate on 2500 samples\n",
      "Epoch 1/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47500/47500 [==============================] - 9s 187us/sample - loss: 1.6749 - accuracy: 0.4963 - val_loss: 2.6212 - val_accuracy: 0.2888\n",
      "Epoch 2/150\n",
      "47500/47500 [==============================] - 8s 162us/sample - loss: 1.2077 - accuracy: 0.6570 - val_loss: 1.4024 - val_accuracy: 0.6024\n",
      "Epoch 3/150\n",
      "47500/47500 [==============================] - 8s 162us/sample - loss: 0.9904 - accuracy: 0.7255 - val_loss: 1.1292 - val_accuracy: 0.6840\n",
      "Epoch 4/150\n",
      "47500/47500 [==============================] - 8s 162us/sample - loss: 0.8518 - accuracy: 0.7704 - val_loss: 0.9999 - val_accuracy: 0.7292\n",
      "Epoch 5/150\n",
      "47500/47500 [==============================] - 8s 162us/sample - loss: 0.7653 - accuracy: 0.7996 - val_loss: 1.0483 - val_accuracy: 0.7108\n",
      "Epoch 6/150\n",
      "47500/47500 [==============================] - 8s 163us/sample - loss: 0.6817 - accuracy: 0.8247 - val_loss: 0.9832 - val_accuracy: 0.7456\n",
      "Epoch 7/150\n",
      "47500/47500 [==============================] - 8s 163us/sample - loss: 0.6325 - accuracy: 0.8442 - val_loss: 0.9711 - val_accuracy: 0.7412\n",
      "Epoch 8/150\n",
      "47500/47500 [==============================] - 8s 162us/sample - loss: 0.5811 - accuracy: 0.8625 - val_loss: 1.0202 - val_accuracy: 0.7392\n",
      "Epoch 9/150\n",
      "47500/47500 [==============================] - 8s 162us/sample - loss: 0.5526 - accuracy: 0.8747 - val_loss: 1.0456 - val_accuracy: 0.7508\n",
      "Epoch 10/150\n",
      "47500/47500 [==============================] - 8s 162us/sample - loss: 0.5135 - accuracy: 0.8915 - val_loss: 0.9897 - val_accuracy: 0.7616\n",
      "Epoch 11/150\n",
      "47500/47500 [==============================] - 8s 162us/sample - loss: 0.4699 - accuracy: 0.9067 - val_loss: 1.0594 - val_accuracy: 0.7632\n",
      "Epoch 12/150\n",
      "47500/47500 [==============================] - 8s 162us/sample - loss: 0.4447 - accuracy: 0.9192 - val_loss: 1.0783 - val_accuracy: 0.7576\n",
      "Epoch 13/150\n",
      "47500/47500 [==============================] - 8s 162us/sample - loss: 0.4327 - accuracy: 0.9242 - val_loss: 1.0466 - val_accuracy: 0.7608\n",
      "Epoch 14/150\n",
      "47500/47500 [==============================] - 8s 162us/sample - loss: 0.4308 - accuracy: 0.9288 - val_loss: 1.1145 - val_accuracy: 0.7612\n",
      "Epoch 15/150\n",
      "47500/47500 [==============================] - 8s 162us/sample - loss: 0.4273 - accuracy: 0.9307 - val_loss: 1.1553 - val_accuracy: 0.7620\n",
      "Epoch 16/150\n",
      "47500/47500 [==============================] - 8s 162us/sample - loss: 0.3909 - accuracy: 0.9443 - val_loss: 1.1624 - val_accuracy: 0.7560\n",
      "Epoch 17/150\n",
      "47500/47500 [==============================] - 8s 162us/sample - loss: 0.4092 - accuracy: 0.9411 - val_loss: 1.1779 - val_accuracy: 0.7600\n",
      "Epoch 18/150\n",
      "47500/47500 [==============================] - 8s 162us/sample - loss: 0.3828 - accuracy: 0.9507 - val_loss: 1.2292 - val_accuracy: 0.7452\n",
      "Epoch 19/150\n",
      "47500/47500 [==============================] - 8s 163us/sample - loss: 0.3686 - accuracy: 0.9560 - val_loss: 1.2296 - val_accuracy: 0.7596\n",
      "Epoch 20/150\n",
      "47500/47500 [==============================] - 8s 162us/sample - loss: 0.3954 - accuracy: 0.9494 - val_loss: 1.1501 - val_accuracy: 0.7752\n",
      "Epoch 21/150\n",
      "47500/47500 [==============================] - 8s 163us/sample - loss: 0.3896 - accuracy: 0.9517 - val_loss: 1.2410 - val_accuracy: 0.7668\n",
      "Epoch 22/150\n",
      "47500/47500 [==============================] - 8s 162us/sample - loss: 0.3557 - accuracy: 0.9632 - val_loss: 1.2674 - val_accuracy: 0.7676\n",
      "Epoch 23/150\n",
      "47500/47500 [==============================] - 8s 163us/sample - loss: 0.3855 - accuracy: 0.9545 - val_loss: 1.3209 - val_accuracy: 0.7784\n",
      "Epoch 24/150\n",
      "47500/47500 [==============================] - 8s 162us/sample - loss: 0.3542 - accuracy: 0.9656 - val_loss: 1.2521 - val_accuracy: 0.7668\n",
      "Epoch 25/150\n",
      "47500/47500 [==============================] - 8s 163us/sample - loss: 0.3572 - accuracy: 0.9651 - val_loss: 1.2627 - val_accuracy: 0.7672\n",
      "Epoch 26/150\n",
      "47500/47500 [==============================] - 8s 162us/sample - loss: 0.3680 - accuracy: 0.9617 - val_loss: 1.2243 - val_accuracy: 0.7740\n",
      "Epoch 27/150\n",
      "47500/47500 [==============================] - 8s 162us/sample - loss: 0.3694 - accuracy: 0.9614 - val_loss: 1.2169 - val_accuracy: 0.7740\n",
      "##################################\n",
      "\n",
      "Training model_2_4:\n",
      "\n",
      "Train on 47500 samples, validate on 2500 samples\n",
      "Epoch 1/150\n",
      "47500/47500 [==============================] - 9s 188us/sample - loss: 1.6562 - accuracy: 0.5028 - val_loss: 3.7064 - val_accuracy: 0.2408\n",
      "Epoch 2/150\n",
      "47500/47500 [==============================] - 8s 163us/sample - loss: 1.1898 - accuracy: 0.6631 - val_loss: 1.3729 - val_accuracy: 0.6096\n",
      "Epoch 3/150\n",
      "47500/47500 [==============================] - 8s 163us/sample - loss: 0.9790 - accuracy: 0.7286 - val_loss: 1.0962 - val_accuracy: 0.6896\n",
      "Epoch 4/150\n",
      "47500/47500 [==============================] - 8s 163us/sample - loss: 0.8353 - accuracy: 0.7745 - val_loss: 1.0481 - val_accuracy: 0.7076\n",
      "Epoch 5/150\n",
      "47500/47500 [==============================] - 8s 163us/sample - loss: 0.7445 - accuracy: 0.8048 - val_loss: 0.9808 - val_accuracy: 0.7320\n",
      "Epoch 6/150\n",
      "47500/47500 [==============================] - 8s 163us/sample - loss: 0.6597 - accuracy: 0.8341 - val_loss: 0.9542 - val_accuracy: 0.7564\n",
      "Epoch 7/150\n",
      "47500/47500 [==============================] - 8s 163us/sample - loss: 0.6074 - accuracy: 0.8515 - val_loss: 0.9837 - val_accuracy: 0.7464\n",
      "Epoch 8/150\n",
      "47500/47500 [==============================] - 8s 163us/sample - loss: 0.5621 - accuracy: 0.8692 - val_loss: 1.2851 - val_accuracy: 0.7064\n",
      "Epoch 9/150\n",
      "47500/47500 [==============================] - 8s 164us/sample - loss: 0.5640 - accuracy: 0.8729 - val_loss: 0.8917 - val_accuracy: 0.7748\n",
      "Epoch 10/150\n",
      "47500/47500 [==============================] - 8s 163us/sample - loss: 0.4930 - accuracy: 0.8995 - val_loss: 1.0628 - val_accuracy: 0.7536\n",
      "Epoch 11/150\n",
      "47500/47500 [==============================] - 8s 163us/sample - loss: 0.4632 - accuracy: 0.9116 - val_loss: 1.0297 - val_accuracy: 0.7640\n",
      "Epoch 12/150\n",
      "47500/47500 [==============================] - 8s 162us/sample - loss: 0.4507 - accuracy: 0.9178 - val_loss: 1.0372 - val_accuracy: 0.7612\n",
      "Epoch 13/150\n",
      "47500/47500 [==============================] - 8s 163us/sample - loss: 0.4333 - accuracy: 0.9259 - val_loss: 1.0488 - val_accuracy: 0.7676\n",
      "Epoch 14/150\n",
      "47500/47500 [==============================] - 8s 163us/sample - loss: 0.4117 - accuracy: 0.9336 - val_loss: 1.1290 - val_accuracy: 0.7624\n",
      "Epoch 15/150\n",
      "47500/47500 [==============================] - 8s 163us/sample - loss: 0.3971 - accuracy: 0.9404 - val_loss: 1.0886 - val_accuracy: 0.7776\n",
      "Epoch 16/150\n",
      "47500/47500 [==============================] - 8s 162us/sample - loss: 0.3987 - accuracy: 0.9425 - val_loss: 1.1314 - val_accuracy: 0.7672\n",
      "Epoch 17/150\n",
      "47500/47500 [==============================] - 8s 163us/sample - loss: 0.3809 - accuracy: 0.9497 - val_loss: 1.2201 - val_accuracy: 0.7564\n",
      "Epoch 18/150\n",
      "47500/47500 [==============================] - 8s 163us/sample - loss: 0.4069 - accuracy: 0.9431 - val_loss: 1.0873 - val_accuracy: 0.7788\n",
      "Epoch 19/150\n",
      "47500/47500 [==============================] - 8s 169us/sample - loss: 0.3762 - accuracy: 0.9554 - val_loss: 1.2096 - val_accuracy: 0.7732\n",
      "Epoch 20/150\n",
      "47500/47500 [==============================] - 9s 194us/sample - loss: 0.3604 - accuracy: 0.9589 - val_loss: 1.1814 - val_accuracy: 0.7780\n",
      "Epoch 21/150\n",
      "47500/47500 [==============================] - 9s 191us/sample - loss: 0.3878 - accuracy: 0.9524 - val_loss: 1.0811 - val_accuracy: 0.7940\n",
      "Epoch 22/150\n",
      "47500/47500 [==============================] - 9s 182us/sample - loss: 0.3714 - accuracy: 0.9581 - val_loss: 1.1918 - val_accuracy: 0.7688\n",
      "Epoch 23/150\n",
      "47500/47500 [==============================] - 9s 183us/sample - loss: 0.3606 - accuracy: 0.9623 - val_loss: 1.3327 - val_accuracy: 0.7644\n",
      "Epoch 24/150\n",
      "47500/47500 [==============================] - 9s 183us/sample - loss: 0.3588 - accuracy: 0.9636 - val_loss: 1.2388 - val_accuracy: 0.7832\n",
      "Epoch 25/150\n",
      "47500/47500 [==============================] - 9s 184us/sample - loss: 0.3569 - accuracy: 0.9643 - val_loss: 1.2998 - val_accuracy: 0.7540\n",
      "Epoch 26/150\n",
      "47500/47500 [==============================] - 9s 184us/sample - loss: 0.3584 - accuracy: 0.9651 - val_loss: 1.2230 - val_accuracy: 0.7768\n",
      "Epoch 27/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47500/47500 [==============================] - 8s 176us/sample - loss: 0.3737 - accuracy: 0.9613 - val_loss: 1.3323 - val_accuracy: 0.7708\n",
      "Epoch 28/150\n",
      "47500/47500 [==============================] - 8s 176us/sample - loss: 0.3735 - accuracy: 0.9623 - val_loss: 1.2114 - val_accuracy: 0.7832\n",
      "Epoch 29/150\n",
      "47500/47500 [==============================] - 8s 177us/sample - loss: 0.3652 - accuracy: 0.9654 - val_loss: 1.2079 - val_accuracy: 0.7792\n",
      "##################################\n",
      "\n",
      "Training model_2_5:\n",
      "\n",
      "Train on 47500 samples, validate on 2500 samples\n",
      "Epoch 1/150\n",
      "47500/47500 [==============================] - 10s 201us/sample - loss: 1.6571 - accuracy: 0.5038 - val_loss: 2.0643 - val_accuracy: 0.3904\n",
      "Epoch 2/150\n",
      "47500/47500 [==============================] - 8s 176us/sample - loss: 1.2025 - accuracy: 0.6570 - val_loss: 1.2867 - val_accuracy: 0.6472\n",
      "Epoch 3/150\n",
      "47500/47500 [==============================] - 8s 178us/sample - loss: 0.9981 - accuracy: 0.7228 - val_loss: 1.1248 - val_accuracy: 0.6924\n",
      "Epoch 4/150\n",
      "47500/47500 [==============================] - 8s 178us/sample - loss: 0.8598 - accuracy: 0.7650 - val_loss: 0.9742 - val_accuracy: 0.7236\n",
      "Epoch 5/150\n",
      "47500/47500 [==============================] - 8s 177us/sample - loss: 0.7705 - accuracy: 0.7942 - val_loss: 0.9520 - val_accuracy: 0.7456\n",
      "Epoch 6/150\n",
      "47500/47500 [==============================] - 8s 177us/sample - loss: 0.6869 - accuracy: 0.8241 - val_loss: 0.9693 - val_accuracy: 0.7432\n",
      "Epoch 7/150\n",
      "47500/47500 [==============================] - 8s 177us/sample - loss: 0.6226 - accuracy: 0.8461 - val_loss: 0.9572 - val_accuracy: 0.7436\n",
      "Epoch 8/150\n",
      "47500/47500 [==============================] - 8s 178us/sample - loss: 0.5791 - accuracy: 0.8646 - val_loss: 0.8898 - val_accuracy: 0.7768\n",
      "Epoch 9/150\n",
      "47500/47500 [==============================] - 8s 178us/sample - loss: 0.5331 - accuracy: 0.8823 - val_loss: 0.9518 - val_accuracy: 0.7636\n",
      "Epoch 10/150\n",
      "47500/47500 [==============================] - 8s 177us/sample - loss: 0.4969 - accuracy: 0.8948 - val_loss: 0.8970 - val_accuracy: 0.7804\n",
      "Epoch 11/150\n",
      "47500/47500 [==============================] - 8s 176us/sample - loss: 0.4781 - accuracy: 0.9057 - val_loss: 0.9640 - val_accuracy: 0.7812\n",
      "Epoch 12/150\n",
      "47500/47500 [==============================] - 8s 177us/sample - loss: 0.4424 - accuracy: 0.9196 - val_loss: 0.9725 - val_accuracy: 0.7708\n",
      "Epoch 13/150\n",
      "47500/47500 [==============================] - 8s 177us/sample - loss: 0.4360 - accuracy: 0.9236 - val_loss: 1.0402 - val_accuracy: 0.7756\n",
      "Epoch 14/150\n",
      "47500/47500 [==============================] - 8s 176us/sample - loss: 0.4414 - accuracy: 0.9256 - val_loss: 1.0634 - val_accuracy: 0.7732\n",
      "Epoch 15/150\n",
      "47500/47500 [==============================] - 8s 176us/sample - loss: 0.4004 - accuracy: 0.9420 - val_loss: 1.0798 - val_accuracy: 0.7920\n",
      "Epoch 16/150\n",
      "47500/47500 [==============================] - 8s 177us/sample - loss: 0.4176 - accuracy: 0.9375 - val_loss: 1.0159 - val_accuracy: 0.7896\n",
      "Epoch 17/150\n",
      "47500/47500 [==============================] - 8s 177us/sample - loss: 0.3829 - accuracy: 0.9501 - val_loss: 1.0538 - val_accuracy: 0.7832\n",
      "Epoch 18/150\n",
      "47500/47500 [==============================] - 8s 176us/sample - loss: 0.4273 - accuracy: 0.9378 - val_loss: 1.1250 - val_accuracy: 0.7896\n",
      "Epoch 19/150\n",
      "47500/47500 [==============================] - 8s 177us/sample - loss: 0.3622 - accuracy: 0.9607 - val_loss: 1.1391 - val_accuracy: 0.7792\n",
      "Epoch 20/150\n",
      "47500/47500 [==============================] - 8s 176us/sample - loss: 0.3836 - accuracy: 0.9548 - val_loss: 1.3019 - val_accuracy: 0.7704\n",
      "Epoch 21/150\n",
      "47500/47500 [==============================] - 8s 177us/sample - loss: 0.3725 - accuracy: 0.9580 - val_loss: 1.1681 - val_accuracy: 0.7860\n",
      "Epoch 22/150\n",
      "47500/47500 [==============================] - 8s 177us/sample - loss: 0.3810 - accuracy: 0.9565 - val_loss: 1.0805 - val_accuracy: 0.7916\n",
      "Epoch 23/150\n",
      "47500/47500 [==============================] - 8s 178us/sample - loss: 0.3786 - accuracy: 0.9581 - val_loss: 1.1603 - val_accuracy: 0.7836\n",
      "Epoch 24/150\n",
      "47500/47500 [==============================] - 8s 176us/sample - loss: 0.3881 - accuracy: 0.9569 - val_loss: 1.1234 - val_accuracy: 0.7884\n",
      "Epoch 25/150\n",
      "47500/47500 [==============================] - 8s 177us/sample - loss: 0.3744 - accuracy: 0.9622 - val_loss: 1.2178 - val_accuracy: 0.7828\n",
      "Epoch 26/150\n",
      "47500/47500 [==============================] - 8s 176us/sample - loss: 0.3662 - accuracy: 0.9642 - val_loss: 1.2378 - val_accuracy: 0.7940\n",
      "Epoch 27/150\n",
      "47500/47500 [==============================] - 8s 177us/sample - loss: 0.3696 - accuracy: 0.9631 - val_loss: 1.2416 - val_accuracy: 0.7832\n",
      "Epoch 28/150\n",
      "47500/47500 [==============================] - 8s 177us/sample - loss: 0.3751 - accuracy: 0.9644 - val_loss: 1.1092 - val_accuracy: 0.8016\n",
      "##################################\n",
      "\n",
      "Training model_2_6:\n",
      "\n",
      "Train on 47500 samples, validate on 2500 samples\n",
      "Epoch 1/150\n",
      "47500/47500 [==============================] - 10s 201us/sample - loss: 1.6638 - accuracy: 0.4999 - val_loss: 2.4263 - val_accuracy: 0.2920\n",
      "Epoch 2/150\n",
      "47500/47500 [==============================] - 8s 176us/sample - loss: 1.1818 - accuracy: 0.6626 - val_loss: 1.2577 - val_accuracy: 0.6392\n",
      "Epoch 3/150\n",
      "47500/47500 [==============================] - 8s 176us/sample - loss: 0.9806 - accuracy: 0.7286 - val_loss: 1.1227 - val_accuracy: 0.6764\n",
      "Epoch 4/150\n",
      "47500/47500 [==============================] - 8s 176us/sample - loss: 0.8431 - accuracy: 0.7729 - val_loss: 1.2045 - val_accuracy: 0.6652\n",
      "Epoch 5/150\n",
      "47500/47500 [==============================] - 8s 177us/sample - loss: 0.7470 - accuracy: 0.8020 - val_loss: 0.9033 - val_accuracy: 0.7436\n",
      "Epoch 6/150\n",
      "47500/47500 [==============================] - 8s 177us/sample - loss: 0.6771 - accuracy: 0.8261 - val_loss: 1.1453 - val_accuracy: 0.6984\n",
      "Epoch 7/150\n",
      "47500/47500 [==============================] - 8s 177us/sample - loss: 0.6135 - accuracy: 0.8486 - val_loss: 1.1264 - val_accuracy: 0.7112\n",
      "Epoch 8/150\n",
      "47500/47500 [==============================] - 8s 176us/sample - loss: 0.5694 - accuracy: 0.8653 - val_loss: 0.9791 - val_accuracy: 0.7524\n",
      "Epoch 9/150\n",
      "47500/47500 [==============================] - 8s 178us/sample - loss: 0.5586 - accuracy: 0.8726 - val_loss: 0.9873 - val_accuracy: 0.7452\n",
      "Epoch 10/150\n",
      "47500/47500 [==============================] - 8s 177us/sample - loss: 0.4983 - accuracy: 0.8952 - val_loss: 0.9782 - val_accuracy: 0.7552\n",
      "Epoch 11/150\n",
      "47500/47500 [==============================] - 8s 176us/sample - loss: 0.4670 - accuracy: 0.9068 - val_loss: 1.0946 - val_accuracy: 0.7364\n",
      "Epoch 12/150\n",
      "47500/47500 [==============================] - 8s 177us/sample - loss: 0.4637 - accuracy: 0.9125 - val_loss: 1.0257 - val_accuracy: 0.7528\n",
      "Epoch 13/150\n",
      "47500/47500 [==============================] - 8s 176us/sample - loss: 0.4388 - accuracy: 0.9225 - val_loss: 1.1606 - val_accuracy: 0.7456\n",
      "Epoch 14/150\n",
      "47500/47500 [==============================] - 8s 176us/sample - loss: 0.4115 - accuracy: 0.9331 - val_loss: 1.1586 - val_accuracy: 0.7580\n",
      "Epoch 15/150\n",
      "47500/47500 [==============================] - 8s 176us/sample - loss: 0.4202 - accuracy: 0.9344 - val_loss: 1.0550 - val_accuracy: 0.7684\n",
      "Epoch 16/150\n",
      "47500/47500 [==============================] - 8s 176us/sample - loss: 0.3960 - accuracy: 0.9431 - val_loss: 1.1517 - val_accuracy: 0.7720\n",
      "Epoch 17/150\n",
      "47500/47500 [==============================] - 8s 177us/sample - loss: 0.3846 - accuracy: 0.9481 - val_loss: 1.2694 - val_accuracy: 0.7524\n",
      "Epoch 18/150\n",
      "47500/47500 [==============================] - 8s 177us/sample - loss: 0.4139 - accuracy: 0.9403 - val_loss: 1.2566 - val_accuracy: 0.7284\n",
      "Epoch 19/150\n",
      "47500/47500 [==============================] - 8s 176us/sample - loss: 0.3809 - accuracy: 0.9524 - val_loss: 1.0977 - val_accuracy: 0.7764\n",
      "Epoch 20/150\n",
      "47500/47500 [==============================] - 8s 176us/sample - loss: 0.3710 - accuracy: 0.9566 - val_loss: 1.2079 - val_accuracy: 0.7544\n",
      "Epoch 21/150\n",
      "47500/47500 [==============================] - 8s 176us/sample - loss: 0.4020 - accuracy: 0.9487 - val_loss: 1.1882 - val_accuracy: 0.7772\n",
      "Epoch 22/150\n",
      "47500/47500 [==============================] - 8s 177us/sample - loss: 0.3668 - accuracy: 0.9611 - val_loss: 1.2519 - val_accuracy: 0.7680\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/150\n",
      "47500/47500 [==============================] - 8s 178us/sample - loss: 0.4071 - accuracy: 0.9501 - val_loss: 1.1460 - val_accuracy: 0.7732\n",
      "Epoch 24/150\n",
      "47500/47500 [==============================] - 8s 177us/sample - loss: 0.3594 - accuracy: 0.9659 - val_loss: 1.2745 - val_accuracy: 0.7644\n",
      "Epoch 25/150\n",
      "47500/47500 [==============================] - 8s 178us/sample - loss: 0.3735 - accuracy: 0.9618 - val_loss: 1.2256 - val_accuracy: 0.7640\n",
      "##################################\n",
      "\n",
      "Training model_2_7:\n",
      "\n",
      "Train on 47500 samples, validate on 2500 samples\n",
      "Epoch 1/150\n",
      "47500/47500 [==============================] - 10s 201us/sample - loss: 1.6758 - accuracy: 0.4962 - val_loss: 2.4004 - val_accuracy: 0.3328\n",
      "Epoch 2/150\n",
      "47500/47500 [==============================] - 8s 177us/sample - loss: 1.1993 - accuracy: 0.6596 - val_loss: 1.2644 - val_accuracy: 0.6596\n",
      "Epoch 3/150\n",
      "47500/47500 [==============================] - 8s 176us/sample - loss: 0.9802 - accuracy: 0.7274 - val_loss: 1.1435 - val_accuracy: 0.6780\n",
      "Epoch 4/150\n",
      "47500/47500 [==============================] - 8s 177us/sample - loss: 0.8478 - accuracy: 0.7714 - val_loss: 1.0554 - val_accuracy: 0.7076\n",
      "Epoch 5/150\n",
      "47500/47500 [==============================] - 8s 177us/sample - loss: 0.7516 - accuracy: 0.8010 - val_loss: 0.8932 - val_accuracy: 0.7612\n",
      "Epoch 6/150\n",
      "47500/47500 [==============================] - 8s 177us/sample - loss: 0.6864 - accuracy: 0.8229 - val_loss: 0.9650 - val_accuracy: 0.7352\n",
      "Epoch 7/150\n",
      "47500/47500 [==============================] - 8s 177us/sample - loss: 0.6205 - accuracy: 0.8460 - val_loss: 0.9683 - val_accuracy: 0.7384\n",
      "Epoch 8/150\n",
      "47500/47500 [==============================] - 8s 177us/sample - loss: 0.5800 - accuracy: 0.8612 - val_loss: 0.9521 - val_accuracy: 0.7448\n",
      "Epoch 9/150\n",
      "47500/47500 [==============================] - 8s 176us/sample - loss: 0.5324 - accuracy: 0.8811 - val_loss: 0.9228 - val_accuracy: 0.7684\n",
      "Epoch 10/150\n",
      "47500/47500 [==============================] - 8s 176us/sample - loss: 0.4950 - accuracy: 0.8963 - val_loss: 0.9508 - val_accuracy: 0.7656\n",
      "Epoch 11/150\n",
      "47500/47500 [==============================] - 8s 177us/sample - loss: 0.4735 - accuracy: 0.9065 - val_loss: 0.9815 - val_accuracy: 0.7672\n",
      "Epoch 12/150\n",
      "47500/47500 [==============================] - 8s 178us/sample - loss: 0.4506 - accuracy: 0.9171 - val_loss: 0.9516 - val_accuracy: 0.7820\n",
      "Epoch 13/150\n",
      "47500/47500 [==============================] - 8s 177us/sample - loss: 0.4349 - accuracy: 0.9248 - val_loss: 1.1197 - val_accuracy: 0.7640\n",
      "Epoch 14/150\n",
      "47500/47500 [==============================] - 8s 176us/sample - loss: 0.4240 - accuracy: 0.9307 - val_loss: 1.0889 - val_accuracy: 0.7712\n",
      "Epoch 15/150\n",
      "47500/47500 [==============================] - 8s 177us/sample - loss: 0.3979 - accuracy: 0.9407 - val_loss: 1.1044 - val_accuracy: 0.7660\n",
      "Epoch 16/150\n",
      "47500/47500 [==============================] - 8s 175us/sample - loss: 0.3926 - accuracy: 0.9439 - val_loss: 1.1391 - val_accuracy: 0.7680\n",
      "Epoch 17/150\n",
      "47500/47500 [==============================] - 8s 177us/sample - loss: 0.3802 - accuracy: 0.9510 - val_loss: 1.2660 - val_accuracy: 0.7464\n",
      "Epoch 18/150\n",
      "47500/47500 [==============================] - 8s 176us/sample - loss: 0.3800 - accuracy: 0.9505 - val_loss: 1.1477 - val_accuracy: 0.7824\n",
      "Epoch 19/150\n",
      "47500/47500 [==============================] - 8s 176us/sample - loss: 0.3907 - accuracy: 0.9495 - val_loss: 1.1922 - val_accuracy: 0.7768\n",
      "Epoch 20/150\n",
      "47500/47500 [==============================] - 8s 176us/sample - loss: 0.3676 - accuracy: 0.9570 - val_loss: 1.1616 - val_accuracy: 0.7696\n",
      "Epoch 21/150\n",
      "47500/47500 [==============================] - 8s 176us/sample - loss: 0.3947 - accuracy: 0.9510 - val_loss: 1.2220 - val_accuracy: 0.7648\n",
      "Epoch 22/150\n",
      "47500/47500 [==============================] - 8s 176us/sample - loss: 0.3875 - accuracy: 0.9549 - val_loss: 1.3102 - val_accuracy: 0.7544\n",
      "Epoch 23/150\n",
      "47500/47500 [==============================] - 8s 176us/sample - loss: 0.3702 - accuracy: 0.9604 - val_loss: 1.3009 - val_accuracy: 0.7672\n",
      "Epoch 24/150\n",
      "47500/47500 [==============================] - 8s 177us/sample - loss: 0.3603 - accuracy: 0.9647 - val_loss: 1.3041 - val_accuracy: 0.7608\n",
      "Epoch 25/150\n",
      "47500/47500 [==============================] - 8s 176us/sample - loss: 0.3596 - accuracy: 0.9641 - val_loss: 1.2733 - val_accuracy: 0.7736\n",
      "##################################\n",
      "\n",
      "Training model_2_8:\n",
      "\n",
      "Train on 47500 samples, validate on 2500 samples\n",
      "Epoch 1/150\n",
      "47500/47500 [==============================] - 10s 204us/sample - loss: 1.6760 - accuracy: 0.4943 - val_loss: 2.2223 - val_accuracy: 0.3128\n",
      "Epoch 2/150\n",
      "47500/47500 [==============================] - 8s 177us/sample - loss: 1.2033 - accuracy: 0.6578 - val_loss: 1.2328 - val_accuracy: 0.6508\n",
      "Epoch 3/150\n",
      "47500/47500 [==============================] - 8s 177us/sample - loss: 0.9844 - accuracy: 0.7248 - val_loss: 1.0989 - val_accuracy: 0.6832\n",
      "Epoch 4/150\n",
      "47500/47500 [==============================] - 8s 177us/sample - loss: 0.8417 - accuracy: 0.7704 - val_loss: 1.1926 - val_accuracy: 0.6804\n",
      "Epoch 5/150\n",
      "47500/47500 [==============================] - 8s 177us/sample - loss: 0.7495 - accuracy: 0.8021 - val_loss: 0.9696 - val_accuracy: 0.7324\n",
      "Epoch 6/150\n",
      "47500/47500 [==============================] - 8s 177us/sample - loss: 0.6804 - accuracy: 0.8259 - val_loss: 0.9893 - val_accuracy: 0.7408\n",
      "Epoch 7/150\n",
      "47500/47500 [==============================] - 8s 177us/sample - loss: 0.6414 - accuracy: 0.8422 - val_loss: 0.9561 - val_accuracy: 0.7500\n",
      "Epoch 8/150\n",
      "47500/47500 [==============================] - 8s 177us/sample - loss: 0.5660 - accuracy: 0.8684 - val_loss: 0.9936 - val_accuracy: 0.7448\n",
      "Epoch 9/150\n",
      "47500/47500 [==============================] - 8s 177us/sample - loss: 0.5281 - accuracy: 0.8839 - val_loss: 0.9856 - val_accuracy: 0.7644\n",
      "Epoch 10/150\n",
      "47500/47500 [==============================] - 8s 177us/sample - loss: 0.5139 - accuracy: 0.8902 - val_loss: 1.0870 - val_accuracy: 0.7520\n",
      "Epoch 11/150\n",
      "47500/47500 [==============================] - 8s 177us/sample - loss: 0.4678 - accuracy: 0.9088 - val_loss: 1.0563 - val_accuracy: 0.7564\n",
      "Epoch 12/150\n",
      "47500/47500 [==============================] - 8s 178us/sample - loss: 0.4408 - accuracy: 0.9201 - val_loss: 1.0755 - val_accuracy: 0.7452\n",
      "Epoch 13/150\n",
      "47500/47500 [==============================] - 8s 176us/sample - loss: 0.4263 - accuracy: 0.9265 - val_loss: 1.1431 - val_accuracy: 0.7576\n",
      "Epoch 14/150\n",
      "47500/47500 [==============================] - 8s 177us/sample - loss: 0.4148 - accuracy: 0.9346 - val_loss: 1.2310 - val_accuracy: 0.7516\n",
      "Epoch 15/150\n",
      "47500/47500 [==============================] - 8s 177us/sample - loss: 0.4133 - accuracy: 0.9367 - val_loss: 1.1269 - val_accuracy: 0.7728\n",
      "Epoch 16/150\n",
      "47500/47500 [==============================] - 11s 224us/sample - loss: 0.3898 - accuracy: 0.9458 - val_loss: 1.1957 - val_accuracy: 0.7536\n",
      "Epoch 17/150\n",
      "47500/47500 [==============================] - 8s 165us/sample - loss: 0.3775 - accuracy: 0.9508 - val_loss: 1.4376 - val_accuracy: 0.7112\n",
      "Epoch 18/150\n",
      "47500/47500 [==============================] - 8s 163us/sample - loss: 0.4083 - accuracy: 0.9436 - val_loss: 1.1656 - val_accuracy: 0.7656\n",
      "Epoch 19/150\n",
      "47500/47500 [==============================] - 8s 163us/sample - loss: 0.4329 - accuracy: 0.9377 - val_loss: 1.2256 - val_accuracy: 0.7580\n",
      "Epoch 20/150\n",
      "47500/47500 [==============================] - 8s 163us/sample - loss: 0.3657 - accuracy: 0.9615 - val_loss: 1.2036 - val_accuracy: 0.7708\n",
      "Epoch 21/150\n",
      "47500/47500 [==============================] - 8s 163us/sample - loss: 0.3547 - accuracy: 0.9641 - val_loss: 1.3469 - val_accuracy: 0.7612\n",
      "Epoch 22/150\n",
      "47500/47500 [==============================] - 8s 163us/sample - loss: 0.3860 - accuracy: 0.9547 - val_loss: 1.2322 - val_accuracy: 0.7704\n",
      "Epoch 23/150\n",
      "47500/47500 [==============================] - 8s 163us/sample - loss: 0.3718 - accuracy: 0.9602 - val_loss: 1.2483 - val_accuracy: 0.7804\n",
      "Epoch 24/150\n",
      "47500/47500 [==============================] - 8s 164us/sample - loss: 0.3864 - accuracy: 0.9571 - val_loss: 1.3406 - val_accuracy: 0.7620\n",
      "Epoch 25/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47500/47500 [==============================] - 8s 163us/sample - loss: 0.3721 - accuracy: 0.9622 - val_loss: 1.2255 - val_accuracy: 0.7688\n",
      "Epoch 26/150\n",
      "47500/47500 [==============================] - 8s 163us/sample - loss: 0.3612 - accuracy: 0.9656 - val_loss: 1.2758 - val_accuracy: 0.7756\n",
      "Epoch 27/150\n",
      "47500/47500 [==============================] - 8s 163us/sample - loss: 0.3795 - accuracy: 0.9602 - val_loss: 1.2303 - val_accuracy: 0.7772\n",
      "##################################\n",
      "\n",
      "Training model_2_9:\n",
      "\n",
      "Train on 47500 samples, validate on 2500 samples\n",
      "Epoch 1/150\n",
      "47500/47500 [==============================] - 9s 187us/sample - loss: 1.6685 - accuracy: 0.4920 - val_loss: 2.0675 - val_accuracy: 0.3656\n",
      "Epoch 2/150\n",
      "47500/47500 [==============================] - 8s 163us/sample - loss: 1.1926 - accuracy: 0.6601 - val_loss: 1.2890 - val_accuracy: 0.6324\n",
      "Epoch 3/150\n",
      "47500/47500 [==============================] - 8s 162us/sample - loss: 0.9811 - accuracy: 0.7256 - val_loss: 1.0458 - val_accuracy: 0.7104\n",
      "Epoch 4/150\n",
      "47500/47500 [==============================] - 8s 162us/sample - loss: 0.8589 - accuracy: 0.7630 - val_loss: 1.0016 - val_accuracy: 0.7208\n",
      "Epoch 5/150\n",
      "47500/47500 [==============================] - 8s 163us/sample - loss: 0.7563 - accuracy: 0.7983 - val_loss: 0.9886 - val_accuracy: 0.7284\n",
      "Epoch 6/150\n",
      "47500/47500 [==============================] - 8s 163us/sample - loss: 0.6752 - accuracy: 0.8252 - val_loss: 0.9168 - val_accuracy: 0.7532\n",
      "Epoch 7/150\n",
      "47500/47500 [==============================] - 8s 162us/sample - loss: 0.6394 - accuracy: 0.8405 - val_loss: 1.1064 - val_accuracy: 0.7092\n",
      "Epoch 8/150\n",
      "47500/47500 [==============================] - 8s 162us/sample - loss: 0.5743 - accuracy: 0.8650 - val_loss: 1.0242 - val_accuracy: 0.7340\n",
      "Epoch 9/150\n",
      "47500/47500 [==============================] - 8s 162us/sample - loss: 0.5301 - accuracy: 0.8810 - val_loss: 1.0339 - val_accuracy: 0.7380\n",
      "Epoch 10/150\n",
      "47500/47500 [==============================] - 8s 162us/sample - loss: 0.5124 - accuracy: 0.8904 - val_loss: 1.0353 - val_accuracy: 0.7568\n",
      "Epoch 11/150\n",
      "47500/47500 [==============================] - 8s 162us/sample - loss: 0.4762 - accuracy: 0.9062 - val_loss: 1.0535 - val_accuracy: 0.7628\n",
      "Epoch 12/150\n",
      "47500/47500 [==============================] - 8s 162us/sample - loss: 0.4391 - accuracy: 0.9200 - val_loss: 1.1702 - val_accuracy: 0.7428\n",
      "Epoch 13/150\n",
      "47500/47500 [==============================] - 8s 162us/sample - loss: 0.4446 - accuracy: 0.9217 - val_loss: 1.0838 - val_accuracy: 0.7736\n",
      "Epoch 14/150\n",
      "47500/47500 [==============================] - 8s 162us/sample - loss: 0.4132 - accuracy: 0.9333 - val_loss: 1.2005 - val_accuracy: 0.7620\n",
      "Epoch 15/150\n",
      "47500/47500 [==============================] - 8s 162us/sample - loss: 0.3954 - accuracy: 0.9432 - val_loss: 1.0921 - val_accuracy: 0.7712\n",
      "Epoch 16/150\n",
      "47500/47500 [==============================] - 8s 162us/sample - loss: 0.3984 - accuracy: 0.9425 - val_loss: 1.1251 - val_accuracy: 0.7732\n",
      "Epoch 17/150\n",
      "47500/47500 [==============================] - 8s 163us/sample - loss: 0.3845 - accuracy: 0.9483 - val_loss: 1.2456 - val_accuracy: 0.7688\n",
      "Epoch 18/150\n",
      "47500/47500 [==============================] - 8s 163us/sample - loss: 0.3731 - accuracy: 0.9528 - val_loss: 1.2923 - val_accuracy: 0.7440\n",
      "Epoch 19/150\n",
      "47500/47500 [==============================] - 8s 162us/sample - loss: 0.4001 - accuracy: 0.9477 - val_loss: 1.2088 - val_accuracy: 0.7580\n",
      "Epoch 20/150\n",
      "47500/47500 [==============================] - 8s 162us/sample - loss: 0.3791 - accuracy: 0.9548 - val_loss: 1.2445 - val_accuracy: 0.7684\n",
      "Epoch 21/150\n",
      "47500/47500 [==============================] - 8s 162us/sample - loss: 0.3810 - accuracy: 0.9561 - val_loss: 1.2631 - val_accuracy: 0.7616\n",
      "Epoch 22/150\n",
      "47500/47500 [==============================] - 8s 162us/sample - loss: 0.3728 - accuracy: 0.9582 - val_loss: 1.2401 - val_accuracy: 0.7724\n",
      "Epoch 23/150\n",
      "47500/47500 [==============================] - 8s 162us/sample - loss: 0.3637 - accuracy: 0.9617 - val_loss: 1.2988 - val_accuracy: 0.7512\n",
      "Epoch 24/150\n",
      "47500/47500 [==============================] - 8s 162us/sample - loss: 0.3623 - accuracy: 0.9629 - val_loss: 1.2891 - val_accuracy: 0.7580\n",
      "Epoch 25/150\n",
      "47500/47500 [==============================] - 8s 162us/sample - loss: 0.3600 - accuracy: 0.9644 - val_loss: 1.3987 - val_accuracy: 0.7476\n",
      "Epoch 26/150\n",
      "47500/47500 [==============================] - 8s 163us/sample - loss: 0.3633 - accuracy: 0.9640 - val_loss: 1.3900 - val_accuracy: 0.7656\n",
      "##################################\n",
      "\n",
      "Training model_2_10:\n",
      "\n",
      "Train on 47500 samples, validate on 2500 samples\n",
      "Epoch 1/150\n",
      "47500/47500 [==============================] - 9s 194us/sample - loss: 1.6752 - accuracy: 0.4929 - val_loss: 2.6270 - val_accuracy: 0.3128\n",
      "Epoch 2/150\n",
      "47500/47500 [==============================] - 8s 162us/sample - loss: 1.2043 - accuracy: 0.6562 - val_loss: 1.1896 - val_accuracy: 0.6732\n",
      "Epoch 3/150\n",
      "47500/47500 [==============================] - 8s 162us/sample - loss: 0.9770 - accuracy: 0.7273 - val_loss: 1.5010 - val_accuracy: 0.6096\n",
      "Epoch 4/150\n",
      "47500/47500 [==============================] - 8s 162us/sample - loss: 0.8457 - accuracy: 0.7669 - val_loss: 0.9533 - val_accuracy: 0.7316\n",
      "Epoch 5/150\n",
      "47500/47500 [==============================] - 8s 162us/sample - loss: 0.7474 - accuracy: 0.8010 - val_loss: 1.0191 - val_accuracy: 0.7224\n",
      "Epoch 6/150\n",
      "47500/47500 [==============================] - 8s 162us/sample - loss: 0.6646 - accuracy: 0.8304 - val_loss: 1.0922 - val_accuracy: 0.7192\n",
      "Epoch 7/150\n",
      "47500/47500 [==============================] - 8s 163us/sample - loss: 0.6036 - accuracy: 0.8527 - val_loss: 0.9852 - val_accuracy: 0.7468\n",
      "Epoch 8/150\n",
      "47500/47500 [==============================] - 8s 162us/sample - loss: 0.5706 - accuracy: 0.8670 - val_loss: 0.9755 - val_accuracy: 0.7520\n",
      "Epoch 9/150\n",
      "47500/47500 [==============================] - 8s 162us/sample - loss: 0.5321 - accuracy: 0.8829 - val_loss: 0.9876 - val_accuracy: 0.7596\n",
      "Epoch 10/150\n",
      "47500/47500 [==============================] - 8s 162us/sample - loss: 0.5010 - accuracy: 0.8947 - val_loss: 1.0701 - val_accuracy: 0.7444\n",
      "Epoch 11/150\n",
      "47500/47500 [==============================] - 8s 162us/sample - loss: 0.4611 - accuracy: 0.9118 - val_loss: 1.1443 - val_accuracy: 0.7480\n",
      "Epoch 12/150\n",
      "47500/47500 [==============================] - 8s 162us/sample - loss: 0.4429 - accuracy: 0.9201 - val_loss: 1.1615 - val_accuracy: 0.7460\n",
      "Epoch 13/150\n",
      "47500/47500 [==============================] - 8s 162us/sample - loss: 0.4224 - accuracy: 0.9274 - val_loss: 1.1685 - val_accuracy: 0.7508\n",
      "Epoch 14/150\n",
      "47500/47500 [==============================] - 8s 162us/sample - loss: 0.4124 - accuracy: 0.9334 - val_loss: 1.1609 - val_accuracy: 0.7516\n",
      "Epoch 15/150\n",
      "47500/47500 [==============================] - 8s 162us/sample - loss: 0.4134 - accuracy: 0.9364 - val_loss: 1.1956 - val_accuracy: 0.7552\n",
      "Epoch 16/150\n",
      "47500/47500 [==============================] - 8s 162us/sample - loss: 0.4035 - accuracy: 0.9404 - val_loss: 1.2483 - val_accuracy: 0.7612\n",
      "Epoch 17/150\n",
      "47500/47500 [==============================] - 8s 162us/sample - loss: 0.3955 - accuracy: 0.9452 - val_loss: 1.2606 - val_accuracy: 0.7644\n",
      "Epoch 18/150\n",
      "47500/47500 [==============================] - 8s 162us/sample - loss: 0.3935 - accuracy: 0.9489 - val_loss: 1.2296 - val_accuracy: 0.7676\n",
      "Epoch 19/150\n",
      "47500/47500 [==============================] - 8s 162us/sample - loss: 0.3622 - accuracy: 0.9591 - val_loss: 1.3229 - val_accuracy: 0.7488\n",
      "Epoch 20/150\n",
      "47500/47500 [==============================] - 8s 162us/sample - loss: 0.4080 - accuracy: 0.9457 - val_loss: 1.1932 - val_accuracy: 0.7648\n",
      "Epoch 21/150\n",
      "47500/47500 [==============================] - 8s 162us/sample - loss: 0.3671 - accuracy: 0.9606 - val_loss: 1.2344 - val_accuracy: 0.7784\n",
      "Epoch 22/150\n",
      "47500/47500 [==============================] - 8s 162us/sample - loss: 0.3600 - accuracy: 0.9621 - val_loss: 1.2932 - val_accuracy: 0.7744\n",
      "Epoch 23/150\n",
      "47500/47500 [==============================] - 8s 162us/sample - loss: 0.3519 - accuracy: 0.9659 - val_loss: 1.3544 - val_accuracy: 0.7612\n",
      "Epoch 24/150\n",
      "47500/47500 [==============================] - 8s 162us/sample - loss: 0.3511 - accuracy: 0.9654 - val_loss: 1.3220 - val_accuracy: 0.7652\n"
     ]
    }
   ],
   "source": [
    "test_model_2(results, x_train, x_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model_3(results, x_train, x_test, y_train, y_test):\n",
    "    results['model_3'] = []\n",
    "    for iteration in range(1, 11):\n",
    "        \n",
    "        model_name = f'model_3_{iteration}'\n",
    "        \n",
    "        x_train, x_valid, y_train, y_valid = train_test_split(x_train_orig, y_train_orig, test_size=0.05)\n",
    "                \n",
    "        print('##################################')\n",
    "        print('')\n",
    "        print(f'Training {model_name}:')\n",
    "        print('')\n",
    "        \n",
    "        model = model_3.get_model()\n",
    "        \n",
    "        model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "        callback_earlystop = tf.keras.callbacks.EarlyStopping(patience=20,\n",
    "                                               monitor='val_loss',\n",
    "                                               mode='auto',\n",
    "                                               restore_best_weights=True)\n",
    "        \n",
    "        model.fit(x_train, y_train, batch_size=128,\n",
    "                      validation_data=(x_valid, y_valid),\n",
    "                      callbacks=[callback_earlystop],\n",
    "                      verbose=1,\n",
    "                      epochs=150)\n",
    "        \n",
    "        model.save(f'./models/no_aug/{model_name}.h5')\n",
    "        \n",
    "        y_proba = model.predict(x_test)\n",
    "        y_hat = np.zeros_like(y_proba)\n",
    "        y_hat[np.arange(y_proba.shape[0]), np.argmax(y_proba, axis=1)] = 1\n",
    "\n",
    "        model_acc = accuracy_score(y_hat, y_test)\n",
    "        results['model_3'].append(model_acc)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##################################\n",
      "\n",
      "Training model_3_1:\n",
      "\n",
      "Train on 47500 samples, validate on 2500 samples\n",
      "Epoch 1/150\n",
      "47500/47500 [==============================] - 15s 308us/sample - loss: 1.6895 - accuracy: 0.5090 - val_loss: 2.1557 - val_accuracy: 0.3648\n",
      "Epoch 2/150\n",
      "47500/47500 [==============================] - 12s 258us/sample - loss: 1.1577 - accuracy: 0.6914 - val_loss: 1.3217 - val_accuracy: 0.6532\n",
      "Epoch 3/150\n",
      "47500/47500 [==============================] - 12s 259us/sample - loss: 0.9310 - accuracy: 0.7632 - val_loss: 1.1038 - val_accuracy: 0.7160\n",
      "Epoch 4/150\n",
      "47500/47500 [==============================] - 12s 259us/sample - loss: 0.7910 - accuracy: 0.8090 - val_loss: 1.0340 - val_accuracy: 0.7368\n",
      "Epoch 5/150\n",
      "47500/47500 [==============================] - 12s 259us/sample - loss: 0.7035 - accuracy: 0.8351 - val_loss: 0.9414 - val_accuracy: 0.7620\n",
      "Epoch 6/150\n",
      "47500/47500 [==============================] - 12s 258us/sample - loss: 0.6338 - accuracy: 0.8608 - val_loss: 1.0236 - val_accuracy: 0.7636\n",
      "Epoch 7/150\n",
      "47500/47500 [==============================] - 12s 258us/sample - loss: 0.5923 - accuracy: 0.8787 - val_loss: 0.9628 - val_accuracy: 0.7744\n",
      "Epoch 8/150\n",
      "47500/47500 [==============================] - 12s 258us/sample - loss: 0.5584 - accuracy: 0.8926 - val_loss: 1.0416 - val_accuracy: 0.7672\n",
      "Epoch 9/150\n",
      "47500/47500 [==============================] - 12s 259us/sample - loss: 0.5168 - accuracy: 0.9101 - val_loss: 1.0497 - val_accuracy: 0.7672\n",
      "Epoch 10/150\n",
      "47500/47500 [==============================] - 12s 258us/sample - loss: 0.5115 - accuracy: 0.9174 - val_loss: 1.1409 - val_accuracy: 0.7704\n",
      "Epoch 11/150\n",
      "47500/47500 [==============================] - 12s 258us/sample - loss: 0.4890 - accuracy: 0.9273 - val_loss: 1.1155 - val_accuracy: 0.7700\n",
      "Epoch 12/150\n",
      "47500/47500 [==============================] - 12s 258us/sample - loss: 0.4774 - accuracy: 0.9344 - val_loss: 1.0267 - val_accuracy: 0.7880\n",
      "Epoch 13/150\n",
      "47500/47500 [==============================] - 12s 258us/sample - loss: 0.4600 - accuracy: 0.9436 - val_loss: 1.2622 - val_accuracy: 0.7700\n",
      "Epoch 14/150\n",
      "47500/47500 [==============================] - 12s 258us/sample - loss: 0.5216 - accuracy: 0.9310 - val_loss: 1.2986 - val_accuracy: 0.7492\n",
      "Epoch 15/150\n",
      "47500/47500 [==============================] - 12s 258us/sample - loss: 0.4882 - accuracy: 0.9435 - val_loss: 1.1413 - val_accuracy: 0.7852\n",
      "Epoch 16/150\n",
      "47500/47500 [==============================] - 12s 258us/sample - loss: 0.4727 - accuracy: 0.9516 - val_loss: 1.1788 - val_accuracy: 0.7940\n",
      "Epoch 17/150\n",
      "47500/47500 [==============================] - 12s 258us/sample - loss: 0.4375 - accuracy: 0.9608 - val_loss: 1.2129 - val_accuracy: 0.7884\n",
      "Epoch 18/150\n",
      "47500/47500 [==============================] - 12s 258us/sample - loss: 0.4402 - accuracy: 0.9599 - val_loss: 1.1575 - val_accuracy: 0.7920\n",
      "Epoch 19/150\n",
      "47500/47500 [==============================] - 12s 258us/sample - loss: 0.4391 - accuracy: 0.9608 - val_loss: 1.1782 - val_accuracy: 0.7808\n",
      "Epoch 20/150\n",
      "47500/47500 [==============================] - 12s 259us/sample - loss: 0.4427 - accuracy: 0.9605 - val_loss: 1.2113 - val_accuracy: 0.7984\n",
      "Epoch 21/150\n",
      "47500/47500 [==============================] - 12s 258us/sample - loss: 0.4266 - accuracy: 0.9659 - val_loss: 1.1878 - val_accuracy: 0.7916\n",
      "Epoch 22/150\n",
      "47500/47500 [==============================] - 12s 258us/sample - loss: 0.4260 - accuracy: 0.9662 - val_loss: 1.2282 - val_accuracy: 0.7812\n",
      "Epoch 23/150\n",
      "47500/47500 [==============================] - 12s 258us/sample - loss: 0.4355 - accuracy: 0.9632 - val_loss: 1.2456 - val_accuracy: 0.7824\n",
      "Epoch 24/150\n",
      "47500/47500 [==============================] - 12s 258us/sample - loss: 0.4371 - accuracy: 0.9649 - val_loss: 1.1997 - val_accuracy: 0.7976\n",
      "Epoch 25/150\n",
      "47500/47500 [==============================] - 12s 259us/sample - loss: 0.4463 - accuracy: 0.9625 - val_loss: 1.2050 - val_accuracy: 0.7968\n",
      "##################################\n",
      "\n",
      "Training model_3_2:\n",
      "\n",
      "Train on 47500 samples, validate on 2500 samples\n",
      "Epoch 1/150\n",
      "47500/47500 [==============================] - 13s 283us/sample - loss: 1.6630 - accuracy: 0.5185 - val_loss: 2.7153 - val_accuracy: 0.2624\n",
      "Epoch 2/150\n",
      "47500/47500 [==============================] - 12s 259us/sample - loss: 1.1492 - accuracy: 0.6947 - val_loss: 1.1356 - val_accuracy: 0.6972\n",
      "Epoch 3/150\n",
      "47500/47500 [==============================] - 12s 259us/sample - loss: 0.9303 - accuracy: 0.7637 - val_loss: 1.0094 - val_accuracy: 0.7436\n",
      "Epoch 4/150\n",
      "47500/47500 [==============================] - 12s 259us/sample - loss: 0.8033 - accuracy: 0.8026 - val_loss: 0.9797 - val_accuracy: 0.7496\n",
      "Epoch 5/150\n",
      "47500/47500 [==============================] - 12s 258us/sample - loss: 0.7066 - accuracy: 0.8343 - val_loss: 1.0370 - val_accuracy: 0.7460\n",
      "Epoch 6/150\n",
      "47500/47500 [==============================] - 12s 258us/sample - loss: 0.6405 - accuracy: 0.8593 - val_loss: 0.8559 - val_accuracy: 0.7832\n",
      "Epoch 7/150\n",
      "47500/47500 [==============================] - 12s 258us/sample - loss: 0.5998 - accuracy: 0.8742 - val_loss: 0.8713 - val_accuracy: 0.7976\n",
      "Epoch 8/150\n",
      "47500/47500 [==============================] - 13s 270us/sample - loss: 0.5639 - accuracy: 0.8899 - val_loss: 1.1506 - val_accuracy: 0.7388\n",
      "Epoch 9/150\n",
      "47500/47500 [==============================] - 15s 311us/sample - loss: 0.5193 - accuracy: 0.9078 - val_loss: 1.1507 - val_accuracy: 0.7504\n",
      "Epoch 10/150\n",
      "47500/47500 [==============================] - 14s 293us/sample - loss: 0.5198 - accuracy: 0.9112 - val_loss: 0.9880 - val_accuracy: 0.7744\n",
      "Epoch 11/150\n",
      "47500/47500 [==============================] - 14s 295us/sample - loss: 0.4790 - accuracy: 0.9293 - val_loss: 1.0045 - val_accuracy: 0.7928\n",
      "Epoch 12/150\n",
      "47500/47500 [==============================] - 14s 291us/sample - loss: 0.4924 - accuracy: 0.9284 - val_loss: 1.0192 - val_accuracy: 0.8008\n",
      "Epoch 13/150\n",
      "47500/47500 [==============================] - 14s 293us/sample - loss: 0.4721 - accuracy: 0.9399 - val_loss: 1.0840 - val_accuracy: 0.7964\n",
      "Epoch 14/150\n",
      "47500/47500 [==============================] - 14s 294us/sample - loss: 0.4897 - accuracy: 0.9387 - val_loss: 1.0122 - val_accuracy: 0.8068\n",
      "Epoch 15/150\n",
      "47500/47500 [==============================] - 14s 293us/sample - loss: 0.4665 - accuracy: 0.9476 - val_loss: 1.1897 - val_accuracy: 0.7796\n",
      "Epoch 16/150\n",
      "47500/47500 [==============================] - 14s 294us/sample - loss: 0.4408 - accuracy: 0.9571 - val_loss: 1.0291 - val_accuracy: 0.8096\n",
      "Epoch 17/150\n",
      "47500/47500 [==============================] - 14s 294us/sample - loss: 0.4362 - accuracy: 0.9583 - val_loss: 1.1003 - val_accuracy: 0.8016\n",
      "Epoch 18/150\n",
      "47500/47500 [==============================] - 14s 293us/sample - loss: 0.4592 - accuracy: 0.9541 - val_loss: 1.1215 - val_accuracy: 0.7944\n",
      "Epoch 19/150\n",
      "47500/47500 [==============================] - 14s 294us/sample - loss: 0.4711 - accuracy: 0.9533 - val_loss: 1.0802 - val_accuracy: 0.8232\n",
      "Epoch 20/150\n",
      "47500/47500 [==============================] - 14s 294us/sample - loss: 0.4325 - accuracy: 0.9657 - val_loss: 1.0816 - val_accuracy: 0.8032\n",
      "Epoch 21/150\n",
      "47500/47500 [==============================] - 14s 294us/sample - loss: 0.4803 - accuracy: 0.9538 - val_loss: 1.0135 - val_accuracy: 0.8224\n",
      "Epoch 22/150\n",
      "47500/47500 [==============================] - 14s 294us/sample - loss: 0.4545 - accuracy: 0.9623 - val_loss: 1.0531 - val_accuracy: 0.8220\n",
      "Epoch 23/150\n",
      "47500/47500 [==============================] - 14s 294us/sample - loss: 0.4796 - accuracy: 0.9565 - val_loss: 1.0724 - val_accuracy: 0.8172\n",
      "Epoch 24/150\n",
      "47500/47500 [==============================] - 14s 294us/sample - loss: 0.4538 - accuracy: 0.9651 - val_loss: 1.1845 - val_accuracy: 0.8000\n",
      "Epoch 25/150\n",
      "47500/47500 [==============================] - 14s 294us/sample - loss: 0.4472 - accuracy: 0.9669 - val_loss: 1.1410 - val_accuracy: 0.8044\n",
      "Epoch 26/150\n",
      "47500/47500 [==============================] - 14s 294us/sample - loss: 0.4432 - accuracy: 0.9673 - val_loss: 1.0605 - val_accuracy: 0.8096\n",
      "##################################\n",
      "\n",
      "Training model_3_3:\n",
      "\n",
      "Train on 47500 samples, validate on 2500 samples\n",
      "Epoch 1/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47500/47500 [==============================] - 15s 314us/sample - loss: 1.6848 - accuracy: 0.5147 - val_loss: 2.4243 - val_accuracy: 0.2824\n",
      "Epoch 2/150\n",
      "47500/47500 [==============================] - 13s 280us/sample - loss: 1.1592 - accuracy: 0.6895 - val_loss: 1.1829 - val_accuracy: 0.6832\n",
      "Epoch 3/150\n",
      "47500/47500 [==============================] - 13s 281us/sample - loss: 0.9457 - accuracy: 0.7589 - val_loss: 1.3354 - val_accuracy: 0.6548\n",
      "Epoch 4/150\n",
      "47500/47500 [==============================] - 13s 281us/sample - loss: 0.8006 - accuracy: 0.8052 - val_loss: 1.0627 - val_accuracy: 0.7192\n",
      "Epoch 5/150\n",
      "47500/47500 [==============================] - 13s 280us/sample - loss: 0.7114 - accuracy: 0.8343 - val_loss: 1.0640 - val_accuracy: 0.7396\n",
      "Epoch 6/150\n",
      "47500/47500 [==============================] - 13s 280us/sample - loss: 0.6433 - accuracy: 0.8587 - val_loss: 1.0051 - val_accuracy: 0.7568\n",
      "Epoch 7/150\n",
      "47500/47500 [==============================] - 13s 280us/sample - loss: 0.6161 - accuracy: 0.8725 - val_loss: 0.9690 - val_accuracy: 0.7784\n",
      "Epoch 8/150\n",
      "47500/47500 [==============================] - 13s 280us/sample - loss: 0.5560 - accuracy: 0.8944 - val_loss: 1.0134 - val_accuracy: 0.7728\n",
      "Epoch 9/150\n",
      "47500/47500 [==============================] - 13s 280us/sample - loss: 0.5219 - accuracy: 0.9088 - val_loss: 0.9876 - val_accuracy: 0.7708\n",
      "Epoch 10/150\n",
      "47500/47500 [==============================] - 13s 279us/sample - loss: 0.5004 - accuracy: 0.9214 - val_loss: 1.0441 - val_accuracy: 0.7832\n",
      "Epoch 11/150\n",
      "47500/47500 [==============================] - 13s 280us/sample - loss: 0.4794 - accuracy: 0.9303 - val_loss: 1.1459 - val_accuracy: 0.7936\n",
      "Epoch 12/150\n",
      "47500/47500 [==============================] - 13s 281us/sample - loss: 0.4711 - accuracy: 0.9360 - val_loss: 1.1155 - val_accuracy: 0.7864\n",
      "Epoch 13/150\n",
      "47500/47500 [==============================] - 13s 279us/sample - loss: 0.4619 - accuracy: 0.9417 - val_loss: 1.0534 - val_accuracy: 0.7980\n",
      "Epoch 14/150\n",
      "47500/47500 [==============================] - 13s 280us/sample - loss: 0.4740 - accuracy: 0.9404 - val_loss: 1.0734 - val_accuracy: 0.8004\n",
      "Epoch 15/150\n",
      "47500/47500 [==============================] - 13s 280us/sample - loss: 0.4445 - accuracy: 0.9523 - val_loss: 1.2134 - val_accuracy: 0.7772\n",
      "Epoch 16/150\n",
      "47500/47500 [==============================] - 13s 280us/sample - loss: 0.4489 - accuracy: 0.9531 - val_loss: 1.1640 - val_accuracy: 0.7872\n",
      "Epoch 17/150\n",
      "47500/47500 [==============================] - 13s 280us/sample - loss: 0.4609 - accuracy: 0.9520 - val_loss: 1.1758 - val_accuracy: 0.7968\n",
      "Epoch 18/150\n",
      "47500/47500 [==============================] - 13s 280us/sample - loss: 0.4549 - accuracy: 0.9567 - val_loss: 1.2305 - val_accuracy: 0.7912\n",
      "Epoch 19/150\n",
      "47500/47500 [==============================] - 13s 279us/sample - loss: 0.4386 - accuracy: 0.9616 - val_loss: 1.2397 - val_accuracy: 0.7924\n",
      "Epoch 20/150\n",
      "47500/47500 [==============================] - 13s 280us/sample - loss: 0.4327 - accuracy: 0.9644 - val_loss: 1.2727 - val_accuracy: 0.7876\n",
      "Epoch 21/150\n",
      "47500/47500 [==============================] - 13s 281us/sample - loss: 0.4571 - accuracy: 0.9581 - val_loss: 1.1255 - val_accuracy: 0.8008\n",
      "Epoch 22/150\n",
      "47500/47500 [==============================] - 13s 280us/sample - loss: 0.4390 - accuracy: 0.9637 - val_loss: 1.2177 - val_accuracy: 0.8020\n",
      "Epoch 23/150\n",
      "47500/47500 [==============================] - 13s 280us/sample - loss: 0.4653 - accuracy: 0.9592 - val_loss: 1.2865 - val_accuracy: 0.7880\n",
      "Epoch 24/150\n",
      "47500/47500 [==============================] - 13s 280us/sample - loss: 0.4213 - accuracy: 0.9702 - val_loss: 1.2340 - val_accuracy: 0.7764\n",
      "Epoch 25/150\n",
      "47500/47500 [==============================] - 13s 280us/sample - loss: 0.4237 - accuracy: 0.9699 - val_loss: 1.0455 - val_accuracy: 0.8224\n",
      "Epoch 26/150\n",
      "47500/47500 [==============================] - 13s 280us/sample - loss: 0.4231 - accuracy: 0.9686 - val_loss: 1.1869 - val_accuracy: 0.7996\n",
      "Epoch 27/150\n",
      "47500/47500 [==============================] - 13s 281us/sample - loss: 0.4172 - accuracy: 0.9705 - val_loss: 1.2611 - val_accuracy: 0.7960\n",
      "##################################\n",
      "\n",
      "Training model_3_4:\n",
      "\n",
      "Train on 47500 samples, validate on 2500 samples\n",
      "Epoch 1/150\n",
      "47500/47500 [==============================] - 19s 395us/sample - loss: 1.6493 - accuracy: 0.5244 - val_loss: 3.5689 - val_accuracy: 0.2984\n",
      "Epoch 2/150\n",
      "47500/47500 [==============================] - 12s 259us/sample - loss: 1.1340 - accuracy: 0.7008 - val_loss: 1.2710 - val_accuracy: 0.6604\n",
      "Epoch 3/150\n",
      "47500/47500 [==============================] - 12s 259us/sample - loss: 0.9335 - accuracy: 0.7645 - val_loss: 1.0649 - val_accuracy: 0.7140\n",
      "Epoch 4/150\n",
      "47500/47500 [==============================] - 12s 259us/sample - loss: 0.7962 - accuracy: 0.8066 - val_loss: 0.9494 - val_accuracy: 0.7440\n",
      "Epoch 5/150\n",
      "47500/47500 [==============================] - 12s 260us/sample - loss: 0.7102 - accuracy: 0.8361 - val_loss: 0.9021 - val_accuracy: 0.7768\n",
      "Epoch 6/150\n",
      "47500/47500 [==============================] - 12s 259us/sample - loss: 0.6437 - accuracy: 0.8566 - val_loss: 0.9155 - val_accuracy: 0.7752\n",
      "Epoch 7/150\n",
      "47500/47500 [==============================] - 12s 259us/sample - loss: 0.5945 - accuracy: 0.8785 - val_loss: 1.0311 - val_accuracy: 0.7596\n",
      "Epoch 8/150\n",
      "47500/47500 [==============================] - 12s 259us/sample - loss: 0.5401 - accuracy: 0.8992 - val_loss: 0.9579 - val_accuracy: 0.7864\n",
      "Epoch 9/150\n",
      "47500/47500 [==============================] - 12s 259us/sample - loss: 0.5367 - accuracy: 0.9034 - val_loss: 0.9122 - val_accuracy: 0.8076\n",
      "Epoch 10/150\n",
      "47500/47500 [==============================] - 12s 259us/sample - loss: 0.5046 - accuracy: 0.9193 - val_loss: 0.9894 - val_accuracy: 0.7788\n",
      "Epoch 11/150\n",
      "47500/47500 [==============================] - 12s 259us/sample - loss: 0.4872 - accuracy: 0.9292 - val_loss: 1.0293 - val_accuracy: 0.7928\n",
      "Epoch 12/150\n",
      "47500/47500 [==============================] - 12s 259us/sample - loss: 0.4624 - accuracy: 0.9403 - val_loss: 0.9807 - val_accuracy: 0.7996\n",
      "Epoch 13/150\n",
      "47500/47500 [==============================] - 12s 259us/sample - loss: 0.5086 - accuracy: 0.9315 - val_loss: 1.0448 - val_accuracy: 0.7920\n",
      "Epoch 14/150\n",
      "47500/47500 [==============================] - 12s 259us/sample - loss: 0.4677 - accuracy: 0.9463 - val_loss: 1.0723 - val_accuracy: 0.7892\n",
      "Epoch 15/150\n",
      "47500/47500 [==============================] - 12s 259us/sample - loss: 0.4743 - accuracy: 0.9460 - val_loss: 1.0126 - val_accuracy: 0.8160\n",
      "Epoch 16/150\n",
      "47500/47500 [==============================] - 12s 259us/sample - loss: 0.4780 - accuracy: 0.9471 - val_loss: 1.0593 - val_accuracy: 0.8096\n",
      "Epoch 17/150\n",
      "47500/47500 [==============================] - 12s 259us/sample - loss: 0.4418 - accuracy: 0.9602 - val_loss: 1.1501 - val_accuracy: 0.8108\n",
      "Epoch 18/150\n",
      "47500/47500 [==============================] - 12s 259us/sample - loss: 0.4327 - accuracy: 0.9623 - val_loss: 1.2085 - val_accuracy: 0.7828\n",
      "Epoch 19/150\n",
      "47500/47500 [==============================] - 12s 259us/sample - loss: 0.4537 - accuracy: 0.9584 - val_loss: 1.1853 - val_accuracy: 0.7936\n",
      "Epoch 20/150\n",
      "47500/47500 [==============================] - 12s 259us/sample - loss: 0.4278 - accuracy: 0.9653 - val_loss: 1.0916 - val_accuracy: 0.8184\n",
      "Epoch 21/150\n",
      "47500/47500 [==============================] - 12s 259us/sample - loss: 0.4459 - accuracy: 0.9606 - val_loss: 1.1045 - val_accuracy: 0.8032\n",
      "Epoch 22/150\n",
      "47500/47500 [==============================] - 12s 259us/sample - loss: 0.4529 - accuracy: 0.9602 - val_loss: 1.1474 - val_accuracy: 0.8040\n",
      "Epoch 23/150\n",
      "47500/47500 [==============================] - 12s 259us/sample - loss: 0.4967 - accuracy: 0.9521 - val_loss: 1.4054 - val_accuracy: 0.7660\n",
      "Epoch 24/150\n",
      "47500/47500 [==============================] - 12s 259us/sample - loss: 0.4514 - accuracy: 0.9645 - val_loss: 1.1273 - val_accuracy: 0.8108\n",
      "Epoch 25/150\n",
      "47500/47500 [==============================] - 12s 259us/sample - loss: 0.4157 - accuracy: 0.9742 - val_loss: 1.1087 - val_accuracy: 0.8104\n",
      "##################################\n",
      "\n",
      "Training model_3_5:\n",
      "\n",
      "Train on 47500 samples, validate on 2500 samples\n",
      "Epoch 1/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47500/47500 [==============================] - 13s 283us/sample - loss: 1.6557 - accuracy: 0.5231 - val_loss: 2.9062 - val_accuracy: 0.2240\n",
      "Epoch 2/150\n",
      "47500/47500 [==============================] - 12s 258us/sample - loss: 1.1370 - accuracy: 0.6984 - val_loss: 1.1580 - val_accuracy: 0.6984\n",
      "Epoch 3/150\n",
      "47500/47500 [==============================] - 12s 258us/sample - loss: 0.9253 - accuracy: 0.7677 - val_loss: 1.0009 - val_accuracy: 0.7364\n",
      "Epoch 4/150\n",
      "47500/47500 [==============================] - 12s 259us/sample - loss: 0.7946 - accuracy: 0.8087 - val_loss: 0.9976 - val_accuracy: 0.7252\n",
      "Epoch 5/150\n",
      "47500/47500 [==============================] - 12s 258us/sample - loss: 0.7148 - accuracy: 0.8338 - val_loss: 1.0515 - val_accuracy: 0.7324\n",
      "Epoch 6/150\n",
      "47500/47500 [==============================] - 12s 259us/sample - loss: 0.6428 - accuracy: 0.8601 - val_loss: 0.9522 - val_accuracy: 0.7532\n",
      "Epoch 7/150\n",
      "47500/47500 [==============================] - 12s 259us/sample - loss: 0.5859 - accuracy: 0.8800 - val_loss: 0.9421 - val_accuracy: 0.7796\n",
      "Epoch 8/150\n",
      "47500/47500 [==============================] - 12s 258us/sample - loss: 0.5581 - accuracy: 0.8928 - val_loss: 1.0407 - val_accuracy: 0.7712\n",
      "Epoch 9/150\n",
      "47500/47500 [==============================] - 12s 258us/sample - loss: 0.5382 - accuracy: 0.9045 - val_loss: 0.9006 - val_accuracy: 0.7984\n",
      "Epoch 10/150\n",
      "47500/47500 [==============================] - 12s 258us/sample - loss: 0.5074 - accuracy: 0.9170 - val_loss: 1.0829 - val_accuracy: 0.7808\n",
      "Epoch 11/150\n",
      "47500/47500 [==============================] - 12s 258us/sample - loss: 0.4869 - accuracy: 0.9284 - val_loss: 0.9502 - val_accuracy: 0.7888\n",
      "Epoch 12/150\n",
      "47500/47500 [==============================] - 12s 258us/sample - loss: 0.4686 - accuracy: 0.9365 - val_loss: 1.0279 - val_accuracy: 0.7952\n",
      "Epoch 13/150\n",
      "47500/47500 [==============================] - 12s 258us/sample - loss: 0.4623 - accuracy: 0.9417 - val_loss: 1.0566 - val_accuracy: 0.7996\n",
      "Epoch 14/150\n",
      "47500/47500 [==============================] - 12s 258us/sample - loss: 0.4525 - accuracy: 0.9478 - val_loss: 1.0131 - val_accuracy: 0.7984\n",
      "Epoch 15/150\n",
      "47500/47500 [==============================] - 12s 258us/sample - loss: 0.4737 - accuracy: 0.9439 - val_loss: 1.0346 - val_accuracy: 0.8052\n",
      "Epoch 16/150\n",
      "47500/47500 [==============================] - 12s 259us/sample - loss: 0.4428 - accuracy: 0.9552 - val_loss: 1.1982 - val_accuracy: 0.7912\n",
      "Epoch 17/150\n",
      "47500/47500 [==============================] - 12s 258us/sample - loss: 0.5034 - accuracy: 0.9422 - val_loss: 1.0956 - val_accuracy: 0.7992\n",
      "Epoch 18/150\n",
      "47500/47500 [==============================] - 12s 258us/sample - loss: 0.4789 - accuracy: 0.9518 - val_loss: 1.1133 - val_accuracy: 0.8040\n",
      "Epoch 19/150\n",
      "47500/47500 [==============================] - 12s 258us/sample - loss: 0.4300 - accuracy: 0.9657 - val_loss: 1.1444 - val_accuracy: 0.8132\n",
      "Epoch 20/150\n",
      "47500/47500 [==============================] - 12s 258us/sample - loss: 0.4338 - accuracy: 0.9636 - val_loss: 1.0951 - val_accuracy: 0.8200\n",
      "Epoch 21/150\n",
      "47500/47500 [==============================] - 12s 258us/sample - loss: 0.4406 - accuracy: 0.9626 - val_loss: 1.1960 - val_accuracy: 0.7868\n",
      "Epoch 22/150\n",
      "47500/47500 [==============================] - 12s 258us/sample - loss: 0.4531 - accuracy: 0.9599 - val_loss: 1.0667 - val_accuracy: 0.8036\n",
      "Epoch 23/150\n",
      "47500/47500 [==============================] - 12s 258us/sample - loss: 0.4321 - accuracy: 0.9666 - val_loss: 1.1252 - val_accuracy: 0.8032\n",
      "Epoch 24/150\n",
      "47500/47500 [==============================] - 12s 258us/sample - loss: 0.4128 - accuracy: 0.9714 - val_loss: 1.1589 - val_accuracy: 0.8096\n",
      "Epoch 25/150\n",
      "47500/47500 [==============================] - 12s 258us/sample - loss: 0.4378 - accuracy: 0.9642 - val_loss: 1.1208 - val_accuracy: 0.8100\n",
      "Epoch 26/150\n",
      "47500/47500 [==============================] - 12s 258us/sample - loss: 0.4245 - accuracy: 0.9691 - val_loss: 1.1990 - val_accuracy: 0.7872\n",
      "Epoch 27/150\n",
      "47500/47500 [==============================] - 12s 258us/sample - loss: 0.4309 - accuracy: 0.9689 - val_loss: 1.2855 - val_accuracy: 0.7924\n",
      "Epoch 28/150\n",
      "47500/47500 [==============================] - 12s 258us/sample - loss: 0.4346 - accuracy: 0.9669 - val_loss: 1.0552 - val_accuracy: 0.8220\n",
      "Epoch 29/150\n",
      "47500/47500 [==============================] - 12s 258us/sample - loss: 0.4370 - accuracy: 0.9681 - val_loss: 1.0473 - val_accuracy: 0.8236\n",
      "##################################\n",
      "\n",
      "Training model_3_6:\n",
      "\n",
      "Train on 47500 samples, validate on 2500 samples\n",
      "Epoch 1/150\n",
      "47500/47500 [==============================] - 14s 293us/sample - loss: 1.6677 - accuracy: 0.5184 - val_loss: 2.9534 - val_accuracy: 0.2548\n",
      "Epoch 2/150\n",
      "47500/47500 [==============================] - 12s 259us/sample - loss: 1.1584 - accuracy: 0.6918 - val_loss: 1.2078 - val_accuracy: 0.6892\n",
      "Epoch 3/150\n",
      "47500/47500 [==============================] - 12s 259us/sample - loss: 0.9443 - accuracy: 0.7616 - val_loss: 1.0618 - val_accuracy: 0.7244\n",
      "Epoch 4/150\n",
      "47500/47500 [==============================] - 12s 259us/sample - loss: 0.7977 - accuracy: 0.8048 - val_loss: 1.0229 - val_accuracy: 0.7372\n",
      "Epoch 5/150\n",
      "47500/47500 [==============================] - 12s 259us/sample - loss: 0.7064 - accuracy: 0.8342 - val_loss: 0.9440 - val_accuracy: 0.7556\n",
      "Epoch 6/150\n",
      "47500/47500 [==============================] - 12s 259us/sample - loss: 0.6452 - accuracy: 0.8569 - val_loss: 1.0012 - val_accuracy: 0.7488\n",
      "Epoch 7/150\n",
      "47500/47500 [==============================] - 12s 259us/sample - loss: 0.6025 - accuracy: 0.8749 - val_loss: 0.9304 - val_accuracy: 0.7824\n",
      "Epoch 8/150\n",
      "47500/47500 [==============================] - 12s 259us/sample - loss: 0.5993 - accuracy: 0.8827 - val_loss: 0.9756 - val_accuracy: 0.7764\n",
      "Epoch 9/150\n",
      "47500/47500 [==============================] - 12s 259us/sample - loss: 0.5208 - accuracy: 0.9107 - val_loss: 0.9056 - val_accuracy: 0.8084\n",
      "Epoch 10/150\n",
      "47500/47500 [==============================] - 12s 258us/sample - loss: 0.4906 - accuracy: 0.9213 - val_loss: 1.0039 - val_accuracy: 0.7956\n",
      "Epoch 11/150\n",
      "47500/47500 [==============================] - 12s 259us/sample - loss: 0.4773 - accuracy: 0.9312 - val_loss: 1.2446 - val_accuracy: 0.7564\n",
      "Epoch 12/150\n",
      "47500/47500 [==============================] - 12s 258us/sample - loss: 0.4697 - accuracy: 0.9358 - val_loss: 1.0942 - val_accuracy: 0.7924\n",
      "Epoch 13/150\n",
      "47500/47500 [==============================] - 12s 259us/sample - loss: 0.4698 - accuracy: 0.9391 - val_loss: 1.1150 - val_accuracy: 0.7812\n",
      "Epoch 14/150\n",
      "47500/47500 [==============================] - 12s 259us/sample - loss: 0.4618 - accuracy: 0.9434 - val_loss: 1.1752 - val_accuracy: 0.7996\n",
      "Epoch 15/150\n",
      "47500/47500 [==============================] - 12s 259us/sample - loss: 0.4666 - accuracy: 0.9467 - val_loss: 1.0302 - val_accuracy: 0.8056\n",
      "Epoch 16/150\n",
      "47500/47500 [==============================] - 12s 259us/sample - loss: 0.4665 - accuracy: 0.9485 - val_loss: 1.0761 - val_accuracy: 0.8132\n",
      "Epoch 17/150\n",
      "47500/47500 [==============================] - 12s 258us/sample - loss: 0.4273 - accuracy: 0.9606 - val_loss: 1.0307 - val_accuracy: 0.8036\n",
      "Epoch 18/150\n",
      "47500/47500 [==============================] - 12s 259us/sample - loss: 0.4551 - accuracy: 0.9533 - val_loss: 1.0730 - val_accuracy: 0.8108\n",
      "Epoch 19/150\n",
      "47500/47500 [==============================] - 12s 259us/sample - loss: 0.4214 - accuracy: 0.9643 - val_loss: 1.1115 - val_accuracy: 0.8040\n",
      "Epoch 20/150\n",
      "47500/47500 [==============================] - 12s 258us/sample - loss: 0.4425 - accuracy: 0.9609 - val_loss: 1.1159 - val_accuracy: 0.8064\n",
      "Epoch 21/150\n",
      "47500/47500 [==============================] - 12s 259us/sample - loss: 0.4376 - accuracy: 0.9625 - val_loss: 1.2285 - val_accuracy: 0.7952\n",
      "Epoch 22/150\n",
      "47500/47500 [==============================] - 12s 258us/sample - loss: 0.4796 - accuracy: 0.9513 - val_loss: 1.2251 - val_accuracy: 0.7904\n",
      "Epoch 23/150\n",
      "47500/47500 [==============================] - 12s 259us/sample - loss: 0.4372 - accuracy: 0.9678 - val_loss: 1.1793 - val_accuracy: 0.7948\n",
      "Epoch 24/150\n",
      "47500/47500 [==============================] - 12s 258us/sample - loss: 0.4334 - accuracy: 0.9667 - val_loss: 1.1399 - val_accuracy: 0.8032\n",
      "Epoch 25/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47500/47500 [==============================] - 12s 259us/sample - loss: 0.4479 - accuracy: 0.9642 - val_loss: 1.0930 - val_accuracy: 0.8200\n",
      "Epoch 26/150\n",
      "47500/47500 [==============================] - 12s 259us/sample - loss: 0.4307 - accuracy: 0.9680 - val_loss: 1.1936 - val_accuracy: 0.7972\n",
      "Epoch 27/150\n",
      "47500/47500 [==============================] - 13s 277us/sample - loss: 0.4166 - accuracy: 0.9708 - val_loss: 1.2099 - val_accuracy: 0.7960\n",
      "Epoch 28/150\n",
      "47500/47500 [==============================] - 15s 308us/sample - loss: 0.4210 - accuracy: 0.9704 - val_loss: 1.1326 - val_accuracy: 0.8116\n",
      "Epoch 29/150\n",
      "47500/47500 [==============================] - 15s 311us/sample - loss: 0.4143 - accuracy: 0.9718 - val_loss: 1.1009 - val_accuracy: 0.8132\n",
      "##################################\n",
      "\n",
      "Training model_3_7:\n",
      "\n",
      "Train on 47500 samples, validate on 2500 samples\n",
      "Epoch 1/150\n",
      "47500/47500 [==============================] - 15s 310us/sample - loss: 1.6446 - accuracy: 0.5255 - val_loss: 3.5220 - val_accuracy: 0.1964\n",
      "Epoch 2/150\n",
      "47500/47500 [==============================] - 14s 285us/sample - loss: 1.1353 - accuracy: 0.6989 - val_loss: 1.1850 - val_accuracy: 0.6876\n",
      "Epoch 3/150\n",
      "47500/47500 [==============================] - 14s 284us/sample - loss: 0.9159 - accuracy: 0.7675 - val_loss: 1.0364 - val_accuracy: 0.7220\n",
      "Epoch 4/150\n",
      "47500/47500 [==============================] - 14s 285us/sample - loss: 0.7934 - accuracy: 0.8068 - val_loss: 1.0222 - val_accuracy: 0.7504\n",
      "Epoch 5/150\n",
      "47500/47500 [==============================] - 14s 285us/sample - loss: 0.6962 - accuracy: 0.8405 - val_loss: 0.9702 - val_accuracy: 0.7720\n",
      "Epoch 6/150\n",
      "47500/47500 [==============================] - 14s 287us/sample - loss: 0.6340 - accuracy: 0.8603 - val_loss: 0.9514 - val_accuracy: 0.7632\n",
      "Epoch 7/150\n",
      "47500/47500 [==============================] - 14s 285us/sample - loss: 0.5886 - accuracy: 0.8801 - val_loss: 0.9766 - val_accuracy: 0.7644\n",
      "Epoch 8/150\n",
      "47500/47500 [==============================] - 14s 285us/sample - loss: 0.5508 - accuracy: 0.8951 - val_loss: 0.9664 - val_accuracy: 0.7740\n",
      "Epoch 9/150\n",
      "47500/47500 [==============================] - 14s 285us/sample - loss: 0.5389 - accuracy: 0.9050 - val_loss: 0.9216 - val_accuracy: 0.8088\n",
      "Epoch 10/150\n",
      "47500/47500 [==============================] - 14s 285us/sample - loss: 0.4880 - accuracy: 0.9231 - val_loss: 1.1273 - val_accuracy: 0.7584\n",
      "Epoch 11/150\n",
      "47500/47500 [==============================] - 14s 285us/sample - loss: 0.5029 - accuracy: 0.9234 - val_loss: 1.0479 - val_accuracy: 0.7884\n",
      "Epoch 12/150\n",
      "47500/47500 [==============================] - 14s 285us/sample - loss: 0.4829 - accuracy: 0.9333 - val_loss: 1.0403 - val_accuracy: 0.7860\n",
      "Epoch 13/150\n",
      "47500/47500 [==============================] - 14s 284us/sample - loss: 0.4672 - accuracy: 0.9419 - val_loss: 1.1167 - val_accuracy: 0.7916\n",
      "Epoch 14/150\n",
      "47500/47500 [==============================] - 14s 286us/sample - loss: 0.4696 - accuracy: 0.9435 - val_loss: 1.0420 - val_accuracy: 0.7988\n",
      "Epoch 15/150\n",
      "47500/47500 [==============================] - 14s 284us/sample - loss: 0.4709 - accuracy: 0.9447 - val_loss: 1.0957 - val_accuracy: 0.7892\n",
      "Epoch 16/150\n",
      "47500/47500 [==============================] - 14s 284us/sample - loss: 0.4898 - accuracy: 0.9437 - val_loss: 1.0812 - val_accuracy: 0.7956\n",
      "Epoch 17/150\n",
      "47500/47500 [==============================] - 13s 284us/sample - loss: 0.4545 - accuracy: 0.9563 - val_loss: 1.1972 - val_accuracy: 0.7940\n",
      "Epoch 18/150\n",
      "47500/47500 [==============================] - 14s 284us/sample - loss: 0.4939 - accuracy: 0.9459 - val_loss: 1.1636 - val_accuracy: 0.8004\n",
      "Epoch 19/150\n",
      "47500/47500 [==============================] - 14s 285us/sample - loss: 0.4389 - accuracy: 0.9638 - val_loss: 1.2406 - val_accuracy: 0.7972\n",
      "Epoch 20/150\n",
      "47500/47500 [==============================] - 14s 284us/sample - loss: 0.4521 - accuracy: 0.9606 - val_loss: 1.1059 - val_accuracy: 0.7976\n",
      "Epoch 21/150\n",
      "47500/47500 [==============================] - 14s 284us/sample - loss: 0.4255 - accuracy: 0.9689 - val_loss: 1.1255 - val_accuracy: 0.8096\n",
      "Epoch 22/150\n",
      "47500/47500 [==============================] - 14s 284us/sample - loss: 0.4268 - accuracy: 0.9669 - val_loss: 1.0908 - val_accuracy: 0.8040\n",
      "Epoch 23/150\n",
      "47500/47500 [==============================] - 14s 285us/sample - loss: 0.4631 - accuracy: 0.9578 - val_loss: 1.2866 - val_accuracy: 0.7872\n",
      "Epoch 24/150\n",
      "47500/47500 [==============================] - 13s 284us/sample - loss: 0.4428 - accuracy: 0.9653 - val_loss: 1.2278 - val_accuracy: 0.7992\n",
      "Epoch 25/150\n",
      "47500/47500 [==============================] - 13s 284us/sample - loss: 0.4406 - accuracy: 0.9672 - val_loss: 1.1237 - val_accuracy: 0.8168\n",
      "Epoch 26/150\n",
      "47500/47500 [==============================] - 14s 285us/sample - loss: 0.4543 - accuracy: 0.9624 - val_loss: 1.1008 - val_accuracy: 0.8152\n",
      "Epoch 27/150\n",
      "47500/47500 [==============================] - 14s 284us/sample - loss: 0.4218 - accuracy: 0.9714 - val_loss: 1.1451 - val_accuracy: 0.8032\n",
      "Epoch 28/150\n",
      "47500/47500 [==============================] - 14s 284us/sample - loss: 0.4112 - accuracy: 0.9740 - val_loss: 1.0834 - val_accuracy: 0.8164\n",
      "Epoch 29/150\n",
      "47500/47500 [==============================] - 14s 285us/sample - loss: 0.4162 - accuracy: 0.9711 - val_loss: 1.1730 - val_accuracy: 0.8048\n",
      "##################################\n",
      "\n",
      "Training model_3_8:\n",
      "\n",
      "Train on 47500 samples, validate on 2500 samples\n",
      "Epoch 1/150\n",
      "47500/47500 [==============================] - 15s 310us/sample - loss: 1.6743 - accuracy: 0.5083 - val_loss: 2.6298 - val_accuracy: 0.2676\n",
      "Epoch 2/150\n",
      "47500/47500 [==============================] - 14s 285us/sample - loss: 1.1530 - accuracy: 0.6908 - val_loss: 1.3733 - val_accuracy: 0.6132\n",
      "Epoch 3/150\n",
      "47500/47500 [==============================] - 14s 286us/sample - loss: 0.9332 - accuracy: 0.7615 - val_loss: 1.0210 - val_accuracy: 0.7408\n",
      "Epoch 4/150\n",
      "47500/47500 [==============================] - 14s 285us/sample - loss: 0.7977 - accuracy: 0.8046 - val_loss: 1.0877 - val_accuracy: 0.7204\n",
      "Epoch 5/150\n",
      "47500/47500 [==============================] - 14s 284us/sample - loss: 0.7125 - accuracy: 0.8330 - val_loss: 1.1046 - val_accuracy: 0.7200\n",
      "Epoch 6/150\n",
      "47500/47500 [==============================] - 14s 284us/sample - loss: 0.6540 - accuracy: 0.8537 - val_loss: 0.9707 - val_accuracy: 0.7640\n",
      "Epoch 7/150\n",
      "47500/47500 [==============================] - 14s 285us/sample - loss: 0.5817 - accuracy: 0.8819 - val_loss: 1.2159 - val_accuracy: 0.7372\n",
      "Epoch 8/150\n",
      "47500/47500 [==============================] - 14s 284us/sample - loss: 0.5623 - accuracy: 0.8925 - val_loss: 1.0568 - val_accuracy: 0.7468\n",
      "Epoch 9/150\n",
      "47500/47500 [==============================] - 14s 285us/sample - loss: 0.5501 - accuracy: 0.8999 - val_loss: 0.9857 - val_accuracy: 0.7904\n",
      "Epoch 10/150\n",
      "47500/47500 [==============================] - 14s 285us/sample - loss: 0.5479 - accuracy: 0.9082 - val_loss: 0.9918 - val_accuracy: 0.7832\n",
      "Epoch 11/150\n",
      "47500/47500 [==============================] - 14s 284us/sample - loss: 0.4940 - accuracy: 0.9272 - val_loss: 1.0120 - val_accuracy: 0.7984\n",
      "Epoch 12/150\n",
      "47500/47500 [==============================] - 14s 285us/sample - loss: 0.4707 - accuracy: 0.9376 - val_loss: 1.0942 - val_accuracy: 0.7876\n",
      "Epoch 13/150\n",
      "47500/47500 [==============================] - 14s 284us/sample - loss: 0.4554 - accuracy: 0.9443 - val_loss: 1.0751 - val_accuracy: 0.7944\n",
      "Epoch 14/150\n",
      "47500/47500 [==============================] - 13s 284us/sample - loss: 0.4623 - accuracy: 0.9445 - val_loss: 1.5256 - val_accuracy: 0.7216\n",
      "Epoch 15/150\n",
      "47500/47500 [==============================] - 16s 328us/sample - loss: 0.4784 - accuracy: 0.9449 - val_loss: 1.0943 - val_accuracy: 0.8040\n",
      "Epoch 16/150\n",
      "47500/47500 [==============================] - 13s 268us/sample - loss: 0.4479 - accuracy: 0.9558 - val_loss: 1.1889 - val_accuracy: 0.7940\n",
      "Epoch 17/150\n",
      "47500/47500 [==============================] - 12s 259us/sample - loss: 0.4469 - accuracy: 0.9567 - val_loss: 1.0801 - val_accuracy: 0.8068\n",
      "Epoch 18/150\n",
      "47500/47500 [==============================] - 12s 258us/sample - loss: 0.4382 - accuracy: 0.9608 - val_loss: 1.1043 - val_accuracy: 0.8128\n",
      "Epoch 19/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47500/47500 [==============================] - 12s 258us/sample - loss: 0.4364 - accuracy: 0.9615 - val_loss: 1.1801 - val_accuracy: 0.7840\n",
      "Epoch 20/150\n",
      "47500/47500 [==============================] - 12s 258us/sample - loss: 0.4385 - accuracy: 0.9613 - val_loss: 1.0898 - val_accuracy: 0.8100\n",
      "Epoch 21/150\n",
      "47500/47500 [==============================] - 12s 259us/sample - loss: 0.4386 - accuracy: 0.9627 - val_loss: 1.1239 - val_accuracy: 0.8028\n",
      "Epoch 22/150\n",
      "47500/47500 [==============================] - 12s 258us/sample - loss: 0.4699 - accuracy: 0.9555 - val_loss: 1.0751 - val_accuracy: 0.8136\n",
      "Epoch 23/150\n",
      "47500/47500 [==============================] - 12s 258us/sample - loss: 0.4414 - accuracy: 0.9644 - val_loss: 1.2069 - val_accuracy: 0.8016\n",
      "Epoch 24/150\n",
      "47500/47500 [==============================] - 12s 259us/sample - loss: 0.4528 - accuracy: 0.9611 - val_loss: 1.0854 - val_accuracy: 0.8124\n",
      "Epoch 25/150\n",
      "47500/47500 [==============================] - 12s 258us/sample - loss: 0.4361 - accuracy: 0.9675 - val_loss: 1.2536 - val_accuracy: 0.7888\n",
      "Epoch 26/150\n",
      "47500/47500 [==============================] - 12s 259us/sample - loss: 0.4611 - accuracy: 0.9611 - val_loss: 1.0377 - val_accuracy: 0.8140\n",
      "##################################\n",
      "\n",
      "Training model_3_9:\n",
      "\n",
      "Train on 47500 samples, validate on 2500 samples\n",
      "Epoch 1/150\n",
      "47500/47500 [==============================] - 14s 293us/sample - loss: 1.6903 - accuracy: 0.5119 - val_loss: 2.8072 - val_accuracy: 0.2520\n",
      "Epoch 2/150\n",
      "47500/47500 [==============================] - 12s 258us/sample - loss: 1.1625 - accuracy: 0.6926 - val_loss: 1.1923 - val_accuracy: 0.6908\n",
      "Epoch 3/150\n",
      "47500/47500 [==============================] - 12s 259us/sample - loss: 0.9391 - accuracy: 0.7619 - val_loss: 1.1221 - val_accuracy: 0.7136\n",
      "Epoch 4/150\n",
      "47500/47500 [==============================] - 12s 259us/sample - loss: 0.8090 - accuracy: 0.8019 - val_loss: 0.9694 - val_accuracy: 0.7624\n",
      "Epoch 5/150\n",
      "47500/47500 [==============================] - 12s 259us/sample - loss: 0.7151 - accuracy: 0.8324 - val_loss: 0.8871 - val_accuracy: 0.7948\n",
      "Epoch 6/150\n",
      "47500/47500 [==============================] - 12s 258us/sample - loss: 0.6448 - accuracy: 0.8573 - val_loss: 0.9474 - val_accuracy: 0.7764\n",
      "Epoch 7/150\n",
      "47500/47500 [==============================] - 12s 259us/sample - loss: 0.5882 - accuracy: 0.8772 - val_loss: 0.9619 - val_accuracy: 0.7600\n",
      "Epoch 8/150\n",
      "47500/47500 [==============================] - 12s 258us/sample - loss: 0.5588 - accuracy: 0.8920 - val_loss: 0.9188 - val_accuracy: 0.7852\n",
      "Epoch 9/150\n",
      "47500/47500 [==============================] - 12s 258us/sample - loss: 0.5211 - accuracy: 0.9083 - val_loss: 0.9188 - val_accuracy: 0.7984\n",
      "Epoch 10/150\n",
      "47500/47500 [==============================] - 12s 258us/sample - loss: 0.5044 - accuracy: 0.9167 - val_loss: 0.9707 - val_accuracy: 0.8104\n",
      "Epoch 11/150\n",
      "47500/47500 [==============================] - 12s 258us/sample - loss: 0.4876 - accuracy: 0.9256 - val_loss: 0.9434 - val_accuracy: 0.7992\n",
      "Epoch 12/150\n",
      "47500/47500 [==============================] - 12s 258us/sample - loss: 0.4696 - accuracy: 0.9367 - val_loss: 1.0315 - val_accuracy: 0.7968\n",
      "Epoch 13/150\n",
      "47500/47500 [==============================] - 12s 258us/sample - loss: 0.5020 - accuracy: 0.9280 - val_loss: 0.9886 - val_accuracy: 0.8008\n",
      "Epoch 14/150\n",
      "47500/47500 [==============================] - 12s 258us/sample - loss: 0.4757 - accuracy: 0.9425 - val_loss: 1.0117 - val_accuracy: 0.8108\n",
      "Epoch 15/150\n",
      "47500/47500 [==============================] - 12s 258us/sample - loss: 0.4522 - accuracy: 0.9499 - val_loss: 1.0240 - val_accuracy: 0.8020\n",
      "Epoch 16/150\n",
      "47500/47500 [==============================] - 12s 258us/sample - loss: 0.4464 - accuracy: 0.9538 - val_loss: 1.0000 - val_accuracy: 0.8196\n",
      "Epoch 17/150\n",
      "47500/47500 [==============================] - 12s 258us/sample - loss: 0.4390 - accuracy: 0.9579 - val_loss: 1.0640 - val_accuracy: 0.8244\n",
      "Epoch 18/150\n",
      "47500/47500 [==============================] - 12s 258us/sample - loss: 0.4443 - accuracy: 0.9577 - val_loss: 1.0247 - val_accuracy: 0.8220\n",
      "Epoch 19/150\n",
      "47500/47500 [==============================] - 12s 258us/sample - loss: 0.4369 - accuracy: 0.9607 - val_loss: 1.1285 - val_accuracy: 0.8176\n",
      "Epoch 20/150\n",
      "47500/47500 [==============================] - 12s 258us/sample - loss: 0.4399 - accuracy: 0.9618 - val_loss: 1.2691 - val_accuracy: 0.7844\n",
      "Epoch 21/150\n",
      "47500/47500 [==============================] - 12s 259us/sample - loss: 0.4274 - accuracy: 0.9656 - val_loss: 1.1477 - val_accuracy: 0.8116\n",
      "Epoch 22/150\n",
      "47500/47500 [==============================] - 12s 258us/sample - loss: 0.4385 - accuracy: 0.9627 - val_loss: 1.1354 - val_accuracy: 0.7948\n",
      "Epoch 23/150\n",
      "47500/47500 [==============================] - 12s 258us/sample - loss: 0.4481 - accuracy: 0.9615 - val_loss: 1.0804 - val_accuracy: 0.8076\n",
      "Epoch 24/150\n",
      "47500/47500 [==============================] - 12s 259us/sample - loss: 0.4321 - accuracy: 0.9672 - val_loss: 1.2564 - val_accuracy: 0.7968\n",
      "Epoch 25/150\n",
      "47500/47500 [==============================] - 12s 259us/sample - loss: 0.4770 - accuracy: 0.9566 - val_loss: 1.1189 - val_accuracy: 0.8184\n",
      "##################################\n",
      "\n",
      "Training model_3_10:\n",
      "\n",
      "Train on 47500 samples, validate on 2500 samples\n",
      "Epoch 1/150\n",
      "47500/47500 [==============================] - 13s 284us/sample - loss: 1.6451 - accuracy: 0.5267 - val_loss: 3.7490 - val_accuracy: 0.1636\n",
      "Epoch 2/150\n",
      "47500/47500 [==============================] - 12s 259us/sample - loss: 1.1261 - accuracy: 0.7020 - val_loss: 1.6138 - val_accuracy: 0.5912\n",
      "Epoch 3/150\n",
      "47500/47500 [==============================] - 12s 259us/sample - loss: 0.9209 - accuracy: 0.7681 - val_loss: 1.1086 - val_accuracy: 0.7184\n",
      "Epoch 4/150\n",
      "47500/47500 [==============================] - 12s 259us/sample - loss: 0.7930 - accuracy: 0.8102 - val_loss: 1.1016 - val_accuracy: 0.7204\n",
      "Epoch 5/150\n",
      "47500/47500 [==============================] - 12s 259us/sample - loss: 0.6971 - accuracy: 0.8397 - val_loss: 0.9531 - val_accuracy: 0.7540\n",
      "Epoch 6/150\n",
      "47500/47500 [==============================] - 12s 259us/sample - loss: 0.6252 - accuracy: 0.8644 - val_loss: 1.0267 - val_accuracy: 0.7404\n",
      "Epoch 7/150\n",
      "47500/47500 [==============================] - 12s 258us/sample - loss: 0.5830 - accuracy: 0.8820 - val_loss: 0.9822 - val_accuracy: 0.7700\n",
      "Epoch 8/150\n",
      "47500/47500 [==============================] - 12s 259us/sample - loss: 0.5462 - accuracy: 0.8980 - val_loss: 1.0636 - val_accuracy: 0.7624\n",
      "Epoch 9/150\n",
      "47500/47500 [==============================] - 12s 259us/sample - loss: 0.5424 - accuracy: 0.9042 - val_loss: 0.9472 - val_accuracy: 0.7900\n",
      "Epoch 10/150\n",
      "47500/47500 [==============================] - 14s 301us/sample - loss: 0.4897 - accuracy: 0.9242 - val_loss: 1.0445 - val_accuracy: 0.7888\n",
      "Epoch 11/150\n",
      "47500/47500 [==============================] - 15s 311us/sample - loss: 0.4868 - accuracy: 0.9273 - val_loss: 1.0164 - val_accuracy: 0.7820\n",
      "Epoch 12/150\n",
      "47500/47500 [==============================] - 15s 309us/sample - loss: 0.4714 - accuracy: 0.9381 - val_loss: 1.0128 - val_accuracy: 0.8028\n",
      "Epoch 13/150\n",
      "47500/47500 [==============================] - 14s 290us/sample - loss: 0.4862 - accuracy: 0.9363 - val_loss: 1.1247 - val_accuracy: 0.7760\n",
      "Epoch 14/150\n",
      "47500/47500 [==============================] - 14s 293us/sample - loss: 0.4484 - accuracy: 0.9505 - val_loss: 1.1400 - val_accuracy: 0.7776\n",
      "Epoch 15/150\n",
      "47500/47500 [==============================] - 13s 274us/sample - loss: 0.4354 - accuracy: 0.9537 - val_loss: 1.1407 - val_accuracy: 0.7900\n",
      "Epoch 16/150\n",
      "47500/47500 [==============================] - 13s 277us/sample - loss: 0.4434 - accuracy: 0.9531 - val_loss: 1.2796 - val_accuracy: 0.7632\n",
      "Epoch 17/150\n",
      "47500/47500 [==============================] - 13s 276us/sample - loss: 0.4373 - accuracy: 0.9575 - val_loss: 1.2207 - val_accuracy: 0.7676\n",
      "Epoch 18/150\n",
      "47500/47500 [==============================] - 13s 280us/sample - loss: 0.4309 - accuracy: 0.9597 - val_loss: 1.3448 - val_accuracy: 0.7572\n",
      "Epoch 19/150\n",
      "47500/47500 [==============================] - 15s 320us/sample - loss: 0.4498 - accuracy: 0.9573 - val_loss: 1.2043 - val_accuracy: 0.7864\n",
      "Epoch 20/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47500/47500 [==============================] - 14s 295us/sample - loss: 0.4587 - accuracy: 0.9560 - val_loss: 1.1607 - val_accuracy: 0.7840\n",
      "Epoch 21/150\n",
      "47500/47500 [==============================] - 14s 286us/sample - loss: 0.4278 - accuracy: 0.9662 - val_loss: 1.1967 - val_accuracy: 0.7824\n",
      "Epoch 22/150\n",
      "47500/47500 [==============================] - 13s 276us/sample - loss: 0.4748 - accuracy: 0.9545 - val_loss: 1.3093 - val_accuracy: 0.7716\n",
      "Epoch 23/150\n",
      "47500/47500 [==============================] - 13s 275us/sample - loss: 0.4390 - accuracy: 0.9660 - val_loss: 1.2720 - val_accuracy: 0.7920\n",
      "Epoch 24/150\n",
      "47500/47500 [==============================] - 14s 292us/sample - loss: 0.4109 - accuracy: 0.9729 - val_loss: 1.1936 - val_accuracy: 0.7896\n",
      "Epoch 25/150\n",
      "47500/47500 [==============================] - 13s 277us/sample - loss: 0.4171 - accuracy: 0.9705 - val_loss: 1.2508 - val_accuracy: 0.7852\n",
      "Epoch 26/150\n",
      "47500/47500 [==============================] - 14s 289us/sample - loss: 0.5396 - accuracy: 0.9403 - val_loss: 1.1740 - val_accuracy: 0.7924\n",
      "Epoch 27/150\n",
      "47500/47500 [==============================] - 13s 278us/sample - loss: 0.4300 - accuracy: 0.9703 - val_loss: 1.2517 - val_accuracy: 0.7804\n",
      "Epoch 28/150\n",
      "47500/47500 [==============================] - 14s 285us/sample - loss: 0.4489 - accuracy: 0.9653 - val_loss: 1.2360 - val_accuracy: 0.8012\n",
      "Epoch 29/150\n",
      "47500/47500 [==============================] - 13s 279us/sample - loss: 0.4195 - accuracy: 0.9720 - val_loss: 1.1839 - val_accuracy: 0.7916\n"
     ]
    }
   ],
   "source": [
    "test_model_3(results, x_train, x_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model_1': [0.7497,\n",
       "  0.755,\n",
       "  0.7304,\n",
       "  0.7479,\n",
       "  0.7485,\n",
       "  0.7359,\n",
       "  0.7437,\n",
       "  0.7601,\n",
       "  0.741,\n",
       "  0.7594],\n",
       " 'model_2': [0.7666,\n",
       "  0.7505,\n",
       "  0.744,\n",
       "  0.7702,\n",
       "  0.7555,\n",
       "  0.7466,\n",
       "  0.7552,\n",
       "  0.7524,\n",
       "  0.7437,\n",
       "  0.73],\n",
       " 'model_3': [0.7702,\n",
       "  0.7877,\n",
       "  0.7816,\n",
       "  0.7768,\n",
       "  0.7943,\n",
       "  0.7954,\n",
       "  0.801,\n",
       "  0.7678,\n",
       "  0.7742,\n",
       "  0.7988]}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (ml-gpu)",
   "language": "python",
   "name": "ml-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
