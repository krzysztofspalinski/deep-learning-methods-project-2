{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import datasets, layers, models, regularizers\n",
    "\n",
    "from data_preprocessing import one_hot_encode\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unpickle(file):\n",
    "    import pickle\n",
    "    with open(file, 'rb') as fo:\n",
    "        dict = pickle.load(fo, encoding='bytes')\n",
    "    return dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.empty((0, 32*32*3), int)\n",
    "y_train = np.empty((0, 10), int)\n",
    "\n",
    "\n",
    "for i in range(1, 6):\n",
    "    raw_data = unpickle(f'../data/data_batch_{i}')\n",
    "    X_tmp = raw_data[b'data']\n",
    "    y_tmp = np.array(raw_data[b'labels'])\n",
    "    X_train = np.append(X_train, X_tmp, axis=0)\n",
    "    y_train = np.append(y_train, y_tmp)\n",
    "\n",
    "X_train, X_validation, y_train, y_validation = train_test_split(X_train, y_train, test_size=0.05, random_state=42)\n",
    "\n",
    "ss = preprocessing.StandardScaler().fit(X_train)\n",
    "X_train = ss.transform(X_train)\n",
    "X_validation = ss.transform(X_validation)\n",
    "\n",
    "X_train = np.reshape(X_train, (-1, 32, 32, 3), order='F').transpose(0, 2, 1, 3)\n",
    "X_validation = np.reshape(X_validation, (-1, 32, 32, 3), order='F').transpose(0, 2, 1, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_cnn = keras.Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_cnn.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)))\n",
    "simple_cnn.add(layers.MaxPooling2D((2, 2)))\n",
    "simple_cnn.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "simple_cnn.add(layers.MaxPooling2D((2, 2)))\n",
    "simple_cnn.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
    "simple_cnn.add(layers.Flatten())\n",
    "simple_cnn.add(layers.Dense(64, activation='relu'))\n",
    "simple_cnn.add(layers.Dense(64, activation='relu'))\n",
    "simple_cnn.add(layers.Dense(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 30, 30, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 15, 15, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 13, 13, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 6, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 4, 4, 128)         73856     \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 64)                131136    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 229,194\n",
      "Trainable params: 229,194\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "simple_cnn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_cnn.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 47500 samples, validate on 2500 samples\n",
      "Epoch 1/30\n",
      "47500/47500 [==============================] - 47s 991us/sample - loss: 1.4525 - accuracy: 0.4709 - val_loss: 1.1448 - val_accuracy: 0.5872\n",
      "Epoch 2/30\n",
      "47500/47500 [==============================] - 46s 960us/sample - loss: 1.0455 - accuracy: 0.6339 - val_loss: 0.9812 - val_accuracy: 0.6480\n",
      "Epoch 3/30\n",
      "47500/47500 [==============================] - 45s 949us/sample - loss: 0.8650 - accuracy: 0.6996 - val_loss: 0.8679 - val_accuracy: 0.7012\n",
      "Epoch 4/30\n",
      "47500/47500 [==============================] - 45s 939us/sample - loss: 0.7496 - accuracy: 0.7385 - val_loss: 0.8970 - val_accuracy: 0.6908\n",
      "Epoch 5/30\n",
      "47500/47500 [==============================] - 45s 943us/sample - loss: 0.6639 - accuracy: 0.7685 - val_loss: 0.7989 - val_accuracy: 0.7284\n",
      "Epoch 6/30\n",
      "47500/47500 [==============================] - 45s 950us/sample - loss: 0.5939 - accuracy: 0.7921 - val_loss: 0.8067 - val_accuracy: 0.7228\n",
      "Epoch 7/30\n",
      "47500/47500 [==============================] - 46s 961us/sample - loss: 0.5281 - accuracy: 0.8162 - val_loss: 0.8119 - val_accuracy: 0.7236\n",
      "Epoch 8/30\n",
      "47500/47500 [==============================] - 45s 941us/sample - loss: 0.4678 - accuracy: 0.8351 - val_loss: 0.8918 - val_accuracy: 0.7152\n",
      "Epoch 9/30\n",
      "47500/47500 [==============================] - 44s 923us/sample - loss: 0.4170 - accuracy: 0.8517 - val_loss: 0.9094 - val_accuracy: 0.7284\n",
      "Epoch 10/30\n",
      "47500/47500 [==============================] - 44s 924us/sample - loss: 0.3724 - accuracy: 0.8686 - val_loss: 0.9438 - val_accuracy: 0.7192\n",
      "Epoch 11/30\n",
      "47500/47500 [==============================] - 44s 924us/sample - loss: 0.3303 - accuracy: 0.8848 - val_loss: 1.0278 - val_accuracy: 0.7268\n",
      "Epoch 12/30\n",
      "47500/47500 [==============================] - 44s 924us/sample - loss: 0.2957 - accuracy: 0.8947 - val_loss: 1.0029 - val_accuracy: 0.7220\n",
      "Epoch 13/30\n",
      "47500/47500 [==============================] - 44s 930us/sample - loss: 0.2653 - accuracy: 0.9072 - val_loss: 1.0965 - val_accuracy: 0.7204\n",
      "Epoch 14/30\n",
      "47500/47500 [==============================] - 45s 943us/sample - loss: 0.2357 - accuracy: 0.9168 - val_loss: 1.2918 - val_accuracy: 0.7024\n",
      "Epoch 15/30\n",
      "47500/47500 [==============================] - 45s 951us/sample - loss: 0.2213 - accuracy: 0.9224 - val_loss: 1.3156 - val_accuracy: 0.7040\n",
      "Epoch 16/30\n",
      "47500/47500 [==============================] - 45s 954us/sample - loss: 0.2010 - accuracy: 0.9293 - val_loss: 1.2863 - val_accuracy: 0.7128\n",
      "Epoch 17/30\n",
      "47500/47500 [==============================] - 44s 930us/sample - loss: 0.1807 - accuracy: 0.9367 - val_loss: 1.4044 - val_accuracy: 0.7176\n",
      "Epoch 18/30\n",
      "47500/47500 [==============================] - 44s 930us/sample - loss: 0.1747 - accuracy: 0.9387 - val_loss: 1.4369 - val_accuracy: 0.7140\n",
      "Epoch 19/30\n",
      "47500/47500 [==============================] - 45s 952us/sample - loss: 0.1590 - accuracy: 0.9454 - val_loss: 1.5523 - val_accuracy: 0.7132\n",
      "Epoch 20/30\n",
      "47500/47500 [==============================] - 46s 961us/sample - loss: 0.1499 - accuracy: 0.9482 - val_loss: 1.5302 - val_accuracy: 0.7060\n",
      "Epoch 21/30\n",
      "47500/47500 [==============================] - 47s 981us/sample - loss: 0.1461 - accuracy: 0.9488 - val_loss: 1.5297 - val_accuracy: 0.7072\n",
      "Epoch 22/30\n",
      "47500/47500 [==============================] - 46s 974us/sample - loss: 0.1411 - accuracy: 0.9521 - val_loss: 1.5878 - val_accuracy: 0.7128\n",
      "Epoch 23/30\n",
      "47500/47500 [==============================] - 45s 950us/sample - loss: 0.1318 - accuracy: 0.9551 - val_loss: 1.7126 - val_accuracy: 0.7056\n",
      "Epoch 24/30\n",
      "47500/47500 [==============================] - 45s 956us/sample - loss: 0.1227 - accuracy: 0.9568 - val_loss: 1.7611 - val_accuracy: 0.7096\n",
      "Epoch 25/30\n",
      "47500/47500 [==============================] - 45s 950us/sample - loss: 0.1224 - accuracy: 0.9592 - val_loss: 1.6314 - val_accuracy: 0.7040\n",
      "Epoch 26/30\n",
      "47500/47500 [==============================] - 47s 984us/sample - loss: 0.1202 - accuracy: 0.9600 - val_loss: 1.8457 - val_accuracy: 0.6952\n",
      "Epoch 27/30\n",
      "47500/47500 [==============================] - 44s 930us/sample - loss: 0.1160 - accuracy: 0.9614 - val_loss: 1.8217 - val_accuracy: 0.7128\n",
      "Epoch 28/30\n",
      "47500/47500 [==============================] - 45s 946us/sample - loss: 0.1146 - accuracy: 0.9610 - val_loss: 1.9032 - val_accuracy: 0.7080\n",
      "Epoch 29/30\n",
      "47500/47500 [==============================] - 44s 929us/sample - loss: 0.1037 - accuracy: 0.9660 - val_loss: 1.9281 - val_accuracy: 0.7076\n",
      "Epoch 30/30\n",
      "47500/47500 [==============================] - 44s 924us/sample - loss: 0.1032 - accuracy: 0.9652 - val_loss: 1.9093 - val_accuracy: 0.7176\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1a4a96bac8>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simple_cnn.fit(X_train, y_train, epochs=30, validation_data=(X_validation, y_validation))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "Model is not generalizing for validation set -- accuracy is below 0.73 on validation set, while on training test accuracy is about 0.95.\n",
    "\n",
    "Next step: regularization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple CNN model with regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_cnn_reg = keras.Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_cnn_reg.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3),\n",
    "                                 kernel_regularizer=regularizers.l2(0.01)))\n",
    "simple_cnn_reg.add(layers.MaxPooling2D((2, 2)))\n",
    "simple_cnn_reg.add(layers.Conv2D(64, (3, 3), activation='relu',\n",
    "                                 kernel_regularizer=regularizers.l2(0.01)))\n",
    "simple_cnn_reg.add(layers.MaxPooling2D((2, 2)))\n",
    "simple_cnn_reg.add(layers.Conv2D(128, (3, 3), activation='relu',\n",
    "                                 kernel_regularizer=regularizers.l2(0.01)))\n",
    "simple_cnn_reg.add(layers.Flatten())\n",
    "simple_cnn_reg.add(layers.Dense(64, activation='relu',\n",
    "                                kernel_regularizer=regularizers.l2(0.01)))\n",
    "simple_cnn_reg.add(layers.Dense(64, activation='relu',\n",
    "                                kernel_regularizer=regularizers.l2(0.01)))\n",
    "simple_cnn_reg.add(layers.Dense(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_3 (Conv2D)            (None, 30, 30, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 15, 15, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 13, 13, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 6, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 4, 4, 128)         73856     \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 64)                131136    \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 229,194\n",
      "Trainable params: 229,194\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "simple_cnn_reg.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_cnn_reg.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 47500 samples, validate on 2500 samples\n",
      "Epoch 1/30\n",
      "47500/47500 [==============================] - 46s 976us/sample - loss: 1.9548 - accuracy: 0.3981 - val_loss: 1.6387 - val_accuracy: 0.4808\n",
      "Epoch 2/30\n",
      "47500/47500 [==============================] - 44s 925us/sample - loss: 1.6170 - accuracy: 0.5022 - val_loss: 1.5601 - val_accuracy: 0.5200\n",
      "Epoch 3/30\n",
      "47500/47500 [==============================] - 44s 924us/sample - loss: 1.5492 - accuracy: 0.5290 - val_loss: 1.5333 - val_accuracy: 0.5312\n",
      "Epoch 4/30\n",
      "47500/47500 [==============================] - 44s 934us/sample - loss: 1.4995 - accuracy: 0.5499 - val_loss: 1.5349 - val_accuracy: 0.5388\n",
      "Epoch 5/30\n",
      "47500/47500 [==============================] - 45s 950us/sample - loss: 1.4593 - accuracy: 0.5712 - val_loss: 1.4229 - val_accuracy: 0.5812\n",
      "Epoch 6/30\n",
      "47500/47500 [==============================] - 44s 931us/sample - loss: 1.4268 - accuracy: 0.5881 - val_loss: 1.4440 - val_accuracy: 0.5888\n",
      "Epoch 7/30\n",
      "47500/47500 [==============================] - 44s 936us/sample - loss: 1.4041 - accuracy: 0.5996 - val_loss: 1.3465 - val_accuracy: 0.6220\n",
      "Epoch 8/30\n",
      "47500/47500 [==============================] - 44s 934us/sample - loss: 1.3737 - accuracy: 0.6148 - val_loss: 1.3591 - val_accuracy: 0.6360\n",
      "Epoch 9/30\n",
      "47500/47500 [==============================] - 44s 928us/sample - loss: 1.3456 - accuracy: 0.6269 - val_loss: 1.3991 - val_accuracy: 0.5992\n",
      "Epoch 10/30\n",
      "47500/47500 [==============================] - 44s 930us/sample - loss: 1.3318 - accuracy: 0.6327 - val_loss: 1.3048 - val_accuracy: 0.6304\n",
      "Epoch 11/30\n",
      "47500/47500 [==============================] - 44s 927us/sample - loss: 1.3203 - accuracy: 0.6364 - val_loss: 1.3096 - val_accuracy: 0.6308\n",
      "Epoch 12/30\n",
      "47500/47500 [==============================] - 44s 927us/sample - loss: 1.3056 - accuracy: 0.6415 - val_loss: 1.2852 - val_accuracy: 0.6540\n",
      "Epoch 13/30\n",
      "47500/47500 [==============================] - 44s 933us/sample - loss: 1.2989 - accuracy: 0.6430 - val_loss: 1.2738 - val_accuracy: 0.6492\n",
      "Epoch 14/30\n",
      "47500/47500 [==============================] - 44s 927us/sample - loss: 1.2873 - accuracy: 0.6457 - val_loss: 1.2474 - val_accuracy: 0.6552\n",
      "Epoch 15/30\n",
      "47500/47500 [==============================] - 45s 937us/sample - loss: 1.2765 - accuracy: 0.6486 - val_loss: 1.3440 - val_accuracy: 0.6112\n",
      "Epoch 16/30\n",
      "47500/47500 [==============================] - 44s 936us/sample - loss: 1.2791 - accuracy: 0.6506 - val_loss: 1.2714 - val_accuracy: 0.6416\n",
      "Epoch 17/30\n",
      "47500/47500 [==============================] - 44s 932us/sample - loss: 1.2641 - accuracy: 0.6548 - val_loss: 1.2399 - val_accuracy: 0.6584\n",
      "Epoch 18/30\n",
      "47500/47500 [==============================] - 44s 935us/sample - loss: 1.2582 - accuracy: 0.6555 - val_loss: 1.3043 - val_accuracy: 0.6336\n",
      "Epoch 19/30\n",
      "47500/47500 [==============================] - 45s 938us/sample - loss: 1.2540 - accuracy: 0.6563 - val_loss: 1.2600 - val_accuracy: 0.6604\n",
      "Epoch 20/30\n",
      "47500/47500 [==============================] - 45s 938us/sample - loss: 1.2517 - accuracy: 0.6544 - val_loss: 1.2978 - val_accuracy: 0.6272\n",
      "Epoch 21/30\n",
      "47500/47500 [==============================] - 44s 936us/sample - loss: 1.2448 - accuracy: 0.6604 - val_loss: 1.2298 - val_accuracy: 0.6608\n",
      "Epoch 22/30\n",
      "47500/47500 [==============================] - 45s 948us/sample - loss: 1.2410 - accuracy: 0.6610 - val_loss: 1.2460 - val_accuracy: 0.6564\n",
      "Epoch 23/30\n",
      "47500/47500 [==============================] - 45s 940us/sample - loss: 1.2376 - accuracy: 0.6623 - val_loss: 1.2967 - val_accuracy: 0.6496\n",
      "Epoch 24/30\n",
      "47500/47500 [==============================] - 45s 941us/sample - loss: 1.2381 - accuracy: 0.6595 - val_loss: 1.2760 - val_accuracy: 0.6528\n",
      "Epoch 25/30\n",
      "47500/47500 [==============================] - 44s 935us/sample - loss: 1.2330 - accuracy: 0.6612 - val_loss: 1.2232 - val_accuracy: 0.6576\n",
      "Epoch 26/30\n",
      "47500/47500 [==============================] - 45s 946us/sample - loss: 1.2313 - accuracy: 0.6621 - val_loss: 1.2245 - val_accuracy: 0.6652\n",
      "Epoch 27/30\n",
      "47500/47500 [==============================] - 45s 940us/sample - loss: 1.2286 - accuracy: 0.6647 - val_loss: 1.1788 - val_accuracy: 0.6828\n",
      "Epoch 28/30\n",
      "47500/47500 [==============================] - 45s 937us/sample - loss: 1.2238 - accuracy: 0.6645 - val_loss: 1.2071 - val_accuracy: 0.6736\n",
      "Epoch 29/30\n",
      "47500/47500 [==============================] - 44s 932us/sample - loss: 1.2282 - accuracy: 0.6642 - val_loss: 1.2124 - val_accuracy: 0.6636\n",
      "Epoch 30/30\n",
      "47500/47500 [==============================] - 44s 929us/sample - loss: 1.2227 - accuracy: 0.6649 - val_loss: 1.2661 - val_accuracy: 0.6480\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1b44063f60>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simple_cnn_reg.fit(X_train, y_train, epochs=30, validation_data=(X_validation, y_validation))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "Model is generalizing better, but it's also much weaker - accuracy on both validation set and training set is much worse.\n",
    "\n",
    "Next step: adding more layers, lowering regularization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deeper CNN with regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "deep_cnn_reg = keras.Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "deep_cnn_reg.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3),\n",
    "                                 kernel_regularizer=regularizers.l2(0.001)))\n",
    "deep_cnn_reg.add(layers.MaxPooling2D((2, 2)))\n",
    "deep_cnn_reg.add(layers.Conv2D(64, (3, 3), activation='relu',\n",
    "                                 kernel_regularizer=regularizers.l2(0.001)))\n",
    "deep_cnn_reg.add(layers.MaxPooling2D((2, 2)))\n",
    "deep_cnn_reg.add(layers.Conv2D(128, (3, 3), activation='relu',\n",
    "                                 kernel_regularizer=regularizers.l2(0.001)))\n",
    "deep_cnn_reg.add(layers.Flatten())\n",
    "deep_cnn_reg.add(layers.Dense(128, activation='relu',\n",
    "                                kernel_regularizer=regularizers.l2(0.01)))\n",
    "deep_cnn_reg.add(layers.Dense(128, activation='relu',\n",
    "                                kernel_regularizer=regularizers.l2(0.01)))\n",
    "deep_cnn_reg.add(layers.Dense(128, activation='relu',\n",
    "                                kernel_regularizer=regularizers.l2(0.01)))\n",
    "deep_cnn_reg.add(layers.Dense(64, activation='relu',\n",
    "                                kernel_regularizer=regularizers.l2(0.01)))\n",
    "deep_cnn_reg.add(layers.Dense(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_6 (Conv2D)            (None, 30, 30, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 15, 15, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 13, 13, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 6, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 4, 4, 128)         73856     \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 128)               262272    \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 397,450\n",
      "Trainable params: 397,450\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "deep_cnn_reg.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "deep_cnn_reg.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 47500 samples, validate on 2500 samples\n",
      "Epoch 1/30\n",
      "47500/47500 [==============================] - 49s 1ms/sample - loss: 1.0125 - accuracy: 0.7627 - val_loss: 1.0795 - val_accuracy: 0.7380\n",
      "Epoch 2/30\n",
      "47500/47500 [==============================] - 49s 1ms/sample - loss: 1.0078 - accuracy: 0.7641 - val_loss: 1.0686 - val_accuracy: 0.7508\n",
      "Epoch 3/30\n",
      "47500/47500 [==============================] - 47s 992us/sample - loss: 1.0005 - accuracy: 0.7656 - val_loss: 1.0771 - val_accuracy: 0.7444\n",
      "Epoch 4/30\n",
      "47500/47500 [==============================] - 47s 997us/sample - loss: 1.0039 - accuracy: 0.7649 - val_loss: 1.1089 - val_accuracy: 0.7388\n",
      "Epoch 5/30\n",
      "47500/47500 [==============================] - 48s 1ms/sample - loss: 0.9975 - accuracy: 0.7701 - val_loss: 1.1202 - val_accuracy: 0.7264\n",
      "Epoch 6/30\n",
      "47500/47500 [==============================] - 47s 996us/sample - loss: 0.9977 - accuracy: 0.7684 - val_loss: 1.1419 - val_accuracy: 0.7264\n",
      "Epoch 7/30\n",
      "47500/47500 [==============================] - 48s 1ms/sample - loss: 0.9933 - accuracy: 0.7704 - val_loss: 1.0431 - val_accuracy: 0.7556\n",
      "Epoch 8/30\n",
      "47500/47500 [==============================] - 48s 1ms/sample - loss: 0.9840 - accuracy: 0.7742 - val_loss: 1.0875 - val_accuracy: 0.7432\n",
      "Epoch 9/30\n",
      "47500/47500 [==============================] - 48s 1ms/sample - loss: 0.9810 - accuracy: 0.7746 - val_loss: 1.1325 - val_accuracy: 0.7212\n",
      "Epoch 10/30\n",
      "47500/47500 [==============================] - 47s 992us/sample - loss: 0.9855 - accuracy: 0.7742 - val_loss: 1.1039 - val_accuracy: 0.7428\n",
      "Epoch 11/30\n",
      "47500/47500 [==============================] - 47s 991us/sample - loss: 0.9843 - accuracy: 0.7761 - val_loss: 1.0697 - val_accuracy: 0.7468\n",
      "Epoch 12/30\n",
      "47500/47500 [==============================] - 49s 1ms/sample - loss: 0.9747 - accuracy: 0.7797 - val_loss: 1.0950 - val_accuracy: 0.7416\n",
      "Epoch 13/30\n",
      "47500/47500 [==============================] - 48s 1ms/sample - loss: 0.9712 - accuracy: 0.7804 - val_loss: 1.0762 - val_accuracy: 0.7440\n",
      "Epoch 14/30\n",
      "47500/47500 [==============================] - 48s 1ms/sample - loss: 0.9728 - accuracy: 0.7789 - val_loss: 1.1141 - val_accuracy: 0.7300\n",
      "Epoch 15/30\n",
      "47500/47500 [==============================] - 48s 1ms/sample - loss: 0.9727 - accuracy: 0.7796 - val_loss: 1.1019 - val_accuracy: 0.7356\n",
      "Epoch 16/30\n",
      "47500/47500 [==============================] - 48s 1ms/sample - loss: 0.9646 - accuracy: 0.7820 - val_loss: 1.1025 - val_accuracy: 0.7396\n",
      "Epoch 17/30\n",
      "47500/47500 [==============================] - 49s 1ms/sample - loss: 0.9709 - accuracy: 0.7812 - val_loss: 1.0866 - val_accuracy: 0.7452\n",
      "Epoch 18/30\n",
      "47500/47500 [==============================] - 49s 1ms/sample - loss: 0.9662 - accuracy: 0.7838 - val_loss: 1.0771 - val_accuracy: 0.7476\n",
      "Epoch 19/30\n",
      "47500/47500 [==============================] - 49s 1ms/sample - loss: 0.9642 - accuracy: 0.7853 - val_loss: 1.1674 - val_accuracy: 0.7184\n",
      "Epoch 20/30\n",
      "47500/47500 [==============================] - 49s 1ms/sample - loss: 0.9630 - accuracy: 0.7876 - val_loss: 1.0688 - val_accuracy: 0.7492\n",
      "Epoch 21/30\n",
      "47500/47500 [==============================] - 49s 1ms/sample - loss: 0.9593 - accuracy: 0.7860 - val_loss: 1.1159 - val_accuracy: 0.7380\n",
      "Epoch 22/30\n",
      "47500/47500 [==============================] - 48s 1ms/sample - loss: 0.9575 - accuracy: 0.7869 - val_loss: 1.0714 - val_accuracy: 0.7552\n",
      "Epoch 23/30\n",
      "47500/47500 [==============================] - 49s 1ms/sample - loss: 0.9537 - accuracy: 0.7876 - val_loss: 1.0946 - val_accuracy: 0.7544\n",
      "Epoch 24/30\n",
      "47500/47500 [==============================] - 49s 1ms/sample - loss: 0.9540 - accuracy: 0.7883 - val_loss: 1.1666 - val_accuracy: 0.7264\n",
      "Epoch 25/30\n",
      "47500/47500 [==============================] - 48s 1ms/sample - loss: 0.9521 - accuracy: 0.7887 - val_loss: 1.1181 - val_accuracy: 0.7384\n",
      "Epoch 26/30\n",
      "47500/47500 [==============================] - 47s 996us/sample - loss: 0.9503 - accuracy: 0.7908 - val_loss: 1.1215 - val_accuracy: 0.7356\n",
      "Epoch 27/30\n",
      "47500/47500 [==============================] - 47s 995us/sample - loss: 0.9482 - accuracy: 0.7932 - val_loss: 1.0733 - val_accuracy: 0.7548\n",
      "Epoch 28/30\n",
      "47500/47500 [==============================] - 47s 996us/sample - loss: 0.9454 - accuracy: 0.7909 - val_loss: 1.1207 - val_accuracy: 0.7496\n",
      "Epoch 29/30\n",
      "47500/47500 [==============================] - 47s 994us/sample - loss: 0.9457 - accuracy: 0.7924 - val_loss: 1.1407 - val_accuracy: 0.7424\n",
      "Epoch 30/30\n",
      "47500/47500 [==============================] - 47s 993us/sample - loss: 0.9430 - accuracy: 0.7945 - val_loss: 1.1321 - val_accuracy: 0.7408\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1a9ae22668>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deep_cnn_reg.fit(X_train, y_train, epochs=30, validation_data=(X_validation, y_validation))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "Accuracy on validation set is ~0.74, it is also more or less consistant with results on training set.\n",
    "\n",
    "Next step: adding data augmentation and using more advanced architecture, maybe resnet. (In the next notebook)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (ml-cpu)",
   "language": "python",
   "name": "ml-cpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
